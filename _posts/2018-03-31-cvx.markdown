---
layout: post
comments: true
title:  "Convex Optimization"
excerpt: "Constrained Optimization, Lagrangians, Duality, and Interior Point Methods"
date:   2018-03-31 11:00:00
mathjax: true
---

<!-- 
<svg width="800" height="200">
	<rect width="800" height="200" style="fill:rgb(98,51,20)" />
	<rect width="20" height="50" x="20" y="100" style="fill:rgb(189,106,53)" />
	<rect width="20" height="50" x="760" y="30" style="fill:rgb(77,175,75)" />
	<rect width="10" height="10" x="400" y="60" style="fill:rgb(225,229,224)" />
</svg>
 -->

## Convexity

### First-Order Condition

If \\(f\\) is convex and differentiable, then 

$$
f(x) + \nabla f(x)^T (y-x) \leq f(y)
$$

That is to say, a tangent line to \\(f\\) is a **global underestimator** of the function.

### Second-Order Condition

Assuming \\(f\\) is twice differentiable, that is, its Hessian or second derivative \\(\nabla^2f\\) exists at each point in the domain of \\(f\\), then \\(f\\) is convex **if and only if ** the domain of \\(f\\) is convex and its Hessian is positive semidefinite.

Formally, we state, for all \\(x \in \mbox{dom}(f)\\),

$$
\nabla^2 f(x) \succeq 0
$$
This condition can be interpreted geometrically as the requirement that the graph of the function have positive (upward) curvature at \\(x\\).

### Known Convex and Concave Functions

Convex
- Linear.
- Affine. \\(f(x) = Ax+b\\), where \\(A \in \mathbb{R}^{m \times n}\\) and \\(b \in \mathbb{R}^m\\). This is the sum of a linear function and a constant.
- Exponential. \\(e^{ax}\\) is convex on \\(\mathbb{R}\\), for any \\(a \in \mathbb{R}\\).
- Powers. \\(x^a\\) is convex on \\(R_{++}\\) when \\(a \geq 1\\) or \\(a \leq 0\\).
- Powers of absolute value. \\(\|x\|^p\\), for \\(p\geq 1\\), is convex on \\(\mathbb{R}\\).
- Negative Entropy. \\(x \mbox{log}(x)\\) is convex on \\(\mathbb{R}_{++}\\).
- Norms. Every norm on \\(\mathbb{R}^n\\) is convex.
- Max function. \\(f(x) = \mbox{max} \{ x_1, \dots, x_n \} \\) is convex on \\(\mathbb{R}^n\\).
- Quadratic-over-linear function.
- Log-sum-exp. \\(f(x) = \mbox{log }(e^{x_1}+\cdots+e^{x_n})\\) is convex on \\(\mathbb{R}^n\\).

Concave
- Logarithm. \\(\mbox{log}(x)\\) concave on \\(\mathbb{R}_{++}\\).
- Powers. \\(x^a\\) is concave for \\(0 \leq a \leq 1\\).
- Geometric mean. \\(f(x) = (\prod\limits_{i=1}^n x_i)^{1/n}\\) is concave on \\(\mathbb{R}_{++}^n\\).

- Log-determinant. \\(f(X) = \mbox{log } \mbox{det } X\\) is concave on \\(S_{++}^n\\)

## Constrained Optimization Problems

These problems take on a very general form, that we'll revisit over and over again. In math, that form is:

$$
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} & f_0(x) & \\
\mbox{subject to} & f_i(x) \leq 0, & i=1,\dots,m \\
& h_i(x) = 0, & i=1,\dots,p
\end{array}
\end{aligned}
$$

In prose, the problem is to find an \\(x\\) that minimizes \\(f_0(x)\\) among all \\(x\\) that satisfy the conditions \\( f_i(x) \leq 0\\) for \\(i=1,\dots,m \\) and \\( h_i(x) = 0\\) for \\( i=1,\dots,p\\).  

The inequalities \\(f_i(x) \leq 0\\) are called inequality constraints, and the equations \\(h_i(x) = 0\\) are called the equality constraints.

### The Epigraph form of the above standard problem is the problem

$$
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} & t & \\
\mbox{subject to} & f_0(x) - t \leq 0 & \\
& f_i(x) \leq 0, & i=1,\dots,m \\
& h_i(x) = 0, & i=1,\dots,p
\end{array}
\end{aligned}
$$

Geometrically, from [1]:

<img src="/assets/epigraph_problem.png" width="50%" />


## The Lagrangian

The basic idea in Lagrangian duality is to take the constraints in the standard problem into account by **augmenting the objective function with a weighted sum of the constraint functions**. The Lagrangian associated with the standard problem is:

$$
L(x, \lambda, \nu) = f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x)
$$

We call \\(\lambda_i\\) as the Lagrange multiplier associated with the \\(i\\)'th **inequality** constraint \\(f_i(x) \leq 0\\).  We refer to \\(\nu_i\\) as the Lagrange multiplier associated with the \\(i\\)'th **equality** constraint \\(h_i(x) = 0\\).

### The Lagrange Dual Function

$$
g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }} L(x,\lambda,\nu)
$$

In detail, the dual function is:

$$
g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }}\Bigg( f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x) \Bigg)
$$

This is the pointwise infimum of a family of affine functions of \\( (\lambda, \nu)\\), so the dual function is **concave**, even when the standard optimization problem is not convex.

### The Lagrange Dual Problem

For each pair \\( (\lambda, \nu)\\), the Lagrange dual function gives us a lower bound on the optimal value \\(p^{*}\\) of the standard optimization problem. It is a **lower bound** that depends on some parameters \\( (\lambda,\nu)\\). But the question of interest for us is, what is the **best** lower bound that can be obtained from the Lagrange dual function. This leads to the following optimization problem:

$$
\begin{aligned}
\begin{array}{ll}
\mbox{maximize} & g(\lambda, \nu) \\
\mbox{subject to} & \lambda \succeq 0
\end{array}
\end{aligned}
$$

We refer to this problem as the **Lagrange dual problem** associated with the standard optimization problem. 

### Weak Duality

Let us define \\(d^{*}\\) as the optimal value of the Lagrange dual problem. This is **the best lower bound** on \\(p^{*}\\) that can be obtained from the Lagrange dual function.

Even if the original problem is not convex, we can always say \\(d^* \leq p^*\\). We call this property weak duality.

### Slater's Constraint Qualification

Slater's condition is a qualification on the problem constraints. It states that there exists an \\(x \in \mbox{relint}(\mathcal{D})\\) such that 

$$
\begin{array}{lll}
f_i(x) < 0, & i=1,\dots,m, & Ax=b.
\end{array}
$$

Why is that important? Well, because if the problem is convex, and **if Slater's condition** holds, then **strong duality** holds.

## KKT Conditions

## Newton's Method

Instead of minimizing the first-order Taylor approximation of a function \\(f\\), we may want to minimize the second-order Taylor approximation, \\(\hat{f}\\). That approximation at a point \\(x\\) is given by:

$$
\hat{f}(x+v) = f(x) + \nabla f(x)^T v + \frac{1}{2}v^T \nabla^2 f(x) v
$$

If the function \\(f\\) is quadratic, then minimizing \\(\hat{f}(x+v)\\) will give us an exact minimizer of \\(f\\). If the function \\(f\\) is nearly quadratic, intuition suggests that minimizing \\(\hat{f}(x+v)\\) should be a very good estimate of the minimizer of \\(f\\), i.e., \\(x^*\\).

Setting \\(\nabla_v \hat{f}(x+v)=0\\), we see:



## Interior Point Methods

Suppose we have the following inequality constrained optimization problem:

We can approximate the problem as an **equality constrained problem**. This is highly desirable because we know that Newton's method can be applied to equality constrained problems. We can make the inequality constraints implicit in the objective:

$$
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} & f_0(x) + \sum\limits_{i=1}^m I_{-}\bigg(f_i(x)\bigg) & \\
\mbox{subject to} & Ax = b
\end{array}
\end{aligned}
$$

The indicator function expresses our displeasure with respect to the satisfaction of the inequality constraints. If the indicator function is violated, its value becomes negative infinity:

$$
I_{-}(u) = \begin{cases} 0 & u\leq 0 \\ \infty & u > 0 \end{cases}
$$

Otherwise, we ignore its presence in the objective function.  Although we were able to remove the inequality constraints, the objective function is, in general, **not differentiable**, so Newton's method cannot be applied.


### The Log-Barrier

However, we could approximate the indicator function \\(I_{-}\\) with the **log-barrier** function:

$$
\hat{I}_{-}(u) = -\bigg(\frac{1}{t}\bigg) \mbox{log }(-u)
$$

Here, \\(t\\) is a parameter that sets the accuracy of the approximation. As \\(t\\) increases, the approximation becomes more accurate.  

A figure shows the quality of the approximation [1]:

<img src="/assets/log_barrier_approximation.png" width="70%" />

We now have a new problem:

$$
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} & f_0(x) + \sum\limits_{i=1}^m -\bigg(\frac{1}{t}\bigg) \mbox{log }\bigg(-f_i(x)\bigg) & \\
\mbox{subject to} & Ax = b
\end{array}
\end{aligned}
$$

This objective function is convex, and as long as an **appropriate closedness condition** holds, Newton's method can be used to solve it.

### References: 
1. Stephen Boyd and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press, New York, NY, USA.

