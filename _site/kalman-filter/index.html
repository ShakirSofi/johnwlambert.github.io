<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>The Kalman Filter</title>
  <meta name="description" content="Multivariate Gaussians, ...">
   <link rel="stylesheet" href="/css/main.css">


  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://johnwlambert.github.io/kalman-filter/">

  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.css"/>


  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">John Lambert</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          
          <a class="page-link" href="/collaborators/">Collaborators</a>
          
          
        
          
          
          
        
          
          
          <a class="page-link" href="/publications/">Publications</a>
          
          
        
          
          
          <a class="page-link" href="/teaching/">Teaching</a>
          
          
        
          
          
          
        
          
          
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1>The Kalman Filter</h1>
    <p class="meta">Dec 27, 2018</p>
  </header>

  <article class="post-content">
  <p>Table of Contents:</p>
<ul>
  <li><a href="#kf-overview">What is the Kalman Filter?</a></li>
  <li><a href="#3d-bbox-constant-velocity">Tracking 3D Bounding Boxes with Constant Velocity</a></li>
  <li><a href="#3dtracking-icp">Practical Example: 3D Tracking with ICP</a></li>
</ul>

<p><a name="kf-overview"></a></p>
<h2 id="what-is-the-kalman-filter">What is the Kalman Filter?</h2>

<p>The Kalman Filter is nothing more than the Bayes’ Filter for Gaussian distributed random variables. The Bayes’ Filter is described in a <a href="/bayes-filter/">previous post</a>.</p>

<p>It is a very surprising result that we can write out the integrals analytically for the Bayes’ Filter when working with a special family of distributions: Gaussian distributed random variables (r.v.’s).  As we recall from the Bayes’ Filter, we have two key recurrences for prediction and updates, respectively:</p>

<script type="math/tex; mode=display">p(x_{t} \mid y_{1:t-1}) = \int_{x_t-1} p(x_{t} \mid x_{t-1}) p(x_{t-1} \mid y_{1:t-1})dx_{t-1}</script>

<script type="math/tex; mode=display">p(x_{t} \mid y_{1:t}) = \frac{p(y_{t} \mid x_{t})p(x_{t} \mid y_{1:t-1})}{\int\limits_{x_{t}} p(y_{t} \mid x_{t}) p(x_{t} \mid y_{1:t-1}) dx_{t}}</script>

<p>Note that to compute these two recurrences, there are only three quantities that we’ll need to be able to evaluate:</p>
<ul>
  <li>(1) <script type="math/tex">\int_{x_{t-1}} p(x_t \mid x_{t-1}) p(x_{t-1} \mid y_{1:t-1}) dx_{t-1}</script></li>
  <li>(2) <script type="math/tex">p(x_t \mid x_{t-1})  = f(x_t, x_{t-1} )</script></li>
  <li>(3) <script type="math/tex">p(y_t \mid x_t) = g(y_t, x_t)</script></li>
</ul>

<p>Expressions (2) and (3) must be finitely parameterizable. We call (2) the <em>transition distribution</em> and we call (3) the <em>measurement likelihood</em>.</p>

<p>It will take a fair amount of work to derive the analytical formulas of the Bayes’ Filter for Gaussian r.v.’s (the Kalman Filter).  Gaussian distributions are the <em>only</em> useful family of distributions for which we can have a closed-form equation for the recursive filter. We’ll first review properties of multivariate Gaussians, then the Woodbury matrix inversion lemmas, intuition behind covariance matrices, and then derive the Kalman Filter.</p>

<h2 id="woodbury-matrix-inversion-lemmas">Woodbury Matrix Inversion Lemmas</h2>

<h2 id="kalman-filter-derivation">Kalman Filter Derivation</h2>

<p>A key property of the Gaussian function: the product of two Gaussian functions is another Gaussian function.</p>

<h2 id="jointly-guassian-random-vectors">Jointly Guassian Random Vectors</h2>

<p>Suppose <script type="math/tex">S = (X,Y)</script> (broken into two pieces)</p>

<p><script type="math/tex">S = (X,Y) \sim \mathcal{N}(\mu, \Sigma)</script>
where</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{ll}
\mu = \begin{bmatrix} \mu_x \\ \mu_y \end{bmatrix}, & \Sigma = \begin{bmatrix} 
\Sigma_x & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_y \end{bmatrix}
\end{array} %]]></script>

<p>Ultimately, we would like to compute <script type="math/tex">p(x \mid y)</script>, the Bayesian estimate of <script type="math/tex">X \mid Y</script></p>

<p>\begin{equation}
\begin{aligned}
\mu_x = E[X] <br />
\mu_y = E[Y] <br />
\Sigma_X = Cov(X) <br />
\Sigma_Y = Cov(Y) <br />
\Sigma_{XY} = Cov(X,Y) <br />
\Sigma_{YX} = Cov(Y,X) = \Sigma_{XY}^T
\end{aligned}
\end{equation}</p>

<p>Claim: The marginals are Gaussian:
\begin{equation}
X \sim p(x) = \int_y p(x,y) dx = \mathcal{N}(\mu_x, \Sigma_x)
\end{equation}
\begin{equation}
Y \sim p(y) = \int_x p(x,y)dx = \mathcal{N}(\mu_y, \Sigma_y)
\end{equation}</p>

<h2 id="conditional-gaussian-multivariate-variables">Conditional Gaussian Multivariate Variables</h2>

<p>The Conditionals are also Gaussian <a href="https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution">see here</a>:</p>

<p>We will recognize the Schur complement <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Boyd, A.5.5</a></p>

<p>\begin{equation}
X \mid Y \sim p(x \mid y) = \mathcal{N}(\mu_{x\mid y}, \Sigma_{x \mid y})
\end{equation}
We use 
\begin{equation}
\mu_{X \mid Y} = \mu_x + \Sigma_{XY} \Sigma_Y^{-1}(y - \mu_y)
\end{equation}</p>

<p>\begin{equation}
\Sigma_{X \mid Y} = \Sigma_x - \Sigma_{XY} \Sigma_Y^{-1} \Sigma_{YX}
\end{equation}
Same for 
\begin{equation}
Y  \mid X \sim p(y \mid x) = \mathcal{N}(\mu_{y \mid x}, \Sigma_{y \mid x})
\end{equation}
\item We recall that
\begin{equation}
p(x,y) = p(x \mid y) p(y) = p(y \mid x)p(x)
\end{equation}
\item which immediately gives us Bayes Rule
\begin{equation}
p(x \mid y) =  \frac{p(y \mid x)p(x)}{p(y)}
\end{equation}
\item Let’s prove that ?????????</p>

<p><script type="math/tex">% <![CDATA[
\mathcal{N}(\mu, \Sigma) = \mathcal{N}\Bigg(\begin{bmatrix} \mu_x \\ \mu_y \end{bmatrix}, \begin{bmatrix} \Sigma_x & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_y \end{bmatrix} \Bigg) = \mathcal{N}(\mu_{x\mid y}, \Sigma_{x \mid y}) \mathcal{N}(\mu_{y}, \Sigma_{ y}) %]]></script>
???????????????</p>

<h2 id="a-proof-by-demonstration">A Proof by Demonstration</h2>

<p>Working Backwards:</p>

<script type="math/tex; mode=display">p(x \mid y) p(y) = \mathcal{N}(\mu_{x\mid y}, \Sigma_{x \mid y}) \mathcal{N}(\mu_{y}, \Sigma_{ y})</script>

<script type="math/tex; mode=display">\mathcal{N}(\mu_x, \Sigma_x) = 
\eta_{x \mid y }\mbox{exp}
\Bigg\{ -\frac{1}{2} (x - \mu_{x \mid y})^T \Sigma_{x \mid y}^{-1} (x - \mu_{x \mid y}) \Bigg\} \cdot \eta_{ y }\mbox{exp}
\Bigg\{ -\frac{1}{2} (y - \mu_y)^T \Sigma_y^{-1} (y - \mu_y) \Bigg\}</script>

<p>Combine exponentials</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{N}(\mu_x, \Sigma_x) =
\eta_{x \mid y } \eta_{ y } \mbox{ exp}
\Bigg\{ -\frac{1}{2} \begin{bmatrix} (x - \mu_{x \mid y}) \\(y - \mu_y)  \end{bmatrix}^T \begin{bmatrix} \Sigma_{x \mid y}^{-1} & 0 \\ 0 &  \Sigma_y^{-1}  \end{bmatrix} \begin{bmatrix} (x - \mu_{x \mid y}) \\ (y - \mu_y)  \end{bmatrix} \Bigg\} %]]></script>

<p>We want to show that the exponent becomes:</p>

<script type="math/tex; mode=display">\begin{bmatrix}
(x - \mu_{x \mid y}) \Sigma_{x \mid y}^{-1} \\
(y - \mu_y)  \Sigma_y^{-1} 
\end{bmatrix}\begin{bmatrix} (x - \mu_{x \mid y}) \\ (y - \mu_y)  \end{bmatrix}</script>

<p>We have 3 matrices multiplied together</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}   \\ (y - \mu_y)  \end{bmatrix}     \begin{bmatrix} & 0 \\ 0 & \Sigma_y^{-1} \end{bmatrix}     \begin{bmatrix}  x - \mu_x - \Sigma_{XY} \Sigma_Y^{-1} (y-\mu_y) \\ (y - \mu_y) \end{bmatrix} %]]></script>

<p>Notice that</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix} x - \mu_x - \Sigma_{XY} \Sigma_Y^{-1} (y-\mu_y) \\ (y - \mu_y) \end{bmatrix} = \begin{bmatrix} I & -\Sigma_{XY} \Sigma_Y^{-1} \\ 0 & I \end{bmatrix} \begin{bmatrix} (x- \mu_x) \\ (y - \mu_y) \end{bmatrix} %]]></script>

<p>Now we go from</p>

<script type="math/tex; mode=display">% <![CDATA[
= \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix}^T \begin{bmatrix} I & 0 \\  -\Sigma_Y^{-1}\Sigma_{YX} & I \end{bmatrix} \begin{bmatrix} \Bigg( \Sigma_{x} - \Sigma_{xy} \Sigma_{y}^{-1}  \Sigma_{yx}\Bigg)^{-1}  & 0 \\ 0 & \Sigma_{y}^{-1} \end{bmatrix} \begin{bmatrix} I & -\Sigma_{XY} \Sigma_Y^{-1} \\ 0 & I \end{bmatrix} \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix} %]]></script>

<p>to</p>

<p>Since <script type="math/tex">LD^{-1}U = \Sigma^{-1}</script> \</p>

<p><script type="math/tex">D^{-1} = L^{-1}\Sigma^{-1} U^{-1}</script> \</p>

<p>Triangular matrix: eigenvalues on diagonal. Here eigenvalues are all along diagonal, and are all 1, so this must be invertible.</p>

<p><script type="math/tex">D = U \Sigma L</script> \</p>

<script type="math/tex; mode=display">\iff p(x \mid y) p(y) = p(x,y)</script>

<script type="math/tex; mode=display">% <![CDATA[
= \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix}^T  \begin{bmatrix} \Sigma_{x} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{y} \end{bmatrix}^{-1} \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix} =   \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix}^T  \Sigma^{-1} \begin{bmatrix} (x-\mu_x) \\ (y-\mu_y) \end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\Sigma L = 
\begin{bmatrix} \Sigma_{x} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{y} \end{bmatrix} \begin{bmatrix} I & 0 \\  -\Sigma_Y^{-1}\Sigma_{YX} & I \end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
U \Sigma L = \begin{bmatrix} I & -\Sigma_{xy} \Sigma_{y}^{-1} \\ 0 & I \end{bmatrix} \begin{bmatrix} \Sigma_{x \mid y} & \Sigma_{xy} \\ 0 & \Sigma_y \end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}  \end{bmatrix} \begin{bmatrix} \end{bmatrix} = \begin{bmatrix} \Sigma_{x \mid y} & 0 \\ 0 & \Sigma_{y} \end{bmatrix} = D %]]></script>

<h2 id="gaussian-estimation-bayes-rule-for-gaussian-rvs-and-recursive-gaussian-estimation-bayesian-estimation-for-gaussian-rvs">Gaussian Estimation (Bayes’ Rule for Gaussian R.V.s) and Recursive Gaussian Estimation (Bayesian Estimation for Gaussian R.V.s)</h2>

<p>For the constants
\begin{equation}
\eta_{x \mid y} \eta_y  = \eta_{xy}
\end{equation}</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{lll}
\eta_y = \frac{1}{\sqrt{(2\pi)^m |\Sigma_y|}}, & \eta_{x \mid y} = \frac{1}{\sqrt{(2\pi)^n |\Sigma_{x \mid y}|}}, & \eta_{xy} = \frac{1}{\sqrt{(2\pi)^{n+m} |\Sigma|}},
\end{array} %]]></script>

<p>where <script type="math/tex">Y \in \mathbb{R}^m, X \in \mathbb{R}^n, (X,Y) \in \mathbb{R}^{n+m}</script></p>

<p>Determinant Identities:
\begin{equation}
|A B| = |A| |B|
\end{equation}</p>

<script type="math/tex; mode=display">% <![CDATA[
|\begin{bmatrix} A & 0 \\ 0 & B \end{bmatrix}| = |A| |B| %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
| \begin{bmatrix} I & 0 \\ A & I \end{bmatrix} | = \begin{bmatrix} I & A \\ 0 & I \end{bmatrix} | = 1 %]]></script>

<p>We hope to find that</p>

<p>\begin{equation}
\eta_{x \mid y}\eta_y = \frac{1}{(2\pi)^{m/2}(2\pi)^{n/2} |\Sigma_y|^{1/2} |\Sigma_{x \mid y}|^{1/2} } =  \frac{1}{(2\pi)^{ \frac{m+n}{2} }|\Sigma|^{1/2} }
\end{equation}</p>

<p>Now we use the fact that
\begin{equation}
D = U \Sigma L 
\end{equation}
and we define
\begin{equation}
D = \begin{bmatrix} \Sigma_{x \mid y} &amp; 0 \ 0 &amp; \Sigma_y  \end{bmatrix}
\end{equation}</p>

<p>By independence,
\begin{equation}
\begin{aligned}
p(y) = \int_x p(x,y) dx <br />
\int_x \tilde{p}(x \mid y) \tilde{p}(y) dx <br />
\int_x \tilde{p}(x \mid y) dx \tilde{p}(y) <br />
= \tilde{p}(y)
\end{aligned}
\end{equation}</p>

<p>We recall that a conditional multivariate Gaussian distribution <script type="math/tex">X \mid Y</script> has a pdf parameterized as follows:</p>

<p>\begin{equation}
p(x \mid y) = \mathcal{N}(\mu_{x\mid y}, \Sigma_{x \mid y}) = \mathcal{N} \Bigg(\mu_x + \Sigma_{xy}\Sigma_{yy}^{-1}(y-\mu_y),  \Sigma_{xx} - \Sigma_{xy} \Sigma_{yy}^{-1}\Sigma_{yx} \Bigg)
\end{equation}
$\mu_x, \Sigma_x$ are the priors.</p>

<p>if <script type="math/tex">\Sigma_y</script> is small, then inverse is huge, reduce uncertainty a lot…
\item Measurement reduces uncertainty in <script type="math/tex">X</script> proportionally to <script type="math/tex">\Sigma_y^{-1}</script></p>

<p>Never do worse than your prior – even crappy measurement is good. Shrink error ellipsoid as you get a measurement. We trust it by amount weighted by inverse of our confidence in the measurement. Mostly keep prior if high amount of uncertainty (so add very little, because <script type="math/tex">\Sigma^{-1}</script> is small). Not realistic to know the joint distribution:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{ll}
\Sigma  = \begin{bmatrix} \Sigma_x & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_y  \end{bmatrix}, \mu = \begin{bmatrix} \mu_x \\ \mu_y \end{bmatrix}
\end{array} %]]></script>

<p>Bayes Rule says:</p>

<p>\begin{equation}
p(x \mid y) = \frac{p(y \mid x) p(x)}{ \int_x p(y \mid x)p(x) dx}
\end{equation}
We do know
\begin{equation}
\begin{array}{ll}
\Sigma_{y \mid x}, &amp; \mu_{y \mid x}
\end{array}
\end{equation}</p>

<p>where
\begin{equation}
p(y \mid x) = \mathcal{N}( \mu_{y \mid x}, \Sigma_{y \mid x})
\end{equation}
\item Definition:
\begin{equation}
(X,Y) \sim \mathcal{N}(\mu, \Sigma)
\end{equation}</p>

<p>Theorem: <script type="math/tex">(X,Y)</script> are jointly Gaussian iff <script type="math/tex">\exists C,M</script> and r.v. <script type="math/tex">V,N</script> such that
\begin{equation}
\begin{array}{ll}
Y = CX + V, &amp; X = MY + N
\end{array}
\end{equation}
where <script type="math/tex">C \in \mathbb{R}^{m \times n}</script> and <script type="math/tex">M \in \mathbb{R}^{n \times m}</script>
\begin{equation}
\begin{aligned}
V \sim \mathcal{N}(\mu_v, R) <br />
N \sim \mathcal{N}(\mu_N, \Sigma_N) <br />
Cov(X,V) = 0 <br />
Cov(Y,N) = 0
\end{aligned}
\end{equation}</p>

<p>Gaussian property is deeply linked to linearity!</p>

<p>Projection of vectors onto different directions (Gaussian random variable can be projected)</p>

<p>Project <script type="math/tex">Y</script> into the direction of $X$ (this is what $CX$ does)</p>

<p><script type="math/tex">V</script> is the leftover part of $Y$ that is orthogonal to $X$</p>

<p>Orthogonality of Gaussian R.V.s: covariance is zero. No way to use one to predict the other (can derive formally as inner product in vector space)</p>

<h2 id="linear-control-systems">Linear Control Systems</h2>

<p>\begin{equation}
\begin{aligned}
\dot{x} = Ax + Bu <br />
y = Cx + Du
\end{aligned}
\end{equation}</p>

<p>We use the discrete-timve version in this class, not the continuous form</p>

<p>\begin{equation}
\begin{aligned}
x_{t+1} = Ax_t + _ + w_t \ 
y_t = Cx_t + _ + v_t
\end{aligned}
\end{equation}
where $w_t, v_t$ are noise
\item Expectation is a linear operator: $Y=CX + V$</p>

<p>\item mean:
\begin{equation}
\mu_y = E[Y] = \int_y y \mbox{ } p(y) dy
\end{equation}
where $Y \in \mathbb{R}^n, \mu_y \in \mathbb{R}^n$</p>

<p>\item Covariance:
\begin{equation}
\Sigma_y = E[(Y-\mu_y)(Y-\mu_y)^T] = \int_y (y-\mu_y)(y-\mu_y)^T p(y) dy
\end{equation}
\item</p>

<p>\begin{equation}
\begin{aligned}
\mathbb{E}[Y] = \mathbb{E}[CX+V] <br />
 = \int_{x,v}(Cx+ v) p(x,v) dx dv <br />
 = \int_{x,v} Cx \mbox{ } p(x,v) dx dv + \int_{x,v}v \mbox{ } p(x,v) dx dv <br />
 = C \int_{x,v} x \mbox{ } p(x,v) dx dv + \int_{x,v} v \mbox{ } p(x,v) dx dv <br />
= C \mathbb{E}[X] + \mathbb{E}[V]
\end{aligned}
\end{equation}
so we have shown that $\mu_y = C \mu_x + \mu_v$. $\mu_x$ is a known prior. $C$ is known (from the measruement model), and $\mu_v$ is also known (from the measurement model)
\item</p>

<p>We can do this because 
\begin{equation}
\begin{aligned}
\int_v v \Bigg( \int_x p(x,v) dx \Bigg) dv
\int_v v \mbox{ } p(v) dv \ 
= \mathbb{E}[V]
\end{aligned}
\end{equation}
\item Take that $Y = CX + V$: 
\begin{equation}
\begin{aligned}
\Sigma_y = Cov(Y) = \mathbb{E}[(Y-\mu_y)(Y-\mu_y)^T] <br />
= \mathbb{E}[((CX + V)-\mu_y)((CX + V)-\mu_y)^T] <br />
 = \mathbb{E}[((CX + V)- (C \mu_x + \mu_v) )((CX + V)- (C \mu_x + \mu_v) )^T]  <br />
 confusing outer product step <br />
  = \mathbb{E}[(V - \mu_v )(CX - C \mu_x)^T ] + \mathbb{E}[(V - \mu_v )(V - \mu_v)^T ]  <br />
  = \mathbb{E}[ C(X - \mu_x )(X - \mu_x)^T C^T] +  + \mathbb{E}[(V - \mu_v )(X - \mu_x)^T C^T ]  + \mathbb{E}[(V- \mu_v)(V- \mu_y)^T] 
\end{aligned}
\end{equation}
We know $Cov(V) = \Sigma_v = R$, the measurement noise covariance
\item The covaraince of the prior is known
\begin{equation}
\begin{aligned}
Cov(X) = \Sigma_x <br />
 = C \mathbb{E}[(X-\mu_x)(X - \mu_x)^T]C^T \</p>
<ul>
  <li>C \mathbb{E}[(X-\mu_x)(V - \mu_v)^T] \</li>
  <li>\mathbb{E}[(V-\mu_v)(X - \mu_x)^T]C^T + R <br />
\end{aligned}
\end{equation}
where $Cov(V,X) = \Sigma_{vx}$
\item So we find
\begin{equation}
\Sigma_y = C \Sigma_x C^T + C \Sigma_{xv} + \Sigma_{vx} C^T + R
\end{equation}
covariances are zero $Cov(X,V) = 0$, so we get</li>
</ul>

<p>\begin{equation}
\Sigma_y = C \Sigma_x C^T + R
\end{equation}
where $\Sigma_x$ is the prior covaraince, and the other threee terms $C,C^T,R$ are known from the measurement model
\item so we find for</p>

<p>\begin{equation}
\begin{aligned}
 \Sigma_{xy} = \mathbb{E}[(X-\mu_x)(Y - \mu_y)^T] <br />
 = \mathbb{E}[(X-\mu_x)(CX+V - C\mu_x -\mu_v) ] <br />
 =   \mathbb{E}[(X-\mu_x)(X - \mu_x)^T]C^T + \mathbb{E}[(X-\mu_x)(V-\mu_v)] <br />
 \Sigma_{xy} = \Sigma_x C^T + \Sigma_{xv} 
\end{aligned}
\end{equation}</p>

<p>for <script type="math/tex">(X,Y)</script> jointly Gaussian <script type="math/tex">\Sigma{xv} = 0</script>, we have
\begin{equation}
\Sigma_{xy} = \Sigma_x C^T
\end{equation}</p>

<h2 id="bayes-rule-for-jointly-gaussian-random-vectors">Bayes Rule for Jointly Gaussian Random Vectors</h2>

<p>\begin{equation}
\mu_{x \mid y} = \mu_x + \Sigma_X C^T \Bigg( C \Sigma_x C^T + R)^{-1} (y - [C \mu_x + \mu_v] \Bigg)
\end{equation}
and 
\begin{equation}
\Sigma_{X \mid Y}  = \Sigma_X - \Sigma_X C^T \Bigg( C \Sigma_x C^T + R\Bigg)^{-1} C \Sigma_x
\end{equation}</p>

<p>\item find out $C$ by shaking around sensor (accelerometer). This is a model of our sensor. We could get it in the lab. We could get the measurement likelihood model from the following equation:
\begin{equation}
Y = CX + V
\end{equation}
with $V \sim \mathcal{N}(\mu_v, R)$ and $Cov(X,V) = 0$ 
\item This is equivalent to $p(y \mid x)$, the measurement likelihood
\item $Y=CX+V$ is guaranteed because these two variables are JOINTLY gaussian. Can see this as a projection
\item We know prior: $(\mu_x, \Sigma_x)$
\item From the measurement equation, we know $C, \mu_v, R$</p>

<h2 id="kalman-filters">Kalman Filters</h2>

<p>What is the connection between <script type="math/tex">Y=CX+V</script> and <script type="math/tex">p(y \mid x)</script>?</p>

<script type="math/tex; mode=display">p(y \mid x) \sim \mathcal{N}(\mu_{y \mid x}, \Sigma_{y \mid x})</script>

<script type="math/tex; mode=display">\begin{aligned}
\mu_{y \mid x } = \mathbb{E}[Y \mid X=x] \\= \mathbb{E}[CX + V \mid X=x] \\= \mathbb{E}[CX \mid X=x] + \mathbb{E}[V \mid X=x]  \\=  \mathbb{E}[CX \mid X=x] + \mathbb{E}[V ]  \\
\mu_{y \mid x } = Cx + \mu_v
\end{aligned}</script>

<p>because uncorrelated means independent for Gaussians</p>

<p><script type="math/tex">\begin{aligned}
\Sigma_{Y \mid X} = \mathbb{E}\Bigg[ (Y-\mu_{y \mid x}) (Y-\mu_{y \mid x})^T \mid X=x \Bigg] \\
= \mathbb{E}\Bigg[ (CX+V-\mu_{y \mid x}) (CX+V-\mu_{y \mid x})^T  \mid X=x \Bigg] \\
= \mathbb{E}\Bigg[ (CX+V-Cx - \mu_v) (CX+V-CX - \mu_v )^T  \mid X=x \Bigg] \\
= R
\end{aligned}</script>
So measurement equation encodes the measurement likelihood</p>

<p>When given <script type="math/tex">x</script>, so lock down in <script type="math/tex">p(y \mid x)</script>, all randomness comes from noise <script type="math/tex">V</script></p>

<p>Since <script type="math/tex">(X,Y) \sim \mathcal{N}(\mu, \Sigma)</script>, then <script type="math/tex">\exists M \in \mathbb{R}^{n \times n}, N \sim \mathcal{N}(\mu_N, \Sigma_N)</script> s.t.
\begin{equation}
\begin{array}{ll}
X = MY + N, &amp; Cov(Y,N) = 0
\end{array}
\end{equation}</p>

<p>We don’t know these things though! But the equation is still valid. Linear in <script type="math/tex">Y</script>, with the following <script type="math/tex">M</script></p>

<p>Why not compute
\begin{equation}
p(x \mid y) = \mathcal{N}\Big(  \mu_{x \mid y}, \Sigma_{x \mid y}\Big)
\end{equation}
where $M = \Sigma_x C^T (C \Sigma_x C^T + R)^{-1}$</p>

<p>where $\mu+N$ is
\begin{equation}
\mu_N  = \mu_x - (\Sigma_x \cdots) (C \mu_x - \mu_v)
\end{equation}
and
\begin{equation}
\Sigma_{x \mid y} = \Sigma_N
\end{equation}
and $\mu_{x \mid y} = My + \mu_N$</p>

<h2 id="recursive-bayesian-estimation-from-jointly-gaussian-rvs-with-conditionally-independent-measurements-treat-output-as-input-to-next-time-step">Recursive Bayesian Estimation from Jointly Gaussian R.V.s with conditionally independent measurements, Treat Output as Input to next time step</h2>

<p>Naive Bayes model of measurements</p>

<p>\begin{equation}
\mu_{x \mid y_{1:t} } = \mu_{x \mid y_{1:t-1} } + \Sigma_{x  \mid y_{1:t-1}} C^T (C \Sigma_{X \mid Y_{1:t-1}} C^T + R)^{-1} \Bigg( y_t - ( C \mu_{x \mid y_{1:t-1}} + \mu_v) \Bigg)
\end{equation}
\item 
\begin{equation}
\Sigma_{X \mid Y_{1:t} }  = \Sigma_{X \mid Y_{1:t-1} } - \Sigma_{X \mid Y_{1:t-1} } C^T \Bigg( C \Sigma_{X \mid Y_{1:t-1} } C^T + R\Bigg)^{-1} C \Sigma_{X \mid Y_{1:t-1} }
\end{equation}
\item Fuse uncertainty in the correct way
\item Covariance should always decrease (but it is a matrix)
\item For a matrix to decrease, we mean that the differencew between the matrix is definite (negative or positive definite)
\item To decrease – expect difference to be positive semidefinite
\begin{equation}
(\Sigma_{x \mid Y_{1:t-1}} - \Sigma_{x \mid y_{1:t}}) \geq 0
\end{equation}</p>

<p>Measurements have to be conditionally independent. Suppose each measurement has a corresponding equation:
\begin{equation}
Y_t = C_t X + V_t
\end{equation}</p>

<p>We can stack all of the measurements into one block, as follows
\begin{equation}
\begin{bmatrix}
Y_1 \ \vdots \ Y_t
\end{bmatrix} = \begin{bmatrix} C_1 \ \vdots \ C_t  \end{bmatrix} X + \begin{bmatrix}  V_1 \ \vdots \ V_t \end{bmatrix}
\end{equation}</p>

<p>Being able to break up the measurements is special</p>

<p>Consider two measurments at <script type="math/tex">Y_t, Y_{\tau}</script>. We wish to compute
\begin{equation}
Cov(Y_t, Y_{\tau} \mid X)
\end{equation}
\item We already know that
\begin{equation}
\begin{aligned}
\mu_{Y_t \mid x} = C_t X + \mu_{v_t} <br />
\mu_{Y_{\tau} \mid x} = C_{\tau} X + \mu_{v_{\tau}} <br />
\end{aligned}
\end{equation}
Conditional covariance</p>

<p>\begin{equation}
Cov(Y_t, Y_{\tau} \mid X) = \mathbb{E}\Bigg[ (Y_t - \mu_{Y_t \mid x})(Y_{\tau} - \mu_{Y_{\tau} \mid x})^T \mid X \Bigg]
\end{equation}</p>

<p>\begin{equation}
Cov(Y_t, Y_{\tau} \mid X) = \mathbb{E}\Bigg[ (Y_t - C_t X - \mu_{v_t})(Y_{\tau} -  C_{\tau} X - \mu_{v_{\tau}})^T \mid X \Bigg]
\end{equation}</p>

<p>With the definition of $Y_t, Y_{\tau}$:
\begin{equation}
Cov(Y_t, Y_{\tau} \mid X) = \mathbb{E}\Bigg[ (C_t X + V_t - C_t X - \mu_{v_t})( C_{\tau} X + V_{\tau} -  C_{\tau} X - \mu_{v_{\tau}})^T \mid X \Bigg]
\end{equation}
Canceling terms
\begin{equation}
Cov(Y_t, Y_{\tau} \mid X) = \mathbb{E}\Bigg[ ( V_t - \mu_{v_t})( V_{\tau} -   \mu_{v_{\tau}})^T \mid X \Bigg]
\end{equation}
And conditionally independent of $X$ because WHY???
\begin{equation}
Cov(Y_t, Y_{\tau} \mid X) = \mathbb{E}\Bigg[ ( V_t - \mu_{v_t})( V_{\tau} -   \mu_{v_{\tau}})^T  \Bigg]
\end{equation}</p>

<p>Uncorrelated measurement noise! 
\item White noise: sequence of measurements $(v_1, v_2, \dots, v_t)$ s.t. $Cov(v_t, v_{\tau} = 0, \forall t \neq \tau$
\end{itemize}</p>

<h2 id="gaussian-white-noise-process">Gaussian White Noise Process</h2>

<p>\begin{equation}
\begin{aligned}
V_t \sim GWP(\mu_{v_t}, R_t) <br />
V_t \sim \mathcal{N}( \mu_{v_t}, R_t) <br />
Cov(V_t, V_{\tau}) = 0
\end{aligned}
\end{equation}</p>

<p>Flipping around – white noise process, knowing all of the previous noise, won’t help you predict anything in the future</p>

<p>Otherwise, get Delta Dirac Function, with R at <script type="math/tex">t-\tau=0</script>. We hope coloring is very small, compared to the other dynamics in your process (coloring looks like a Laplacian distribution). We hope to put as much of the sensor into the state as possible
\item White noise: sucked out everything from the sensor measurement that relates to the thing that you are measuring
\item White noise in measurment is essential to enforcing the conditional independence assumption!!! To use a linear estimator with a constant state…????
\end{itemize}
\subsection{Kalman Filter}
\begin{itemize}
\item Bayeisan filter from Linear-Gaussian system, with Markov prooperty and conditionally independent measurements
\item Linear-Gausssian state-space system
\item By the dynamics equation,
\begin{equation}
X_{t+1} = A_t x_t + B u_t + W_t
\end{equation}
By the measurement equation,
\begin{equation}
Y_t = C_t X_t + D_t u_t + V_t
\end{equation}
\item $V_t \sim GWP(0, R_t)$
\item Where $D_tu_t = \mu_v$, the mean of our \textbf{sensor noise}
\item We also need our \textbf{process noise} to be white:
\begin{equation}
W_t \sim GWP(0, Q_t)
\end{equation}
\item And uncorrelated with the initial state:
\begin{equation}
\begin{aligned}
Cov(X_0, V_t) = 0, \forall t<br />
Cov(x_0, W_t) = 0, \forall t<br />
Cov(w_t,v_{\tau}) = 0, \forall \tau,t
\end{aligned}
\end{equation}
I.C.
\begin{equation}
X_0 \sim \mathcal{N}(\mu_0,\Sigma_0)
\end{equation}
Must be HMM undirected model, which gives us two kinds of conditional independence: <br />
(1) Markov -  $p(x_{t+1} \mid x_t, x_{0:t-1},y_{1:t}) = p(x_{t+1} \mid x_t)$ <br />
(2) Cond. Independence of Measurment – 
\begin{equation}
p(y_t \mid x_{0:t},y_{1:t-1}) = p(y_t \mid x_t)
\end{equation}</p>

<p>\end{itemize}
\subsection{Kalman Filter Equations}
\begin{itemize}
\item Notation:</p>

<p>\begin{equation}
\begin{aligned}
\mu_{t \mid t} = \mathbb{E}[X_t \mid Y_{1:t}] <br />
\Sigma_{t \mid t} = Cov(X_t \mid Y_{1:t}) <br />
\mu_{t \mid t-1} = \mathbb{E}[X_t \mid Y_{1:t-1}] <br />
\Sigma_{t \mid t-1} = Cov(X_t \mid Y_{1:t-1})
\end{aligned}
\end{equation}</p>

<p>Predict Step:</p>

<p>\begin{equation}
\begin{aligned}
\mu_{t \mid t-1} = A_{t-1} \mu_{t-1 \mid t-1} + B_{t-1} u_{t-1} <br />
\Sigma_{t \mid t-1} = A_{t-1} \Sigma_{t-1 \mid t-1} A_{t-1}^T + Q_{t-1}
\end{aligned}
\end{equation}</p>

<p>Update Step:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\mu_{t \mid t} &= \mu_{t \mid t-1} + \Sigma_{t \mid t-1} C_t^T (C_t \Sigma_{t \mid t-1} C_t^T + R_t)^{-1} \Bigg( y_t - (C_t \mu_{t \mid t-1} + D_t u_{t}) \Bigg) \\
\Sigma_{t \mid t} &= \Sigma_{t \mid t-1}  - \Sigma_{t \mid t-1} C_t^T\Bigg(C_t \Sigma_{t \mid t-1} C_t^T + R_t \Bigg)^{-1} C_t \Sigma_{t \mid t-1}
\end{aligned} %]]></script>

<h2 id="kalman-filter-continued">Kalman Filter Continued</h2>

<p>Find a model for <script type="math/tex">X_{t+1} = f(X_{0:t}, Y_{1:t})</script> and find requirements on <script type="math/tex">f(\cdot)</script> s.t. Markov
\begin{equation}
(X_{0:t+1},Y_{1:t}) \sim \mathcal{N}(\mu, \Sigma)
\end{equation}
where
\begin{equation}
(X,Y) \sim \mathcal{N} \
\end{equation}
where</p>

<p>\begin{equation}
\begin{array}{ll}
Y = CX + V, &amp; Cov(X,V) = 0
\end{array}
\end{equation}</p>

<p>We write equations to slice a vector into pieces</p>

<p>\begin{equation}
\begin{aligned}
X_{t+1} = M(X_{0:t},Y_{1:t}) + W_t <br />
X_{t+1} = A_tX_t + \sum\limits_{\tau=0}^{t-1}\Phi_{\tau}X_{\tau} + \sum\limits_{\tau=0}^t \theta_{\tau} Y_{\tau}  + W_t
\end{aligned}
\end{equation}</p>

<p>where we</p>

<p>\begin{equation}
\begin{aligned}
Cov(X_{\tau}, W_t) = 0, \forall \tau \leq t <br />
Cov(Y_{\tau}, W_t) = 0, \forall \tau \leq t <br />
\end{aligned}
\end{equation}</p>

<p>By Markov Property, the rest of the matrices must be zero!
\begin{equation}
\mathbb{E}\Bigg[ X_{t+1} \mid X_t, X_{0:t-1}, Y_{1:t}\Bigg] = \mathbb{E}[X_{t+1} \mid X_t]
\end{equation}</p>

<p>So all of the terms in the sum that involve <script type="math/tex">\Phi_{\tau}=0 \forall \tau \leq t-1</script> and also <script type="math/tex">\Theta_{\tau} = 0, \forall \tau \leq t</script>
must equal zero</p>

<p>\begin{equation}
\begin{aligned}
X_{t+1} = A_tX_t + W_t <br />
Cov(X_{\tau},W_t) = 0, \forall \tau \leq t, <br />
Cov( Y_{\tau}, W_t) = 0, \forall \tau \leq t
\end{aligned}
\end{equation}</p>

<p>Now we can nest things, apply the recursion once backwards
\begin{equation}
\begin{aligned}
X_{t+1} = A_tX_t + W_t <br />
X_{t+1} = A_t (A_{t-1} X_{t-1} + W_{t-1}) + W_t<br />
X_{t+1} = A_t (A_{t-1} (A_{t-2} X_t W_t) + W_t) + W_t<br />
X_{t+1} =\Big( A_t A_{t-1} A_{t-2}\Big) X_{t-2} + ( A_t (A_{t-1} \Big(A_{t-2})W_{t-2}\Bigg) + W_t\Big) + A_tW_{t-1}) + W_t<br />
X_{t+1} = \Bigg( \prod\limits_{\tau=0}^t A_{\tau}  \Bigg)X_0 + \sum\limits_{\tau=1}^t  (\prod\limits_{i=\tau}^t A_i) W_{\tau-1} + W_t <br />
X_{t+1} = X_{t+1}(X_0, W_{0:t})
\end{aligned}
\end{equation}
deterministically
\begin{equation}
X_{\tau}(X_0, W_{0:\tau-1})
\end{equation}
As long as noise is independent that everything that $X_{\tau}$ depends on, then it will be independent of $X_{\tau}$.</p>

<p>We call Gaussian white noise process.</p>

<p>Projection onto another:
\begin{equation}
\begin{aligned}
Y_t = C_tX_t + \sum\limits_{\tau=0}^{t-1}\Psi_{\tau}X_{\tau} + \sum\limits_{\tau=0}^t \Xi_{\tau} Y_{\tau}  + V_t
\end{aligned}
\end{equation}</p>

<p>We want conditionally independent measurements. So all terms involving $\Psi_{\tau}, \Xi_{\tau}$ are zero.</p>

<p>\begin{equation}
\begin{aligned}
Y_t = C_tX_t + V_t <br />
Cov(X_{\tau}, V_t) = 0, \forall \tau \leq t<br />
Cov(Y_{\tau}, V_t) = 0, \forall \tau &lt; t
\end{aligned}
\end{equation}
We recall that $X_{\tau}(X_0, W_{0:\tau-1})$.<br />
Since $Y_t = C_tX_t + V_t \implies Y_{\tau}(X_0, W_{0:\tau-1}, V_{\tau})$.</p>

<p>\end{itemize}
\subsection{To fulfill the other Covariance=0 reqs}
\begin{itemize}
\item If $Cov(X_{\tau}, V_t) = 0, \forall \tau \leq t$, then $\implies$:<br />
\begin{equation}
\begin{aligned}
Cov() =  <br />
Cov() = 
\end{aligned}
\end{equation}</p>

<p>So we have white noise. We just derived the dynamics equaiton (without the input $B_tu_t$ term). These where the dirty details of the linear Gaussian model.</p>

<p>\end{itemize}
\subsection{Next Steps}
\begin{itemize}
\item Bayesian Filter, but in Gaussian step. Basic rules to update $\mu, \Sigma$. <br />
Predict:
\begin{equation}
p(x_{t+1} | y_{1:t})  \sim \mathcal{N}(\mu_{t+1 \mid t}, \Sigma_{t+1 \mid t})
\end{equation}
Now, the mean:
\begin{equation}
\mu_{t+1 \mid t} = \mathbb{E}[ X_{t+1} \mid Y_{1:t}] = \mathbb{E}[A_tX_t + W_t \mid Y_{1:t}]
\end{equation}
which is 
\begin{equation}
=A_t \mathbb{E}[X_t \mid Y_{1:t}] + \mathbb{E}[W_t \mid Y_{1:t}]
\end{equation}
where the first term is $\mu_{t \mid t}$, and the second term is $\mathbb{E}[W_t]$.</p>

<p>And we know that $Cov(Y_{\tau}, W_t) = 0, \forall \tau \leq t$.</p>

<p>This noise has a mean! 
\begin{equation}
\mathbb{E}[\tilde{w}<em>t] = \mu</em>{w_t} = B_t u_t
\end{equation}
We define
\begin{equation}
w_t = \tilde{w_t} - B_tu_t
\end{equation}
where
\begin{equation}
w_t \sim \mathcal{N}(0, Q_t)
\end{equation}
What have we shown, we have shown VERY IMPORTANT
\begin{equation}
\mu_{t+1 \mid t} = A_t \mu_{t \mid t} + B_t u_t
\end{equation}</p>

<p>\end{itemize}
\subsection{Now for the covariance}
\begin{itemize}
\item  Control input does not show up in error covariance</p>

<p>\begin{equation}
\Sigma_{t+1 \mid t} = \mathbb{E}[ (X_{t+1} - \mu_{t+1 \mid t}) (X_{t+1} - \mu_{t+1 \mid t}) \mid Y_{1:t}]
\end{equation}
Pluggin in $X_{t+1} = A_tX_t + B u_t + W_t $ definition, and that $\mu_{t+1 \mid t} = A_t \mu_{t \mid t} + B_tu_t$, we can see
\begin{equation}
\Sigma_{t+1 \mid t} = \mathbb{E}[ ( A_tX_t + B u_t + W_t  - (A_t \mu_{t \mid t} + B_tu_t) ) ( A_tX_t + B u_t + W_t - (A_t \mu_{t \mid t} + B_tu_t) ) \mid Y_{1:t}]
\end{equation}
the $B u_t$’s cancel, so we have\</p>

<p>TYPE UP THE REST FROM THE PHOTO\</p>

<p>Leveraging conditional independences, we have shown in the problem set that
\begin{equation}
\mathbb{E}[ (X_t - \mu_{t \mid t}) W_t^T \mid Y_{1:t}] = 0
\end{equation}
We end up with the very important EQUATION
\begin{equation}
\Sigma_{t+1 \mid t} = A_t \Sigma_{t \mid t} A_t^T + Q_t
\end{equation}</p>

<h2 id="update-step-for-kf">Update Step for KF</h2>
<p>We remember</p>

<p>\begin{equation}
p(x_t \mid y_{1:t})   = \frac{ p(y_t \mid x_t) p(x_t \mid y_{1: t-1}) }{\int_{x_t} \cdots dx_t}
\end{equation}</p>

<p>ADD THE NOTES FROM THE PICTURE I TOOK\</p>

<p>The expected value of <script type="math/tex">Y</script>, given previous, is</p>

<p>\begin{equation}
\hat{y}<em>{t \mid t-1} = \mathbb{E}[Y_t \mid Y</em>{1:t-1}] = \mathbb{E}[C_tX_t + D_t u_t \mid Y_{1:t-1}] = 
\end{equation}
So we subtract this out, <script type="math/tex">(y - \hat{y}_{t \mid t-1} )</script>.</p>

<p>\item You predicted your mean, so try to correct now! Here is what we thought the measurement should have been! The innovation is the disagreement between the two. This is the innovation process.</p>

<p>The Kalman Gain! is what you add on.</p>

<h2 id="kalman-and-ekf">Kalman and EKF</h2>

<p>In the Kalman Filter, need to be given initial <script type="math/tex">\mu_{0 \mid 0}, \Sigma_{0 \mid 0}</script>, where <script type="math/tex">X_0 \sim \mathcal{N}(\mu_{0 \mid 0}, \Sigma_{0 \mid 0}</script></p>

<p>By the dynamics equation,</p>

<p>\begin{equation}
X_{t+1} = A_t x_t + B u_t + W_t
\end{equation}</p>

<p>By the measurement equation,</p>

<p>\begin{equation}
Y_t = C_t X_t + D_t u_t + V_t
\end{equation}</p>

<p>Almost always, <script type="math/tex">D_t = 0</script> so that you don’t mix up your actuators and your sensors
\item E.g. single integrator particle
\item If you have a filter, you have to stop the filter somewhere, and the computation begins
\item Manually discretize the dynamics, being aware that we ARE GOING AWAY FROM PHYSICS, INTO COMPUTATION
\item dynamics: <script type="math/tex">\dot{x} = u</script>
\item measurement: <script type="math/tex">y = x</script>
\item First order Euler discretization. Assume rate of change is constant</p>

<p>\begin{equation}
x_{t+1} = x_t + \delta t u_t
\end{equation}</p>

<p>where <script type="math/tex">\delta t = 1</script>
Works for relatively well behaved dynamics. We introduce some noise:</p>

<p>\begin{equation}
\begin{aligned}
x_{t+1} = x_t + u_t <br />
y_t = x_t
\end{aligned}
\end{equation}</p>

<p>Process noise</p>

<p>\begin{equation}
\begin{aligned}
W_t \sim \mathcal{N}(0,1), process_ noise <br />
V_t \sim \mathcal{N}(0,1), measurement_ noise
\end{aligned}
\end{equation}</p>

<p>\item I.C. $X_0 \sim \mathcal{N}(0,1)$
\item Linear Gaussian System:
\begin{equation}
\begin{aligned}
X_{t+1} = X_t + u_t + W_t<br />
Y_t = X_t + V_t
\end{aligned}
\end{equation}</p>

<p>\item K.F. says
\begin{equation}
\begin{aligned}
\mu_{t+1 \mid t} = \mu_{t \mid t} + u_t <br />
\mu_{t\mid t} = \mu_{t \mid t-1} + \Sigma_{t \mid t-1} ( \Sigma_{t \mid t-1})^{-1} (y_t - \mu_{t \mid t-1})
\end{aligned}
\end{equation}
\item $\mu$ will bounce around in a noisy fashion
\item Covariance are completely independent from the specific data acquired by the system. Can solve for it offline. Know how confident you will be, without having taken any data (Not true for EKF or UKF, just for linear system) 
\item Very weird property! Just baked into the linearity of the model
\item Covariance tells you how confident you are
\item If covaraince is huge, crappy estimate
\item Often as interested in covaraince, as you are in the mean</p>

<p>\item Consider example:</p>

<p>\begin{equation}
\begin{aligned}
A_t = 1, B_t = 1, Q_T = 1 <br />
C_t = 1, D_t = 0, R_t = 1
\end{aligned}
\end{equation}
\item Evolution of $\Sigma_{t \mid t}$:
\begin{equation}
\Sigma_{t \mid t} = \Sigma_{t \mid t-1 } -\Sigma_{t \mid t -1} ( \Sigma_{t \mid t-1} + 1)^{-1} \Sigma_{t \mid t-1}
\end{equation}</p>

<p>\item Here the state is a scalar, so $\Sigma$ is a scalar
\begin{equation}
\Sigma_{t \mid t} = \frac{\Sigma_{t \mid t -1} ( \Sigma_{t \mid t -1} + 1) - \Sigma_{t \mid t -1}^2}{\Sigma_{t \mid t -1} + 1}
\end{equation}
\item So the covariance goes down in every single step! $ \Sigma_{t \mid t } \leq \Sigma_{t \mid t -1}$
\item So in our update step, 
\begin{equation}
\Sigma_{t \mid t} = \frac{\Sigma_{t \mid t - 1}}{ \Sigma_{t \mid t-1} + 1}
\end{equation}</p>

<h2 id="gaussian-white-noise">Gaussian White Noise</h2>

<p>In practice, noise is usually not Gaussian and is not white (usually colored).</p>

<p>\item Fact: For a Linear-Gaussian dynamical system (one who’s dynamics are expressed with Gaussian White Noise
\begin{equation}
\begin{array}{ll}
x_{t+1} = Ax_t + B u_t + w_t, &amp; w_t \sim \mathcal{N}(0,Q) <br />
\end{array}
\end{equation}</p>

<p>\begin{equation}
\begin{array}{ll}
y_t = Cx_t + Du_t + v_t, &amp; v_t \sim \mathcal{N}(O, R)
\end{array}
\end{equation}
where $w_t, v_t$ are zero-mean white noise</p>

<h2 id="ekf">EKF</h2>

<h2 id="ukf">UKF</h2>

<p><a name="3d-bbox-constant-velocity"></a></p>
<h2 id="practical-example-tracking-3d-bounding-boxes-with-constant-velocity">Practical Example: Tracking 3D Bounding Boxes with Constant Velocity</h2>

<p>Consider the following scenario: we use a deep network to estimate 3d bounding boxes as we drive through a city. At each timestep <script type="math/tex">t</script>, we receive a set of <script type="math/tex">n_t</script> 3d object detections <script type="math/tex">D_t = \{D_t^1, D_t^2, \cdots, D_t^{n_t} \}</script>. We wish to track objects in 3D through time.</p>

<p>Weng and Kitani introduce a simple baseline for 3d tracking using Kalman Filters in [1]. They also provide Python code <a href="https://github.com/xinshuoweng/AB3DMOT">here</a> for a 3D multi-object tracking baseline.</p>

<p>A 3d bounding box detection <script type="math/tex">D_t^i</script> is modeled as an 8-tuple <script type="math/tex">(x, y, z, l, w, h, \theta, s)</script>. These 8 parameters represent the 3D coordinate of the object center <script type="math/tex">(x, y, z)</script>, the object’s size <script type="math/tex">(l, w, h)</script>, heading angle <script type="math/tex">\theta</script> and its confidence <script type="math/tex">s</script>.</p>

<p>The state of a tracked object trajectory is modeled as a 10-dimensional vector <script type="math/tex">\mathbf{x} = (x, y, z, \theta, l, w, h, v_x, v_y, v_z)</script></p>

<p>A constant velocity model is used to propogate tracks from frame <script type="math/tex">t</script> to frame <script type="math/tex">(t+1)</script>:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
x_{est} &= x + v_x, \\ 
y_{est} &= y + v_y, \\
 z_{est} &= z + v_z
 \end{aligned} %]]></script>

<p>The state transition matrix <script type="math/tex">F \in \mathbb{R}^{n \times n}</script> is thus a <script type="math/tex">10 \times 10</script> matrix that we use to accomplish this motion model:</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathbf{x}_{t+1} = \begin{bmatrix} x + v_x \\ y + v_y \\ z + v_z \\ \theta \\ l \\ w \\ h \\ v_x \\ v_y \\ v_z \end{bmatrix} =
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\      
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\  
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 
\end{bmatrix} \begin{bmatrix}
x \\ y \\ z \\ \theta \\ l \\ w \\ h \\ v_x \\ v_y \\ v_z
\end{bmatrix} = F \mathbf{x}_t %]]></script>

<p>The measurement model is even simpler. We use a matrix <script type="math/tex">H \in \mathbb{R}^{m \times n}</script> to model the observation of a 3d bounding box  from a 3d object’s trajectory state <script type="math/tex">\mathbf{x}_t</script>. Here <script type="math/tex">H</script> is <script type="math/tex">7 \times 10</script> in shape:</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathbf{x}_{t+1} = \begin{bmatrix}
x \\ y \\ z \\ \theta \\ l \\ w \\ h \\ 0 \\ 0 \\ 0
\end{bmatrix} = \begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0
\end{bmatrix} \begin{bmatrix}
x \\ y \\ z \\ \theta \\ l \\ w \\ h \\ v_x \\ v_y \\ v_z
\end{bmatrix} = H \mathbf{x}_t %]]></script>

<p><a name="3dtracking-icp"></a></p>
<h2 id="practical-example-3d-tracking-with-icp">Practical Example: 3D Tracking with ICP</h2>

<p><a href="https://github.com/alliecc/argoverse_baselinetracker">Argoverse Tracking Baseline</a></p>

<p><a href="https://github.com/alliecc/argoverse_baselinetracker/blob/master/utils/tools_pcl.py#L1048">EKF</a></p>

<p>[1] Xinshuo Weng and Kris Kitani. A Baseline for 3D Multi-Object Tracking. <a href="https://arxiv.org/pdf/1907.03961.pdf">PDF</a>.</p>

<p>[2] Boyd and Vandenberghe. Convex Optimization. <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">PDF</a></p>


  </article>

  <!-- mathjax -->
  
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>
  
  
  <!-- disqus comments -->
<!--   -->
  
</div>
      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <!-- <h2 class="footer-heading">John Lambert</h2> -->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              John Lambert
            
          </li>
          
          <li><a href="mailto:johnlambert [at] gatech.edu">johnlambert [at] gatech.edu</a></li>
          
          
       </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
         
          <li>
              <a href="https://scholar.google.com/citations?user=6GhZedEAAAAJ">
                <i class="ai ai-google-scholar ai"></i> Google Scholar
              </a>
          </li>
          
          
          
          <li>
              <a href="https://linkedin.com/in/johnwlambert">
                <i class="fa fa-linkedin fa"></i> LinkedIn
              </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
         <ul class="social-media-list">
          <li>
        <a>Ph.D. Candidate in Computer Vision.
</a>
         </li>
          <li>
        Website Design by <a href="http://www.niebles.net/">Juan Carlos Niebles, Ph.D.</a>
        </li>
         </ul>
      </div>
    </div>

  </div>

</footer>

    

  </body>

</html>
