<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Fast Nearest Neighbors</title>
  <meta name="description" content="Vectorizing nearest neighbors (with no for-loops!)">
   <link rel="stylesheet" href="/css/main.css">


  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://johnwlambert.github.io/fast-nearest-neighbor/">

  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.css"/>


  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">

    <a class="site-title" href="/">John Lambert</a>

    <nav class="site-nav">
      <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </span>

      <div class="trigger">
        
          
          
          <a class="page-link" href="/collaborators/">Collaborators</a>
          
          
        
          
          
          
        
          
          
          <a class="page-link" href="/publications/">Publications</a>
          
          
        
          
          
          <a class="page-link" href="/teaching/">Teaching</a>
          
          
        
          
          
          
        
          
          
          
        
      </div>
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1>Fast Nearest Neighbors</h1>
    <p class="meta">Oct 2, 2018</p>
  </header>

  <article class="post-content">
  <p>Table of Contents:</p>

<ul>
  <li><a href="#nn-problem">The Nearest Neighbor Problem</a></li>
  <li><a href="#nn-computation">Nearest Neighbor Computation</a></li>
  <li><a href="#brute-force">Brute Force Nearest Neighbors</a></li>
  <li><a href="#vectorized-nn">Vectorized NN Derivation</a></li>
  <li><a href="#vectorized-numpy">Implementation: Fast Affinity Matrix Computation</a></li>
  <li><a href="#speedup">Speed Comparison</a></li>
</ul>

<p><a name="nn-problem"></a></p>
<h2 id="the-nearest-neighbor-problem">The Nearest Neighbor Problem</h2>
<p>Finding closest points in a high-dimensional space is a re-occurring problem in computer vision, especially when performing feature matching (e.g. with SIFT [1]) or computing Chamfer distances [2,3] for point set generation with deep networks. It is a cheaper way of finding point-to-point correspondences than optimal bipartite matching, as the Earth Moverâ€™s Distance requires.</p>

<p>Brute force methods can be prohibitively slow and much faster ways exist of computing with a bit of linear algebra.</p>

<p><a name="nn-computation"></a></p>
<h2 id="nearest-neighbor-computation">Nearest Neighbor Computation</h2>

<p>Let <script type="math/tex">\mathcal{A,B}</script> be sets. We are interested in the finding the nearest neighbor for each point in <script type="math/tex">\mathcal{A}</script>. Let <script type="math/tex">a,b</script> be two points such that <script type="math/tex">a \in \mathcal{A}</script>, <script type="math/tex">b \in \mathcal{B}</script>. The nearest neighbor in <script type="math/tex">\mathcal{B}</script> of a point <script type="math/tex">a \in \mathcal{A}</script> is a point <script type="math/tex">b \in \mathcal{B}</script>, such that <script type="math/tex">b = \mbox{arg} \underset{b \in \mathcal{B}}{\mbox{ min}} \|a-b\|_2</script>. We can equivalently use the squared Euclidean distance <script type="math/tex">\|a-b\|_2^2</script>, since the square function is monotonically increasing for positive values, and distances are always positive. We will see that using the squared Euclidean distance to find the nearest neighbor will spare us some computation later.</p>

<p>The expression <script type="math/tex">\|a-b\|_2^2</script> is equivalent to an inner product. It is equivalent to the Mahalanobis distance, <script type="math/tex">(a-b)^TA(a-b)</script>, when <script type="math/tex">A=I</script>, when working in Euclidean space (computing \(\ell_2\) norms):</p>

<p>Let <script type="math/tex">a,b</script> be vectors, i.e. \(a,b \in R^n\) are vectors:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\|a-b\|_2^2 &= (a-b)^T(a-b) \\
&= (a^T-b^T)(a-b) \\
&= (a^T-b^T)(a-b) \\
&= a^Ta -b^Ta - a^Tb + b^Tb 
\end{aligned} %]]></script>

<p>Since <script type="math/tex">-b^Ta</script> and  <script type="math/tex">- a^Tb</script> are scalars (inner products), we can swap the order or arguments to find:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\|a-b\|_2^2 &= a^Ta -a^Tb - a^Tb + b^Tb \\
&= a^Ta -2 a^Tb + b^Tb
\end{aligned} %]]></script>

<p><a name="brute-force"></a></p>
<h2 id="brute-force-nearest-neighbors">Brute Force Nearest Neighbors</h2>

<p>In the brute force regime, we would loop through all points <script type="math/tex">a_i \in \mathcal{A}</script>, and then loop through all points <script type="math/tex">b_j \in \mathcal{B}</script>, and find the distance <script type="math/tex">\|a_i - b_j\|</script> with <code class="highlighter-rouge">np.linalg.norm(A[i] - B[j])</code>. This can be done with a double for-loop in Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">naive_upper_triangular_compute_affinity_matrix</span><span class="p">(</span><span class="n">pts1</span><span class="p">,</span> <span class="n">pts2</span><span class="p">):</span>
    <span class="s">"""
    Create an mxn matrix, where each (i,j) entry denotes
    the Mahalanobis distance between point i and point j,
    as defined by the metric "A". A has dimension (dim x dim).
    Use of a for loop makes this function somewhat slow.

    not symmetric
    """</span>
    <span class="n">m1</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">pts1</span><span class="o">.</span><span class="n">shape</span>

    <span class="c"># make sure feature vectors have the same length</span>
    <span class="k">assert</span> <span class="n">pts1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">pts2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">m2</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">pts2</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">affinity_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m1</span><span class="p">,</span><span class="n">m2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m1</span><span class="p">):</span> <span class="c"># rows</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m2</span><span class="p">):</span> <span class="c"># cols</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">pts1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">pts2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
            <span class="n">affinity_mat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm</span>

    <span class="c">#affinity matrix contains the Mahalanobis distances</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">affinity_mat</span><span class="p">)</span>
</code></pre></div></div>
<p>However, this method will be brutally slow for thousands, tens of thousands, or millions of points, which are quite common point cloud sizes in computer vision or robotics. We need a better way.</p>

<p><a name="vectorized-nn"></a></p>
<h2 id="vectorized-nn-derivation">Vectorized NN Derivation</h2>

<p>Now we wish to compute these distances on all pairs of points in entire datasets simultaneously. We can form matrices \(A \in R^{m_1 \times n}, B \in R^{m_2 \times n}\) that hold our high-dimensional points.</p>

<p>We will see that nearest neighbor computation for all points boils down to only 3 required matrix products: <script type="math/tex">AA^T, BB^T, AB^T</script>.</p>

<p>Our goal is to find <script type="math/tex">\|a_i - b_j\|_2^2 = a_i^Ta_i -2 a_i^Tb_j + b_j^Tb_j</script> for all <script type="math/tex">i,j</script>. We wish to build an affinity matrix <script type="math/tex">D</script> such that the <script type="math/tex">D_{ij}</script> entry contains the squared distance between <script type="math/tex">a_i, b_j</script>.</p>

<p>Consider a sets <script type="math/tex">\mathcal{A,B}</script> with 3 points each. We form <script type="math/tex">AA^T, BB^T</script>:</p>

<script type="math/tex; mode=display">% <![CDATA[
AA^T = \begin{bmatrix} - & a_1 & - \\ - & a_2 & - \\ - & a_3 & - \end{bmatrix} \begin{bmatrix} | & | & | \\ a_1^T & a_2^T & a_3^T \\ | & | & | \end{bmatrix}  =
\begin{bmatrix}
a_1^Ta_1 & a_1^T a_2 & a_1^T a_3 \\
a_2^Ta_1 & a_2^T a_2 & a_2^T a_3 \\
a_3^Ta_1 & a_3^T a_2 & a_3^T a_3
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
BB^T = \begin{bmatrix} - & b_1 & - \\ - & b_2 & - \\ - & b_3 & - \end{bmatrix} \begin{bmatrix} | & | & | \\ b_1^T & b_2^T & b_3^T \\ | & | & | \end{bmatrix} = \begin{bmatrix}
b_1^T b_1 & b_1^T b_2 & b_1^T b_3 \\
b_2^T b_1 & b_2^T b_2 & b_2^T b_3 \\
b_3^T b_1 & b_3^T b_2 & b_3^T b_3
\end{bmatrix} %]]></script>

<p>We are interested only in the diagonal elements <script type="math/tex">a_i^Ta_i</script> and <script type="math/tex">b_i^Tb_i</script>. We will define <script type="math/tex">T_A</script> and <script type="math/tex">T_B</script> to contain tiled rows, where each row is a diagonal of <script type="math/tex">AA^T</script> or <script type="math/tex">BB^T</script>, respectively:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{ll}
T_A = \begin{bmatrix}
a_1^Ta_1 & a_2^Ta_2 & a_3^Ta_3 \\
a_1^Ta_1 & a_2^Ta_2 & a_3^Ta_3 \\
a_1^Ta_1 & a_2^Ta_2 & a_3^Ta_3 
\end{bmatrix}, & T_B = \begin{bmatrix}
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 \\
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 \\
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 
\end{bmatrix}
\end{array} %]]></script>

<p>We now form <script type="math/tex">AB^T</script>:</p>

<script type="math/tex; mode=display">% <![CDATA[
AB^T = \begin{bmatrix} - & a_1 & - \\ - & a_2 & - \\ - & a_3 & - \end{bmatrix} \begin{bmatrix} | & | & | \\ b_1^T & b_2^T & b_3^T \\ | & | & | \end{bmatrix} = \begin{bmatrix}
b_1^Ta_1 & b_2^Ta_1 & b_3^Ta_1 \\
b_1^Ta_2 & b_2^Ta_2 & b_3^Ta_2 \\
b_1^Ta_3 & b_2^Ta_3 & b_3^Ta_3 
\end{bmatrix} %]]></script>

<p>Our desired affinity matrix <script type="math/tex">D \in \mathbf{R}^{3 \times 3}</script> will contain entries <script type="math/tex">D_{ij} = \|a_i - b_j\|_2^2</script>:</p>

<script type="math/tex; mode=display">% <![CDATA[
D = 
\begin{bmatrix} 
\| a_1 - b_1 \|_2^2 & \| a_1 - b_2 \|_2^2 & \|a_1 - b_3 \|_2^2 \\
\| a_2 - b_1 \|_2^2 & \| a_2 - b_2 \|_2^2 & \|a_2 - b_3 \|_2^2 \\
\| a_3 - b_1 \|_2^2 & \| a_3 - b_2 \|_2^2 & \|a_3 - b_3 \|_2^2
\end{bmatrix} %]]></script>

<p>In turns out that:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
D &= T_A^T + T_B - 2 AB^T \\
D &= \begin{bmatrix}
a_1^Ta_1 & a_1^Ta_1 & a_1^Ta_1 \\
a_2^Ta_2 & a_2^Ta_2 & a_2^Ta_2 \\
a_3^Ta_3 & a_3^Ta_3 & a_3^Ta_3 
\end{bmatrix} + 
\begin{bmatrix}
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 \\
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 \\
b_1^T b_1 & b_2^T b_2 & b_3^T b_3 
\end{bmatrix} - 2 \begin{bmatrix}
b_1^Ta_1 & b_2^Ta_1 & b_3^Ta_1 \\
b_1^Ta_2 & b_2^Ta_2 & b_3^Ta_2 \\
b_1^Ta_3 & b_2^Ta_3 & b_3^Ta_3 
\end{bmatrix}  
\end{aligned} %]]></script>

<p>Since as you can see above, <script type="math/tex">D_{ij} = \|a_i - b_j\|_2^2 = a_i^Ta_i -2 a_i^Tb_j + b_j^Tb_j</script> for all <script type="math/tex">i,j</script>.</p>

<p><a name="vectorized-numpy"></a></p>
<h2 id="implementation-fast-affinity-matrix-computation">Implementation: Fast Affinity Matrix Computation</h2>

<p>The implementation requires just a few lines in Numpy:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">fast_affinity_mat_compute</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">X2</span><span class="p">):</span>
    <span class="s">"""
    X is (m,n)
    A is (n,n)
    K is (m,m)
    """</span>
    <span class="n">m1</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">X1</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">X1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">m2</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">X2</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ab_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">T</span> <span class="p">)</span>
    <span class="n">a_sqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">b_sqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">a_sqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">a_sqr</span><span class="p">,</span> <span class="p">(</span><span class="n">m2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">b_sqr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">b_sqr</span><span class="p">,</span> <span class="p">(</span><span class="n">m1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">a_sqr</span> <span class="o">+</span> <span class="n">b_sqr</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ab_T</span>
</code></pre></div></div>

<p><a name="speedup"></a></p>
<h2 id="speed-comparison">Speed Comparison</h2>

<p>We now demonstrate the speedup of the vectorized approach over the brute force approach:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">unit_test_arr_arr</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span><span class="n">m2</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
  <span class="s">""" """</span>
  <span class="n">pts1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">pts2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

  <span class="n">gt_aff</span> <span class="o">=</span> <span class="n">naive_upper_triangular_compute_affinity_matrix</span><span class="p">(</span><span class="n">pts1</span><span class="p">,</span> <span class="n">pts2</span><span class="p">)</span>

  <span class="n">pred_aff</span> <span class="o">=</span> <span class="n">fast_affinity_mat_compute</span><span class="p">(</span><span class="n">pts1</span><span class="p">,</span><span class="n">pts2</span><span class="p">)</span>

  <span class="k">print</span><span class="p">(</span><span class="n">gt_aff</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">pred_aff</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">gt_aff</span> <span class="o">-</span> <span class="n">pred_aff</span><span class="p">)</span><span class="o">.</span><span class="nb">sum</span><span class="p">())</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>

  <span class="n">m1</span> <span class="o">=</span> <span class="mi">3</span> <span class="c"># 100</span>
  <span class="n">m2</span> <span class="o">=</span> <span class="mi">4</span> <span class="c"># 135</span>
  <span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>

  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
  <span class="c"># unit_test_pt_arr(m1,m2,n)</span>
  <span class="n">unit_test_arr_arr</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span><span class="n">m2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
</code></pre></div></div>

<p>Now consider the speedup weâ€™ve achieved:</p>

<h2 id="references">References</h2>

<ol>
  <li>
    <p>David Lowe. Distinctive Image Features
from Scale-Invariant Keypoints. IJCV, 2004. <a href="https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">PDF</a>.</p>
  </li>
  <li>
    <p>H.  Fan,  H.  Su,  and  L.  J.  Guibas.   A  point  set  generationnetwork  for  3d  object  reconstruction  from  a  single  image. CVPR 2017. <a href="https://arxiv.org/abs/1612.00603">PDF</a>.</p>
  </li>
  <li>
    <p>A. Kurenkov, J. Ji, A. Garg, V. Mehta, J. Gwak, C. B. Choy, and  S.  Savarese.   Deformnet:  Free-form  deformation  network for 3d shape reconstruction from a single image. WACV 2018. <a href="https://arxiv.org/abs/1708.04672">PDF</a>.</p>
  </li>
</ol>


  </article>

  <!-- mathjax -->
  
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>
  
  
  <!-- disqus comments -->
<!--   -->
  
</div>
      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <!-- <h2 class="footer-heading">John Lambert</h2> -->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              John Lambert
            
          </li>
          
          <li><a href="mailto:johnlambert [at] gatech.edu">johnlambert [at] gatech.edu</a></li>
          
          
       </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
         
          <li>
              <a href="https://scholar.google.com/citations?user=6GhZedEAAAAJ">
                <i class="ai ai-google-scholar ai"></i> Google Scholar
              </a>
          </li>
          
          
          
          <li>
              <a href="https://linkedin.com/in/johnwlambert">
                <i class="fa fa-linkedin fa"></i> LinkedIn
              </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
         <ul class="social-media-list">
          <li>
        <a>Ph.D. Candidate in Computer Vision.
</a>
         </li>
          <li>
        Website Design by <a href="http://www.niebles.net/">Juan Carlos Niebles, Ph.D.</a>
        </li>
         </ul>
      </div>
    </div>

  </div>

</footer>

    

  </body>

</html>
