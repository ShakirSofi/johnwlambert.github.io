<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>John Lambert blog</title>
    <description>Notes on Machine Learning and Optimization.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 01 Apr 2018 05:14:12 -0700</pubDate>
    <lastBuildDate>Sun, 01 Apr 2018 05:14:12 -0700</lastBuildDate>
    <generator>Jekyll v3.7.3</generator>
    
      <item>
        <title>Subgradient Calculus</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;

&lt;p&gt;Now that we’ve cover topics from convex optimization in a very shallow manner, it’s time to go deeper.&lt;/p&gt;

&lt;h2 id=&quot;subgradient-methods&quot;&gt;Subgradient methods&lt;/h2&gt;

&lt;h3 id=&quot;subgradients&quot;&gt;Subgradients&lt;/h3&gt;

&lt;h3 id=&quot;subgradient-methods-1&quot;&gt;Subgradient methods&lt;/h3&gt;

&lt;h3 id=&quot;subgradient-methods-for-constrained-problems&quot;&gt;Subgradient methods for constrained problems&lt;/h3&gt;

&lt;h3 id=&quot;primal-dual-subgradient-methods&quot;&gt;Primal-dual subgradient methods&lt;/h3&gt;

&lt;h3 id=&quot;stochastic-subgradient-method&quot;&gt;Stochastic subgradient method&lt;/h3&gt;

&lt;h3 id=&quot;mirror-descent-and-variable-metric-methods&quot;&gt;Mirror descent and variable metric methods&lt;/h3&gt;

&lt;h2 id=&quot;localization-methods&quot;&gt;Localization methods&lt;/h2&gt;

&lt;h3 id=&quot;localization-and-cutting-plane-methods&quot;&gt;Localization and cutting-plane methods&lt;/h3&gt;

&lt;h3 id=&quot;analytic-center-cutting-plane-method&quot;&gt;Analytic center cutting-plane method&lt;/h3&gt;

&lt;h3 id=&quot;ellipsoid-method&quot;&gt;Ellipsoid method&lt;/h3&gt;

&lt;h2 id=&quot;decomposition-and-distributed-optimization&quot;&gt;Decomposition and distributed optimization&lt;/h2&gt;

&lt;h3 id=&quot;primal-and-dual-decomposition&quot;&gt;Primal and dual decomposition&lt;/h3&gt;

&lt;h3 id=&quot;decomposition-applications&quot;&gt;Decomposition applications&lt;/h3&gt;

&lt;h3 id=&quot;distributed-optimization-via-circuits&quot;&gt;Distributed optimization via circuits&lt;/h3&gt;

&lt;h2 id=&quot;proximal-and-operator-splitting-methods&quot;&gt;Proximal and operator splitting methods&lt;/h2&gt;

&lt;h3 id=&quot;proximal-algorithms&quot;&gt;Proximal algorithms&lt;/h3&gt;

&lt;h3 id=&quot;monotone-operators&quot;&gt;Monotone operators&lt;/h3&gt;

&lt;h3 id=&quot;monotone-operator-splitting-methods&quot;&gt;Monotone operator splitting methods&lt;/h3&gt;

&lt;h3 id=&quot;alternating-direction-method-of-multipliers-admm&quot;&gt;Alternating direction method of multipliers (ADMM)&lt;/h3&gt;

&lt;h2 id=&quot;conjugate-gradients&quot;&gt;Conjugate gradients&lt;/h2&gt;

&lt;h3 id=&quot;conjugate-gradient-method&quot;&gt;Conjugate-gradient method&lt;/h3&gt;

&lt;h3 id=&quot;truncated-newton-methods&quot;&gt;Truncated Newton methods&lt;/h3&gt;

&lt;h2 id=&quot;nonconvex-problems&quot;&gt;Nonconvex problems&lt;/h2&gt;

&lt;h3 id=&quot;l_1-methods-for-convex-cardinality-problems-matlab-files&quot;&gt;l_1 methods for convex-cardinality problems (matlab files)&lt;/h3&gt;

&lt;h3 id=&quot;l_1-methods-for-convex-cardinality-problems-part-ii-matlab-files&quot;&gt;l_1 methods for convex-cardinality problems, part II (matlab files)&lt;/h3&gt;

&lt;h3 id=&quot;sequential-convex-programming-matlab-files&quot;&gt;Sequential convex programming (matlab files)&lt;/h3&gt;

&lt;h2 id=&quot;branch-and-bound-methods-notes--python-files&quot;&gt;Branch-and-bound methods (notes | python files)&lt;/h2&gt;
</description>
        <pubDate>Sat, 31 Mar 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/03/31/subgradient/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/31/subgradient/</guid>
        
        
      </item>
    
      <item>
        <title>Essential Linear Algebra Overview</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;
&lt;h3 id=&quot;linear-algebra-definitions&quot;&gt;Linear Algebra Definitions&lt;/h3&gt;
&lt;p&gt;Before we do anything interesting with machine learning or optimization, we’ll need to review some absolutely &lt;strong&gt;essential&lt;/strong&gt; linear algebra concepts.&lt;/p&gt;
&lt;h2 id=&quot;matrix-rank&quot;&gt;Matrix Rank&lt;/h2&gt;

&lt;h2 id=&quot;vector-space&quot;&gt;Vector Space&lt;/h2&gt;

&lt;h2 id=&quot;null-space-of-a-matrix&quot;&gt;Null Space of a Matrix&lt;/h2&gt;

&lt;p&gt;Given \(A \in \mathbb{R}^{m \times n}\), the &lt;strong&gt;null space&lt;/strong&gt; of \(A\) is the set of vectors which are sent to the zero vector:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(A) = \{ x \in \mathbb{R}^n \mid Ax = 0 \}&lt;/script&gt;

&lt;p&gt;Multiplication by \(A\) can be seen as a function which sends a vector \(x \in \mathbb{R}^n\) to a vector \(Ax \in \mathbb{R}^m\).&lt;/p&gt;

&lt;p&gt;Of course, \(\mathcal{N}(A)\) always contains the zero vector, i.e. \({0} \in \mathcal{N}(A)\). But the question is, does it contain any other vectors? If the columns of \(A\) are linearly independent, then we can always say \(\mathcal{N}(A) = {0} \).&lt;/p&gt;

&lt;h2 id=&quot;column-space-range-of-a-matrix&quot;&gt;Column Space (Range) of a Matrix&lt;/h2&gt;

&lt;p&gt;Given an \(m \times n\) matrix \(A\), we would like to know for which vectors \(b \in \mathbb{R}^m\) the system \(Ax = b\) has a solution. Let’s define the columns of \(A\) as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A = \begin{bmatrix} | &amp; | &amp; &amp; | \\ v_1 &amp; v_2 &amp; \cdots &amp; v_n \\ | &amp; | &amp; &amp; | \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;The column space of \(A\) is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(A) = \mbox{span}(v_1, v_2, \dots, v_n)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(A) = \{ Ax \mid x \in \mathbb{R}^n \}&lt;/script&gt;

&lt;p&gt;The system \(Ax = b\) has a solution &lt;strong&gt;if and only if&lt;/strong&gt; \(b \in C(A)\), equivalent to stating \(b\) is in the range of \(A\): \(b \in R(A)\).&lt;/p&gt;

&lt;h2 id=&quot;rank-nullity-theorem&quot;&gt;Rank-Nullity Theorem&lt;/h2&gt;
&lt;p&gt;Let \(A\) be any matrix such that \(A \in \mathbb{R}^{m \times n}\).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{rank}(A) + \mbox{nullity}(A) = n&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{dim}\bigg(C(A)\bigg) + \mbox{dim}\bigg(N(A)\bigg) = n&lt;/script&gt;

&lt;h2 id=&quot;orthogonal-complement&quot;&gt;Orthogonal Complement&lt;/h2&gt;

&lt;h3 id=&quot;matrix-calculus&quot;&gt;Matrix Calculus&lt;/h3&gt;

&lt;h3 id=&quot;gram-schmidt&quot;&gt;Gram Schmidt&lt;/h3&gt;

&lt;h3 id=&quot;solving-systems-of-equations&quot;&gt;Solving Systems of Equations&lt;/h3&gt;

&lt;h2 id=&quot;overdetermined-systems&quot;&gt;Overdetermined Systems&lt;/h2&gt;
&lt;p&gt;Here, matrix \(A\) is a skinny, full-rank matrix. We cannot solve such a system, so instead we minimize a residual \(r\), i.e. we minimize \(\lVert r \rVert^2 = \lVert Ax-y \rVert^2\).  We find an approximate solution to \(Y=Ax\). Formally, we minimize some objective function \(J\):
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\begin{array}{ll}
\mbox{minimize} &amp; J \\
&amp; \lVert r \rVert^2 \\
 &amp;  \lVert Ax-y \rVert^2 \\
&amp; (Ax-y)^T (Ax-y) \\
&amp; (Ax)^T(Ax) - y^TAx - (Ax)^Ty + y^Ty \\
&amp; x^TA^TAx - y^TAx - x^TA^Ty + y^Ty
\end{array}
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can set its gradient to zero, and since the objective is the square of an affine function, it is convex, so we can find its true, global minimum:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_x J = 2(A^TA)x - 2A^Ty = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2(A^TA)x = 2A^Ty&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(A^TA)x = A^Ty&lt;/script&gt;

&lt;p&gt;Multiply on the left by \((A^TA)^{-1}\), and we recover the least squares solution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ls} = (A^TA)^{-1}A^Ty = A^{\dagger}y&lt;/script&gt;

&lt;p&gt;We call \(A^{\dagger}\) a &lt;strong&gt;left-inverse&lt;/strong&gt; of \(A\) because \(A^{\dagger}A=I\).&lt;/p&gt;

&lt;h2 id=&quot;underdetermined-systems&quot;&gt;Underdetermined Systems&lt;/h2&gt;
&lt;p&gt;Here \(A\) is a fat, full-rank matrix. We can &lt;strong&gt;always&lt;/strong&gt; solve such a system, and there will be an infinite # of solutions.&lt;/p&gt;

&lt;p&gt;We often choose to find the smallest solution, i.e. the one closest to the origin. We call this a least-norm (\(x_{ln}\) ) solution, because we minimize \(\lVert x \rVert\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ln} = A^T(AA^T)^{-1}y = A^{\dagger}y&lt;/script&gt;

&lt;p&gt;We call \(A^{\dagger}\) a right-inverse of \(A\) because \(AA^{\dagger}=I\).&lt;/p&gt;

&lt;h2 id=&quot;singular-value-decomposition-svd&quot;&gt;Singular Value Decomposition (SVD)&lt;/h2&gt;

&lt;h3 id=&quot;svd-definition&quot;&gt;SVD Definition&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A=U\Sigma V^T = \begin{bmatrix} u_1 &amp; \dots &amp; u_r \end{bmatrix} \begin{bmatrix} \sigma_1 &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_r \end{bmatrix} \begin{bmatrix} v_1^T \\ \vdots \\ v_r^T \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where \(U\), \(V\) are orthogonal matrices, meaning \(U^TU = I\), \(UU^T=I\).&lt;/p&gt;

&lt;p&gt;We call \(V=\begin{bmatrix} v_1, \dots, v_r \end{bmatrix}\) the right/input singular vectors, because this is the first matrix to interact with an input vector \(x\) when we compute \(y=Ax\).&lt;/p&gt;

&lt;p&gt;We call \(U=\begin{bmatrix} u_1, \dots, u_r \end{bmatrix}\) the left/output singular vectors, because this is the last matrix that the intermediate results are multiplied before we obtain our result ( \(y=Ax\) ).&lt;/p&gt;

&lt;h3 id=&quot;computation-of-the-svd&quot;&gt;Computation of the SVD&lt;/h3&gt;

&lt;p&gt;To find this decomposition for a matrix \(A\), we’ll need to compute the \(V\)’s.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^TA = (V\Sigma U^T) (U \Sigma V^T)&lt;/script&gt;

&lt;p&gt;This reduces to \(V \Sigma^2 V^T\). We need to find orthonormal eigenvectors, and the \(V_i\)’s are simply the eigenvectors of \(A^TA\).&lt;/p&gt;

&lt;p&gt;Now, we’ll need to compute the \(U\)’s.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;AA^T = (U \Sigma V^T)(V\Sigma U^T) = U \Sigma^2 U^T&lt;/script&gt;

&lt;p&gt;The \(U_i\)’s are the eigenvectors of \(AA^T\).&lt;/p&gt;
&lt;h3 id=&quot;svd-applications&quot;&gt;SVD Applications&lt;/h3&gt;

&lt;p&gt;We can use the SVD to compute the general pseudo-inverse of a matrix for \(y=Ax\):&lt;/p&gt;

&lt;p&gt;For skinny/full-rank matrices:&lt;/p&gt;

&lt;h2 id=&quot;extremal-trace-problems&quot;&gt;Extremal Trace Problems&lt;/h2&gt;

&lt;h2 id=&quot;eigenvectors&quot;&gt;Eigenvectors&lt;/h2&gt;

&lt;h2 id=&quot;unconstrained-optimization&quot;&gt;Unconstrained Optimization&lt;/h2&gt;

&lt;h3 id=&quot;the-gauss-newton-method&quot;&gt;The Gauss-Newton Method&lt;/h3&gt;

&lt;p&gt;Suppose our residual is no longer affine, but rather nonlinear. We want to minimize \(\lVert r(x) \rVert^2\). Generally speaking, we cannot solve this problem, but rather can use good heuristics to find local minima.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Start from initial guess for your solution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Repeat:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;(1) Linearize \(r(x)\) around current guess \(x^{(k)}\). This can be accomplished by using a Taylor Series and Calculus (Standard Gauss-Newton), or one can use a least-squares fit to the line.&lt;/li&gt;
  &lt;li&gt;(2) Solve least squares for linearized objective, get \(x^{(k+1)}\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The linearized residual \(r(x)\) will resemble:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx r(x^{(k)}) + Dr(x^{(k)}) (x-x^{(k)})&lt;/script&gt;

&lt;p&gt;where \(Dr\) is the Jacobian, meaning \( (Dr)_{ij} = \frac{\partial r_i}{\partial x_j}\)&lt;/p&gt;

&lt;p&gt;Distributing the rightmost product, we obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx Dr(x^{(k)})x - \bigg(Dr(x^{(k)}) (x^{(k)}) - r(x^{(k)}) \bigg)&lt;/script&gt;

&lt;p&gt;With a single variable \(x\), we can re-write the above equation as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx A^{(k)}x - b^{(k)}&lt;/script&gt;

&lt;h3 id=&quot;levenberg-marquardt-algorithm-trust-region-gauss-newton-method&quot;&gt;Levenberg-Marquardt Algorithm (Trust-Region Gauss-Newton Method)&lt;/h3&gt;

</description>
        <pubDate>Sat, 31 Mar 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/03/31/linalg/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/31/linalg/</guid>
        
        
      </item>
    
      <item>
        <title>Convex Optimization</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;

&lt;h2 id=&quot;convexity&quot;&gt;Convexity&lt;/h2&gt;

&lt;h3 id=&quot;first-order-condition&quot;&gt;First-Order Condition&lt;/h3&gt;

&lt;p&gt;If \(f\) is convex and differentiable, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) + \nabla f(x)^T (y-x) \leq f(y)&lt;/script&gt;

&lt;p&gt;That is to say, a tangent line to \(f\) is a &lt;strong&gt;global underestimator&lt;/strong&gt; of the function.&lt;/p&gt;

&lt;h3 id=&quot;second-order-condition&quot;&gt;Second-Order Condition&lt;/h3&gt;

&lt;p&gt;Assuming \(f\) is twice differentiable, that is, its Hessian or second derivative \(\nabla^2f\) exists at each point in the domain of \(f\), then \(f\) is convex **if and only if ** the domain of \(f\) is convex and its Hessian is positive semidefinite.&lt;/p&gt;

&lt;p&gt;Formally, we state, for all \(x \in \mbox{dom}(f)\),&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\nabla^2 f(x) \succeq 0&lt;/script&gt;
This condition can be interpreted geometrically as the requirement that the graph of the function have positive (upward) curvature at \(x\).&lt;/p&gt;

&lt;h3 id=&quot;known-convex-and-concave-functions&quot;&gt;Known Convex and Concave Functions&lt;/h3&gt;

&lt;p&gt;Convex&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linear.&lt;/li&gt;
  &lt;li&gt;Affine. \(f(x) = Ax+b\), where \(A \in \mathbb{R}^{m \times n}\) and \(b \in \mathbb{R}^m\). This is the sum of a linear function and a constant.&lt;/li&gt;
  &lt;li&gt;Exponential. \(e^{ax}\) is convex on \(\mathbb{R}\), for any \(a \in \mathbb{R}\).&lt;/li&gt;
  &lt;li&gt;Powers. \(x^a\) is convex on \(R_{++}\) when \(a \geq 1\) or \(a \leq 0\).&lt;/li&gt;
  &lt;li&gt;Powers of absolute value. \(|x|^p\), for \(p\geq 1\), is convex on \(\mathbb{R}\).&lt;/li&gt;
  &lt;li&gt;Negative Entropy. \(x \mbox{log}(x)\) is convex on \(\mathbb{R}_{++}\).&lt;/li&gt;
  &lt;li&gt;Norms. Every norm on \(\mathbb{R}^n\) is convex.&lt;/li&gt;
  &lt;li&gt;Max function. \(f(x) = \mbox{max} { x_1, \dots, x_n } \) is convex on \(\mathbb{R}^n\).&lt;/li&gt;
  &lt;li&gt;Quadratic-over-linear function.&lt;/li&gt;
  &lt;li&gt;Log-sum-exp. \(f(x) = \mbox{log }(e^{x_1}+\cdots+e^{x_n})\) is convex on \(\mathbb{R}^n\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Concave&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logarithm. \(\mbox{log}(x)\) concave on \(\mathbb{R}_{++}\).&lt;/li&gt;
  &lt;li&gt;Powers. \(x^a\) is concave for \(0 \leq a \leq 1\).&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Geometric mean. \(f(x) = (\prod\limits_{i=1}^n x_i)^{1/n}\) is concave on \(\mathbb{R}_{++}^n\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Log-determinant. \(f(X) = \mbox{log } \mbox{det } X\) is concave on \(S_{++}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;constrained-optimization-problems&quot;&gt;Constrained Optimization Problems&lt;/h2&gt;

&lt;p&gt;These problems take on a very general form, that we’ll revisit over and over again. In math, that form is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) &amp; \\
\mbox{subject to} &amp; f_i(x) \leq 0, &amp; i=1,\dots,m \\
&amp; h_i(x) = 0, &amp; i=1,\dots,p
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In prose, the problem is to find an \(x\) that minimizes \(f_0(x)\) among all \(x\) that satisfy the conditions \( f_i(x) \leq 0\) for \(i=1,\dots,m \) and \( h_i(x) = 0\) for \( i=1,\dots,p\).&lt;/p&gt;

&lt;p&gt;The inequalities \(f_i(x) \leq 0\) are called inequality constraints, and the equations \(h_i(x) = 0\) are called the equality constraints.&lt;/p&gt;

&lt;h3 id=&quot;the-epigraph-form-of-the-above-standard-problem-is-the-problem&quot;&gt;The Epigraph form of the above standard problem is the problem&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; t &amp; \\
\mbox{subject to} &amp; f_0(x) - t \leq 0 &amp; \\
&amp; f_i(x) \leq 0, &amp; i=1,\dots,m \\
&amp; h_i(x) = 0, &amp; i=1,\dots,p
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Geometrically, from [1]:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/epigraph_problem.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-lagrangian&quot;&gt;The Lagrangian&lt;/h2&gt;

&lt;p&gt;The basic idea in Lagrangian duality is to take the constraints in the standard problem into account by &lt;strong&gt;augmenting the objective function with a weighted sum of the constraint functions&lt;/strong&gt;. The Lagrangian associated with the standard problem is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(x, \lambda, \nu) = f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x)&lt;/script&gt;

&lt;p&gt;We call \(\lambda_i\) as the Lagrange multiplier associated with the \(i\)’th &lt;strong&gt;inequality&lt;/strong&gt; constraint \(f_i(x) \leq 0\).  We refer to \(\nu_i\) as the Lagrange multiplier associated with the \(i\)’th &lt;strong&gt;equality&lt;/strong&gt; constraint \(h_i(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;the-lagrange-dual-function&quot;&gt;The Lagrange Dual Function&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }} L(x,\lambda,\nu)&lt;/script&gt;

&lt;p&gt;In detail, the dual function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }}\Bigg( f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x) \Bigg)&lt;/script&gt;

&lt;p&gt;This is the pointwise infimum of a family of affine functions of \( (\lambda, \nu)\), so the dual function is &lt;strong&gt;concave&lt;/strong&gt;, even when the standard optimization problem is not convex.&lt;/p&gt;

&lt;h3 id=&quot;the-lagrange-dual-problem&quot;&gt;The Lagrange Dual Problem&lt;/h3&gt;

&lt;p&gt;For each pair \( (\lambda, \nu)\), the Lagrange dual function gives us a lower bound on the optimal value \(p^{*}\) of the standard optimization problem. It is a &lt;strong&gt;lower bound&lt;/strong&gt; that depends on some parameters \( (\lambda,\nu)\). But the question of interest for us is, what is the &lt;strong&gt;best&lt;/strong&gt; lower bound that can be obtained from the Lagrange dual function. This leads to the following optimization problem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{ll}
\mbox{maximize} &amp; g(\lambda, \nu) \\
\mbox{subject to} &amp; \lambda \succeq 0
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We refer to this problem as the &lt;strong&gt;Lagrange dual problem&lt;/strong&gt; associated with the standard optimization problem.&lt;/p&gt;

&lt;h3 id=&quot;weak-duality&quot;&gt;Weak Duality&lt;/h3&gt;

&lt;p&gt;Let us define \(d^&lt;em&gt;\) as the optimal value of the Lagrange dual problem. This is &lt;strong&gt;the best lower bound&lt;/strong&gt; on \(p^&lt;/em&gt;\) that can be obtained from the Lagrange dual function.&lt;/p&gt;

&lt;p&gt;Even if the original problem is not convex, we can always say \(d^* \leq p^*\). We call this property weak duality.&lt;/p&gt;

&lt;h3 id=&quot;slaters-constraint-qualification&quot;&gt;Slater’s Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Slater’s condition is a qualification on the problem constraints. It states that there exists an \(x \in \mbox{relint}(\mathcal{D})\) such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{lll}
f_i(x) &lt; 0, &amp; i=1,\dots,m, &amp; Ax=b.
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Why is that important? Well, because if the problem is convex, and &lt;strong&gt;if Slater’s condition&lt;/strong&gt; holds, then &lt;strong&gt;strong duality&lt;/strong&gt; holds.&lt;/p&gt;

&lt;h2 id=&quot;kkt-conditions&quot;&gt;KKT Conditions&lt;/h2&gt;

&lt;h2 id=&quot;newtons-method&quot;&gt;Newton’s Method&lt;/h2&gt;

&lt;p&gt;Instead of minimizing the first-order Taylor approximation of a function \(f\), we may want to minimize the second-order Taylor approximation, \(\hat{f}\). That approximation at a point \(x\) is given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f}(x+v) = f(x) + \nabla f(x)^T v + \frac{1}{2}v^T \nabla^2 f(x) v&lt;/script&gt;

&lt;p&gt;If the function \(f\) is quadratic, then minimizing \(\hat{f}(x+v)\) will give us an exact minimizer of \(f\). If the function \(f\) is nearly quadratic, intuition suggests that minimizing \(\hat{f}(x+v)\) should be a very good estimate of the minimizer of \(f\), i.e., \(x^*\).&lt;/p&gt;

&lt;p&gt;Setting \(\nabla_v \hat{f}(x+v)=0\), we see:&lt;/p&gt;

&lt;h2 id=&quot;interior-point-methods&quot;&gt;Interior Point Methods&lt;/h2&gt;

&lt;p&gt;Suppose we have the following inequality constrained optimization problem:&lt;/p&gt;

&lt;p&gt;We can approximate the problem as an &lt;strong&gt;equality constrained problem&lt;/strong&gt;. This is highly desirable because we know that Newton’s method can be applied to equality constrained problems. We can make the inequality constraints implicit in the objective:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) + \sum\limits_{i=1}^m I_{-}\bigg(f_i(x)\bigg) &amp; \\
\mbox{subject to} &amp; Ax = b
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The indicator function expresses our displeasure with respect to the satisfaction of the inequality constraints. If the indicator function is violated, its value becomes negative infinity:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
I_{-}(u) = \begin{cases} 0 &amp; u\leq 0 \\ \infty &amp; u &gt; 0 \end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;Otherwise, we ignore its presence in the objective function.  Although we were able to remove the inequality constraints, the objective function is, in general, &lt;strong&gt;not differentiable&lt;/strong&gt;, so Newton’s method cannot be applied.&lt;/p&gt;

&lt;h3 id=&quot;the-log-barrier&quot;&gt;The Log-Barrier&lt;/h3&gt;

&lt;p&gt;However, we could approximate the indicator function \(I_{-}\) with the &lt;strong&gt;log-barrier&lt;/strong&gt; function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{I}_{-}(u) = -\bigg(\frac{1}{t}\bigg) \mbox{log }(-u)&lt;/script&gt;

&lt;p&gt;Here, \(t\) is a parameter that sets the accuracy of the approximation. As \(t\) increases, the approximation becomes more accurate.&lt;/p&gt;

&lt;p&gt;A figure shows the quality of the approximation [1]:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/log_barrier_approximation.png&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We now have a new problem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) + \sum\limits_{i=1}^m -\bigg(\frac{1}{t}\bigg) \mbox{log }\bigg(-f_i(x)\bigg) &amp; \\
\mbox{subject to} &amp; Ax = b
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;This objective function is convex, and as long as an &lt;strong&gt;appropriate closedness condition&lt;/strong&gt; holds, Newton’s method can be used to solve it.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References:&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Stephen Boyd and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press, New York, NY, USA.&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 31 Mar 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/03/31/cvx/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/31/cvx/</guid>
        
        
      </item>
    
  </channel>
</rss>
