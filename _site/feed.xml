<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://johnwlambert.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://johnwlambert.github.io/" rel="alternate" type="text/html" /><updated>2019-02-16T17:49:28-05:00</updated><id>http://johnwlambert.github.io/</id><title type="html">John Lambert</title><subtitle>Ph.D. Candidate in Computer Vision.
</subtitle><entry><title type="html">Direct Methods for Linear System Solving</title><link href="http://johnwlambert.github.io/direct-methods/" rel="alternate" type="text/html" title="Direct Methods for Linear System Solving" /><published>2019-02-12T06:00:00-05:00</published><updated>2019-02-12T06:00:00-05:00</updated><id>http://johnwlambert.github.io/direct-methods-linear-systems</id><content type="html" xml:base="http://johnwlambert.github.io/direct-methods/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;Back Substitution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;LU Factorization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Cholesky Factorization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;back-substitution-for-triangular-matrices&quot;&gt;Back Substitution for Triangular Matrices&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;back_substitution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; &quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;back_substitution_demo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;x_est&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_substitution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;lu-decomposition&quot;&gt;LU Decomposition&lt;/h2&gt;
&lt;p&gt;In the LU Decomposition/Factorization, we seek to find two matrices &lt;script type=&quot;math/tex&quot;&gt;L,U&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;A = L * U&lt;/script&gt;, and where &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is unit lower triangular (1’s along the diagonal), and where &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; is upper triangular.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;LU_demo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; &quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A =  \begin{bmatrix}  7&amp; 5&amp; 4&amp; 6&amp; 7&amp; 1&amp; 4&amp; 1&amp; 1&amp; 2 \\
            9&amp; 1&amp; 2&amp; 2&amp; 4&amp; 8&amp; 9&amp; 5&amp; 4&amp; 5 \\
            6&amp; 5&amp; 6&amp; 2&amp; 1&amp; 5&amp; 6&amp; 2&amp; 7&amp; 4 \\
            6&amp; 8&amp; 3&amp; 6&amp; 2&amp; 5&amp; 8&amp; 4&amp; 7&amp; 3 \\
            6&amp; 7&amp; 6&amp; 7&amp; 8&amp; 4&amp; 8&amp; 7&amp; 8&amp; 8 \\
            4&amp; 4&amp; 4&amp; 4&amp; 5&amp; 2&amp; 1&amp; 7&amp; 4&amp; 2 \\
            3&amp; 7&amp; 4&amp; 9&amp; 7&amp; 5&amp; 3&amp; 8&amp; 2&amp; 3 \\
            7&amp; 1&amp; 8&amp; 8&amp; 7&amp; 6&amp; 4&amp; 8&amp; 5&amp; 8 \\
            4&amp; 5&amp; 3&amp; 5&amp; 1&amp; 4&amp; 6&amp; 4&amp; 3&amp; 3 \\
            3&amp; 3&amp; 3&amp; 3&amp; 7&amp; 4&amp; 5&amp; 2&amp; 5&amp; 9 \end{bmatrix}, M_0 = \begin{bmatrix} 1.     &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -1.285 &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -1.    &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        \\
                -0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        \\
                -0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.       \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;LU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; 
	Alternatively, we could compute multipliers,
	update the A matrix entries that change 
	(lower square block), and then store the
	multipliers in the empty, lower triangular part of A.
	&quot;&quot;&quot;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# loop over the columns of U&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;c&quot;&gt;# compute multipliers for each row under the diagonal&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;c&quot;&gt;# must update the matrix to compute&lt;/span&gt;
		&lt;span class=&quot;c&quot;&gt;# multipliers for next column&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;pdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_trace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# left-multiply higher M matrices&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Suppose we wish to see how &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; changes when &lt;script type=&quot;math/tex&quot;&gt;M_0&lt;/script&gt; is applied: the zero’th column is now upper triangular.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
M_0 A = \begin{bmatrix} 7. &amp;  5. &amp;  4. &amp;  6. &amp;  7. &amp;  1. &amp;  4. &amp;  1. &amp;  1. &amp;  2.  \\
			 0. &amp; -5.4&amp; -3.1&amp; -5.7&amp; -5. &amp;  6.7&amp;  3.9&amp;  3.7&amp;  2.7&amp;  2.4 \\
			 0. &amp;  0.7&amp;  2.6&amp; -3.1&amp; -5. &amp;  4.1&amp;  2.6&amp;  1.1&amp;  6.1&amp;  2.3 \\
			 0. &amp;  3.7&amp; -0.4&amp;  0.9&amp; -4. &amp;  4.1&amp;  4.6&amp;  3.1&amp;  6.1&amp;  1.3 \\
			 0. &amp;  2.7&amp;  2.6&amp;  1.9&amp;  2. &amp;  3.1&amp;  4.6&amp;  6.1&amp;  7.1&amp;  6.3 \\
			 0. &amp;  1.1&amp;  1.7&amp;  0.6&amp;  1. &amp;  1.4&amp; -1.3&amp;  6.4&amp;  3.4&amp;  0.9 \\
			 0. &amp;  4.9&amp;  2.3&amp;  6.4&amp;  4. &amp;  4.6&amp;  1.3&amp;  7.6&amp;  1.6&amp;  2.1 \\
			 0. &amp; -4. &amp;  4. &amp;  2. &amp;  0. &amp;  5. &amp;  0. &amp;  7. &amp;  4. &amp;  6.  \\
			 0. &amp;  2.1&amp;  0.7&amp;  1.6&amp; -3. &amp;  3.4&amp;  3.7&amp;  3.4&amp;  2.4&amp;  1.9 \\
			 0. &amp;  0.9&amp;  1.3&amp;  0.4&amp;  4. &amp;  3.6&amp;  3.3&amp;  1.6&amp;  4.6&amp;  8.1 \end{bmatrix}, A = \begin{bmatrix}  7&amp; 5&amp; 4&amp; 6&amp; 7&amp; 1&amp; 4&amp; 1&amp; 1&amp; 2 \\
            9&amp; 1&amp; 2&amp; 2&amp; 4&amp; 8&amp; 9&amp; 5&amp; 4&amp; 5 \\
            6&amp; 5&amp; 6&amp; 2&amp; 1&amp; 5&amp; 6&amp; 2&amp; 7&amp; 4 \\
            6&amp; 8&amp; 3&amp; 6&amp; 2&amp; 5&amp; 8&amp; 4&amp; 7&amp; 3 \\
            6&amp; 7&amp; 6&amp; 7&amp; 8&amp; 4&amp; 8&amp; 7&amp; 8&amp; 8 \\
            4&amp; 4&amp; 4&amp; 4&amp; 5&amp; 2&amp; 1&amp; 7&amp; 4&amp; 2 \\
            3&amp; 7&amp; 4&amp; 9&amp; 7&amp; 5&amp; 3&amp; 8&amp; 2&amp; 3 \\
            7&amp; 1&amp; 8&amp; 8&amp; 7&amp; 6&amp; 4&amp; 8&amp; 5&amp; 8 \\
            4&amp; 5&amp; 3&amp; 5&amp; 1&amp; 4&amp; 6&amp; 4&amp; 3&amp; 3 \\
            3&amp; 3&amp; 3&amp; 3&amp; 7&amp; 4&amp; 5&amp; 2&amp; 5&amp; 9 \end{bmatrix} %]]&gt;&lt;/script&gt;
I’m actually rounding the entries above, i.e. showing the output of:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A fact that makes computing the inverses of these elementary GE matrices trivial: simply negate the spike entries below the diagonal.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
M_0 = \begin{bmatrix} 1.     &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -1.285 &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.857 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                -1.    &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        \\
                -0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        \\
                -0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.       \\
\end{bmatrix},  M_0^{-1} = \begin{bmatrix} 1.     &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                1.285 &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                0.857 &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                0.857 &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                0.857 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 1.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  1.        &amp;  0.        &amp;  0.        &amp;  0.        \\
                1.    &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  1.        &amp;  0.        &amp;  0.        \\
                0.571 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  1.        &amp;  0.        \\
                0.428 &amp;  0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp; 0.        &amp;  0.        &amp;  0.        &amp;  0.        &amp;  1.       \\
\end{bmatrix} %]]&gt;&lt;/script&gt;
Indeed, &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is lower-triangular and &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; is upper-triangular, as desired:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
L = \begin{bmatrix}   1.&amp;    0.&amp;   0.&amp;    0.&amp;   0.&amp;    0.&amp;    0.&amp;    0.&amp;   0. &amp; 0. \\
    1.&amp;    1.&amp;    0.&amp;   0.&amp;    0.&amp;    0.&amp;    0.&amp;    0.&amp;   0.&amp; 0. \\
    1.&amp;   0.&amp;    1.&amp;   0.&amp;   0.&amp;   0.&amp;    0.&amp;    0.&amp;    0.&amp; 0. \\
    1.&amp;   -1.&amp;   -1.&amp;    1.&amp;   0.&amp;    0.&amp;   0.&amp;   0.&amp;   0.&amp; 0. \\
    1.&amp;   0.&amp;    0.&amp;   0.&amp;    1.&amp;   0.&amp;    0.&amp;   0.&amp;    0. &amp; 0. \\
    1.&amp;   0.&amp;    0.&amp;   0.&amp;    1.&amp;    1.&amp;    0.&amp;    0.&amp;    0.&amp; 0. \\
    0.&amp;   -1.&amp;   -0.&amp;   0.&amp;   -4.&amp;  -69.&amp;    1.&amp;   0.&amp;   0. &amp; 0. \\
    1.&amp;    1.&amp;    3.&amp;   -2.&amp;  -19.&amp; -249.&amp;    4.&amp;    1.&amp;   0. &amp; 0. \\
    1.&amp;   0.&amp;   0.&amp;    0.&amp;   -5.&amp;  -67.&amp;    1.&amp;    0.&amp;    1.&amp; 0. \\
    0.&amp;   0.&amp;    0.&amp;   -0.&amp;    6.&amp;   53.&amp;   -1.&amp;   0.&amp;   -1.&amp; 1. \end{bmatrix} , U =  \begin{bmatrix}  7. &amp;    5. &amp;    4. &amp;    6. &amp;    7. &amp;    1. &amp;    4. &amp;    1. &amp;  1. &amp;    2.  \\
   0. &amp;   -5.4&amp;   -3.1&amp;   -5.7&amp;   -5. &amp;    6.7&amp;    3.9&amp;    3.7&amp;  2.7&amp;    2.4 \\
   0. &amp;    0. &amp;    2.2&amp;   -3.9&amp;   -5.7&amp;    5. &amp;    3.1&amp;    1.6&amp;   6.5&amp;    2.6 \\
   0. &amp;    0. &amp;    0. &amp;   -7.7&amp;  -14.2&amp;   14.7&amp;   10.9&amp;    7.6&amp;   15.8&amp;    6.1 \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0.6&amp;    5.7&amp;    6.2&amp;    8. &amp;  7.1&amp;    6.9 \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;   -0.5&amp;   -3.8&amp;    3. &amp;  -0.7&amp;   -2.9 \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp; -230.1&amp;  247.9&amp; -15.8&amp; -169.  \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;   33.3&amp; 27.7&amp;    8.8 \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp; -3.7&amp;   -0.8 \\
   0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp;    0. &amp; 0. &amp;    3.   \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;There is a very small amount of numerical error introduced in the process:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i,j} (A - LU) = 2.80 \times 10^{-12}&lt;/script&gt;

&lt;h2 id=&quot;cholesky&quot;&gt;Cholesky&lt;/h2&gt;</content><author><name></name></author><summary type="html">LU, Cholesky, QR</summary></entry><entry><title type="html">Image Derivatives and the Harris Corner Detector</title><link href="http://johnwlambert.github.io/image-derivatives-harris/" rel="alternate" type="text/html" title="Image Derivatives and the Harris Corner Detector" /><published>2019-01-24T06:01:00-05:00</published><updated>2019-01-24T06:01:00-05:00</updated><id>http://johnwlambert.github.io/image-derivatives-harris</id><content type="html" xml:base="http://johnwlambert.github.io/image-derivatives-harris/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;Image Derivatives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Summed-Square Difference Error&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;The Autocorrelation (AC) Surface&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Taylor Approximations of the AC Surface&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;The Harris Corner Detector&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Ellipse Analogy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-derivatives&quot;&gt;Image Derivatives&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    ksize = 7
    sigma = 5

    g = cv2.getGaussianKernel(ksize=ksize, sigma=sigma)
    small_filter = g * g.T
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_approx_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'np_grad'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_approx_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'finite_diff'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# compute gradient on x-direction&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# compute gradient on y-direction&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_approx_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'cv2_sobel'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sobel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CV_64F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sobel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CV_64F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_approx_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'scipy_sobel'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sobel_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sobel_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convolve2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;in1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;in2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sobel_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;boundary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'fill'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;fillvalue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convolve2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;in1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;in2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sobel_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;boundary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'fill'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;fillvalue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ky&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;image-derivatives-1&quot;&gt;Image Derivatives&lt;/h2&gt;

&lt;p&gt;Great question – there are a number of ways to do it, and they will all give different results.&lt;/p&gt;

&lt;p&gt;Convolving (not cross-correlation filtering) with the Sobel filter is a good way to approximate image derivatives (here we could treat a Gaussian filter as the image to find its derivatives).&lt;/p&gt;

&lt;p&gt;We’ve recommended a number of potentially useful OpenCV and SciPy functions that can do so in the project page. These will be very helpful!&lt;/p&gt;

&lt;p&gt;Another simple way to approximate the derivative is to calculate the 1st discrete difference along the given axis. For example, in order to compute horizontal discrete differences, shift the image by 1 pixel to the left and subtract the two&lt;/p&gt;

&lt;p&gt;For example, suppose you have a matrix b&lt;/p&gt;

&lt;p&gt;b = np.array([[  0,   1,   1,   2],&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   [  3,   5,   8,  13],

   [ 21,  34,  55,  89],

   [144, 233, 377, 610]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;b[:,1:] - b[:,:-1]
We would get:&lt;/p&gt;

&lt;p&gt;array([[  1,   0,   1],&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   [  2,   3,   5],

   [ 13,  21,  34],

   [ 89, 144, 233]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then we could the pad the matrix with zeros on the right column to bring it back to the original size.&lt;/p&gt;

&lt;h2 id=&quot;sobel-vs-gaussian&quot;&gt;Sobel vs. Gaussian&lt;/h2&gt;

&lt;p&gt;Hi, I’m trying to decide which is a better way to compute the gradient for the Harris corner detection, before I compute my cornerness function. I’m confused about the difference between both.&lt;/p&gt;

&lt;p&gt;If I run just Sobel on my image, that means I’m getting the derivative, and smoothing with Gaussian in one go, right? And if I want to use Gaussian, I find the derivatives of the pixels, and apply Gaussian separately on the image? Not sure if one way is better than the other, and why.&lt;/p&gt;

&lt;p&gt;You can also do both with one filter.&lt;/p&gt;

&lt;p&gt;Suppose we have the image  &lt;script type=&quot;math/tex&quot;&gt;I&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
I = \begin{bmatrix}a &amp; b &amp; c \\d &amp; e &amp; f \\g &amp; h &amp; i\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;One way to think about the Sobel x-derivative filter is that rather than looking at only &lt;script type=&quot;math/tex&quot;&gt;\frac{rise}{run}=\frac{f-d}{2}&lt;/script&gt; (centered at pixel e), we also use the x-derivatives above it and below it, e.g. &lt;script type=&quot;math/tex&quot;&gt;\frac{c-a}{2}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\frac{i-g}{2}&lt;/script&gt;. But we weight the x-derivative in the center the most (this is a form of smoothing) so we use an approximation like&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{ 2 \cdot (f-d) + (i-g)+ (c-a) }{8}&lt;/script&gt;

&lt;p&gt;meaning our kernel resembles&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{1}{8}\begin{bmatrix}1 &amp; 0 &amp; -1 \\2 &amp; 0 &amp; -2 \\1 &amp; 0 &amp; -1\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;It is actually derived with directional derivatives.
https://www.researchgate.net/publication/239398674_An_Isotropic_3_3_Image_Gradient_Operator&lt;/p&gt;

&lt;p&gt;This is not identical to first blurring the image with a Gaussian filter, and then computing derivatives. We blur the image first because it makes the gradients less noisy.&lt;/p&gt;

&lt;p&gt;https://d1b10bmlvqabco.cloudfront.net/attach/jl1qtqdkuye2rp/jl1r1s4npvog2/jm1ficspl6jw/smoothing_gradients.png&lt;/p&gt;

&lt;p&gt;https://d1b10bmlvqabco.cloudfront.net/attach/jl1qtqdkuye2rp/jl1r1s4npvog2/jm1fiqeigs2g/derivative_theorem.png&lt;/p&gt;

&lt;p&gt;And an elegant fact that can save a step in smoothed gradient computation is to simply blur with the x and y derivatives of a Gaussian filter, by the following property:&lt;/p&gt;

&lt;p&gt;http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture5_edges_cs131_2016.pdf
Slides&lt;/p&gt;

&lt;h2 id=&quot;the-autocorrelation-functionsurface&quot;&gt;The Autocorrelation Function/Surface&lt;/h2&gt;

&lt;p&gt;Suppose we wish to match a keypoint in image &lt;script type=&quot;math/tex&quot;&gt;I_0&lt;/script&gt; with a keypoint in an image &lt;script type=&quot;math/tex&quot;&gt;I_1&lt;/script&gt;. Matching RGB values at a single pixel location will be completely uninformative. However, comparing &lt;em&gt;local patches&lt;/em&gt; around the supposed keypoints can be quite effective because the local window captures necessary context.&lt;/p&gt;

&lt;p&gt;Suppose we shift image &lt;script type=&quot;math/tex&quot;&gt;I_1&lt;/script&gt; by displacement &lt;script type=&quot;math/tex&quot;&gt;\mathbf{u} = (u,v)&lt;/script&gt;, and then compare its shifted RGB values with &lt;script type=&quot;math/tex&quot;&gt;I_0&lt;/script&gt;. This function of weighted summed square difference (WSSD) error is known as the autocorrelation function or surface [1]. We compute the values of this function at every single possible displacement &lt;script type=&quot;math/tex&quot;&gt;\mathbf{u}&lt;/script&gt;. We loop over &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; locations in the local window neighborhood and at each &lt;script type=&quot;math/tex&quot;&gt;x_i = (x,y)&lt;/script&gt;, compute the difference:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E_{WSSD}(\mathbf{u}) = \sum\limits_i w(x_i)\bigg[I_1(x_i + \mathbf{u}) − I_0(x_i)\bigg]^2&lt;/script&gt;

&lt;p&gt;This is accomplished in a few lines of Python (&lt;a href=&quot;https://gist.github.com/johnwlambert/b5e8fb75a8b474ad90f37d95af523b41&quot;&gt;code here&lt;/a&gt;):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;window_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patch_img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;window_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patch_img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;img_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mtn_img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mtn_img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;e_ssd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# start at top-left corner&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;e_ssd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mtn_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patch_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;fig figcenter fighighlight&quot;&gt;
  &lt;img src=&quot;/assets/mtn_img_centered_full.png&quot; width=&quot;49%&quot; /&gt;
    &lt;img src=&quot;/assets/mtn_img_centered_patch.png&quot; width=&quot;20%&quot; /&gt;
  &lt;div class=&quot;figcaption&quot;&gt;
    Left: Original mountain scene from [1]. Right: Centered patch cropped from the image.
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;fig figcenter fighighlight&quot;&gt;
  &lt;img src=&quot;/assets/surface_3d_view.png&quot; width=&quot;30%&quot; /&gt;
  &lt;img src=&quot;/assets/overhead_surface.png&quot; width=&quot;30%&quot; /&gt;
  &lt;img src=&quot;/assets/localized_patch.png&quot; width=&quot;30%&quot; /&gt;

  &lt;div class=&quot;figcaption&quot;&gt;
    Left: 3D surface plot of the error function. Blue is lower error, red is higher error. Center: Overhead (bird's eye view) of the 3D surface plot. Right: The localized patch, computed using the displacement that minimizes the error function, is plotted in red.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;However, this method is unbelievable slow – it took 25 minutes even to localize this simple patch within an image.&lt;/p&gt;

&lt;p&gt;When performing keypoint detection, we want to match local patches between images. However, we don’t know which local patches are the most informative, so we compute an “informativeness” score: how stable the WSSD function is with respect to small variations in position (&lt;script type=&quot;math/tex&quot;&gt;\Delta \mathbf{u}&lt;/script&gt;).&lt;/p&gt;

&lt;h2 id=&quot;taylor-approximation-the-autocorrelation-matrix&quot;&gt;Taylor Approximation: The Autocorrelation Matrix&lt;/h2&gt;

&lt;p&gt;Unfortunately, it turns out that the autocorrelation function is extraordinarily slow to evaluate.&lt;/p&gt;

&lt;p&gt;The &lt;script type=&quot;math/tex&quot;&gt;*&lt;/script&gt; in the equation you’ve written is not multiplication – it is convolution. Szeliski [1] states that he has “replaced the weighted summations with discrete convolutions with the weighting kernel &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;”.&lt;/p&gt;

&lt;p&gt;So before we had values &lt;script type=&quot;math/tex&quot;&gt;w(x,y)&lt;/script&gt; that could have been values from a Gaussian probability density function. Let &lt;script type=&quot;math/tex&quot;&gt;z = \begin{bmatrix} x \\ y \end{bmatrix}&lt;/script&gt; be the stacked 2D coordinate locations.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w(z) = \frac{1}{(2 \pi)^{n/2} |\Sigma|^{1/2}} \mbox{exp} \Bigg( - \frac{1}{2} (z − \mu)^T \Sigma^{-1} (z − \mu) \Bigg)&lt;/script&gt;

&lt;p&gt;For example, where &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; is the center pixel location and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; is the location of each pixel in the local neighborhood. These were used as weights in summations over a local neighborhood,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
M = \sum\limits_{x,y} w(x,y) \begin{bmatrix}I_x^2 &amp; I_xI_y \\I_xI_y &amp; I_y^2\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;But the elegant convolution approach is used here because it is equivalent to summing a bunch of elementwise multiplications –  each point in a local neighborhood with its weight value (as we saw in Proj 1, and here filtering is equivalent to convolution since Gaussian filter is symmetric).&lt;/p&gt;

&lt;h2 id=&quot;the-harris-corner-detector&quot;&gt;The Harris Corner Detector&lt;/h2&gt;

&lt;p&gt;A gaussian filter is expressed as &lt;script type=&quot;math/tex&quot;&gt;g(\sigma_1)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The second moment matrix at each pixel is convolved as follows:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\mu(\sigma_1,\sigma_D) = g(\sigma_1) * \begin{bmatrix} I_x^2 (\sigma_D) &amp; I_xI_y (\sigma_D) \\ I_xI_y (\sigma_D) &amp; I_{y}^2 (\sigma_D) \end{bmatrix} %]]&gt;&lt;/script&gt;
Giving a cornerness function in the lecture slides:
&lt;script type=&quot;math/tex&quot;&gt;har = \mbox{ det }[\mu(\sigma_1,\sigma_D)] - \alpha[\mbox{trace }\Big(\mu(\sigma_1,\sigma_D)\Big)]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;or, when evaluated,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;har = g(I_x^2)g(I_y^2) - [g(I_xI_y)]^2 - \alpha [g(I_x^2) + g(I_y^2)]^2&lt;/script&gt;

&lt;p&gt;So in the lecture slides notation, we can write &lt;script type=&quot;math/tex&quot;&gt;\mu(\sigma_1,\sigma_D)&lt;/script&gt; more simply by bringing in the filtering (identical to convolution here) operation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu(\sigma_1,\sigma_D) = \begin{bmatrix} g(\sigma_1) * I_x^2 (\sigma_D) &amp; g(\sigma_1) * I_xI_y (\sigma_D) \\ g(\sigma_1) * I_xI_y (\sigma_D) &amp; g(\sigma_1) * I_{y}^2 (\sigma_D) \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;It may be easier to understand if we write the equation in the following syntax:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu(\sigma_1,\sigma_D) = \begin{bmatrix} g(\sigma_1) * \Big(g(\sigma_D) * I_x \Big)^2 &amp; g(\sigma_1) * \Bigg[ \Big(g(\sigma_D) * I_x \Big) \odot \Big(g(\sigma_D) * I_x \Big) \Bigg] \\g(\sigma_1) * \Bigg[ \Big(g(\sigma_D) * I_x \Big) \odot \Big(g(\sigma_D) * I_x \Big) \Bigg] &amp; g(\sigma_1) * \Bigg[g(\sigma_D) * I_y \Bigg]^2\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;I should have explained that above – &lt;script type=&quot;math/tex&quot;&gt;\odot&lt;/script&gt; is the Hadamard product (element wise multiplication).&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Richard Szeliski. Computer Vision: Algorithms and Applications. &lt;a href=&quot;http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2] Fei-Fei Li. &lt;a href=&quot;http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture5_edges_cs131_2016.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author></entry><entry><title type="html">Graph Cuts and Flows in Computer Vision</title><link href="http://johnwlambert.github.io/graphs-cuts-flows/" rel="alternate" type="text/html" title="Graph Cuts and Flows in Computer Vision" /><published>2018-12-28T06:00:00-05:00</published><updated>2018-12-28T06:00:00-05:00</updated><id>http://johnwlambert.github.io/graph-cuts</id><content type="html" xml:base="http://johnwlambert.github.io/graphs-cuts-flows/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#whyliegroups&quot;&gt;Factor Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#liegroups&quot;&gt;Factor Densities&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#son&quot;&gt;MAP Inference on Factor Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so2&quot;&gt;Factor Graph Variable Elimanation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;whyliegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;min-cut-is-max-cost-flow&quot;&gt;Min Cut is Max-Cost Flow&lt;/h2&gt;

&lt;h2 id=&quot;min-cost-flow&quot;&gt;Min-Cost Flow&lt;/h2&gt;

&lt;p&gt;http://www.csd.uwo.ca/~yuri/Papers/pami04.pdf&lt;/p&gt;

&lt;p&gt;MIT 6.046J Design and Analysis of Algorithms, Spring 2015
View the complete course: http://ocw.mit.edu/6-046JS15
Instructor: Srinivas Devadas&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=VYZGlgzr_As&amp;amp;t=129s&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Factor Graphs for SLAM and SfM</title><link href="http://johnwlambert.github.io/factor-graphs/" rel="alternate" type="text/html" title="Factor Graphs for SLAM and SfM" /><published>2018-12-28T06:00:00-05:00</published><updated>2018-12-28T06:00:00-05:00</updated><id>http://johnwlambert.github.io/factor-graphs-slam</id><content type="html" xml:base="http://johnwlambert.github.io/factor-graphs/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#whyliegroups&quot;&gt;Factor Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#liegroups&quot;&gt;Factor Densities&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#son&quot;&gt;MAP Inference on Factor Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so2&quot;&gt;Factor Graph Variable Elimanation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;whyliegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;factor-graphs-for-robot-vision&quot;&gt;Factor Graphs for Robot Vision&lt;/h2&gt;

&lt;p&gt;A factor graph is a probabilistic graphical model, theory which represents the marriage of graph theory with probability.&lt;/p&gt;

&lt;p&gt;To use factor graphs for computer vision in robotics, we will need another tool: numerical linear algebra. These problems can be reformulated as very large least-squares problems. In fact, the size of the matrix that would not need be to inverted to solve the system of equations makes these problems solvable only by iterative methods, rather than direct methods.&lt;/p&gt;

&lt;h2 id=&quot;factor-graphs-background&quot;&gt;Factor Graphs: Background&lt;/h2&gt;

&lt;p&gt;A factor graph is a probabilistic graphical model (in the same family with Markov Random Fields (MRFs) and Bayesian Networks). It is an undirected graph (meaning there are no parents or topological ordering).&lt;/p&gt;

&lt;p&gt;Bayesian Networks are directed graphs where edges in the graph are associated with conditional probability distributions (CPDs), assigning the probability of children in the graph taking on certain values based on the values of the parents.&lt;/p&gt;

&lt;p&gt;In undirected models like MRFs and Factor Graphs, instead of specifying CPDs, we specify (non-negative) potential functions (or factors) over sets of variables associated with cliques (complete subgraphs) C of the graph.  Like Conditional Prob. Distributions, a factor/potential can be represented as a table, but it is not normalized (does not sum to one).&lt;/p&gt;

&lt;p&gt;A factor graph is a bipartite undirected graph with variable nodes (circles) and factor nodes (squares). Edges are only between the variable nodes and the factor nodes.&lt;/p&gt;

&lt;p&gt;The variable nodes can take on certain values, and the likelihood of that event for a set of variables is expressed in the potential (factor node) attached to those variables.  Each factor node is associated with a single potential, whose scope is the set of variables that are neighbors in the factor graph.&lt;/p&gt;

&lt;p&gt;A small example might make this clearer. Suppose we have a group of four people: Alex, Bob, Catherine, David A=Alex’s hair color (red, green, blue)&lt;/p&gt;

&lt;p&gt;B=Bob’s hair color&lt;/p&gt;

&lt;p&gt;C=Catherine’s hair color&lt;/p&gt;

&lt;p&gt;D=David’s hair color&lt;/p&gt;

&lt;p&gt;Alex and Bob are friends, Bob and Catherine are friends, Catherine and David are friends, David and Alex are friends&lt;/p&gt;

&lt;p&gt;Friends never have the same hair color!&lt;/p&gt;

&lt;p&gt;It turns out that this distribution p cannot be represented (perfectly) by any Bayesian network. But it is succinctly represented by a Factor Graph or MRF.
https://d1b10bmlvqabco.cloudfront.net/attach/jl1qtqdkuye2rp/jl1r1s4npvog2/jmsma7unw07s/Screen_Shot_20181002_at_11.48.05_PM.png&lt;/p&gt;

&lt;p&gt;The Factor Graph distribution is same as the MRF – this is just a different graph data structure.&lt;/p&gt;

&lt;h2 id=&quot;factor-densities&quot;&gt;Factor Densities&lt;/h2&gt;

&lt;p&gt;The most often used probability densities involve the multi-variate Gaussian distribution [1], whose density is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x \sim p(x) = \mathcal{N}(\mu, \Sigma) = 
\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\mbox{exp}
\Big\{ -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \Big\}&lt;/script&gt;

&lt;p&gt;For the sake of brevity, we can write this as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x \sim p(x) = \mathcal{N}(\mu, \Sigma) = 
\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\mbox{exp}
\Big\{ -\frac{1}{2} \|(x - \mu)^T \|_{\Sigma^{-1}}^2 \Big\}&lt;/script&gt;

&lt;h2 id=&quot;map-inference-on-factor-graphs&quot;&gt;MAP Inference on Factor Graphs&lt;/h2&gt;

&lt;p&gt;MAP inference in SLAM is exactly the process of determining those
values for the unknowns that maximally agree with the information
present in the uncertain measurements [1]&lt;/p&gt;

&lt;p&gt;We wish to solve for &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, the position of the robot at all timesteps.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
X^{MAP} &amp;= \mbox{arg }\underset{X}{\mbox{max }} \phi(X) &amp; \mbox{Maximum likelihood Defn.} \\
 &amp;= \mbox{arg }\underset{X}{\mbox{max }} \prod\limits_i \phi_i(X_i) &amp; \mbox{text} \\
  &amp;= \mbox{arg }\underset{X}{\mbox{max }} \prod\limits_i \mbox{exp } \bigg\{ -\frac{1}{2}\|h_i(X_i) - z_i\|_{\Sigma_i}^2 \bigg\} &amp; \mbox{Use Gaussian prior and likelihood factors} \\
    &amp;= \mbox{arg }\underset{X}{\mbox{max }} \mbox{log } \prod\limits_i  \mbox{exp } \bigg\{ -\frac{1}{2}\|h_i(X_i) - z_i\|_{\Sigma_i}^2 \bigg\} &amp; \mbox{Log is monotonically increasing} \\
     &amp;= \mbox{arg }\underset{X}{\mbox{max }} \sum\limits_i \mbox{log }   \mbox{exp } \bigg\{ -\frac{1}{2}\|h_i(X_i) - z_i\|_{\Sigma_i}^2 \bigg\} &amp; \mbox{Log of a product is a sum of logs.} \\
       &amp;= \mbox{arg }\underset{X}{\mbox{max }} \sum\limits_i  \bigg( -\frac{1}{2}\|h_i(X_i) - z_i\|_{\Sigma_i}^2 \bigg) &amp; \mbox{Simplify } f(f^{-1}(x))=x \\
        &amp;= \mbox{arg }\underset{X}{\mbox{min }} \sum\limits_i  \bigg( \frac{1}{2}\|h_i(X_i) - z_i\|_{\Sigma_i}^2 \bigg) &amp; \mbox{Max of } -f(x) \mbox{ is min of } f(x) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We’ve reduce the problem to minimization of a sum of nonlinear least-squares.&lt;/p&gt;

&lt;p&gt;Along the way, we decided to maximize the log-likelihood instead of the likelihood because the argument that maximizes the log of a function also maximizes the function itself.&lt;/p&gt;

&lt;h2 id=&quot;factor-graph-variable-elimanation&quot;&gt;Factor Graph Variable Elimanation&lt;/h2&gt;

&lt;p&gt;If you’re wondering about the variable elimination part, we choose subsets of variables connected by factors and start combining them by taking the product of their factors and marginalizing out variables.&lt;/p&gt;

&lt;p&gt;In the table above, we have variables as the columns and factors as the rows. We can combines factors progressively to involve more and more variables.&lt;/p&gt;

&lt;p&gt;https://d1b10bmlvqabco.cloudfront.net/attach/jl1qtqdkuye2rp/jl1r1s4npvog2/jmtgs7d71g2p/Screen_Shot_20181003_at_2.05.56_PM.png&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Frank Dellaert and Michael Kaess. &lt;em&gt;Factor Graphs for Robot Perception&lt;/em&gt;. Foundations and Trends in Robotics, Vol. 6, No. 1-2 (2017) 1–139. &lt;a href=&quot;https://www.ri.cmu.edu/wp-content/uploads/2018/05/Dellaert17fnt.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2] Stefano Ermon.&lt;/p&gt;</content><author><name></name></author><summary type="html">Gaussian densities, direct methods, iterative methods</summary></entry><entry><title type="html">Lie Groups and Rigid Body Kinematics</title><link href="http://johnwlambert.github.io/lie-groups/" rel="alternate" type="text/html" title="Lie Groups and Rigid Body Kinematics" /><published>2018-12-28T06:00:00-05:00</published><updated>2018-12-28T06:00:00-05:00</updated><id>http://johnwlambert.github.io/lie-groups</id><content type="html" xml:base="http://johnwlambert.github.io/lie-groups/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#whyliegroups&quot;&gt;Why do we need Lie Groups?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#liegroups&quot;&gt;Lie Groups&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#son&quot;&gt;SO(N)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so2&quot;&gt;SO(2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so3&quot;&gt;SO(3)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#se2&quot;&gt;SE(2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#se3&quot;&gt;SE(3)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conjugation&quot;&gt;Conjugation in Group Theory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lie-algebra&quot;&gt;The Lie Algebra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;whyliegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-do-we-need-lie-groups&quot;&gt;Why do we need Lie Groups?&lt;/h2&gt;

&lt;p&gt;Rigid bodies have a state which consists of position and orientation. When sensors are placed on a rigid body (e.g. a robot), they provide measurements in the body frame. Suppose we wish to take a measurement &lt;script type=&quot;math/tex&quot;&gt;y_b&lt;/script&gt; from the body frame and move it to the world frame, &lt;script type=&quot;math/tex&quot;&gt;y_w&lt;/script&gt;. We can do this via left multiplication with a transformation matrix &lt;script type=&quot;math/tex&quot;&gt;{}^{w}T_{b}&lt;/script&gt;, a member of the matrix Lie groups, that transports the point from one space to another space:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_w = {}^{w}T_{b} y_b&lt;/script&gt;

&lt;h2 id=&quot;what-is-a-group&quot;&gt;What is a &lt;em&gt;group&lt;/em&gt;?&lt;/h2&gt;
&lt;p&gt;A group is a set &lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt;, with an operation of (binary) multiplication &lt;script type=&quot;math/tex&quot;&gt;\circ&lt;/script&gt; on elements of &lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt; which is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;closed: If &lt;script type=&quot;math/tex&quot;&gt;g_1, g_2 \in G&lt;/script&gt; then also &lt;script type=&quot;math/tex&quot;&gt;g_1 \circ g_2 \in G&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;associative: &lt;script type=&quot;math/tex&quot;&gt;(g_1 \circ g_2) \circ g_3 = g_1 \circ (g_2 \circ g_3)&lt;/script&gt;, for all &lt;script type=&quot;math/tex&quot;&gt;g_1, g_2, g_3 \in G&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;unit element &lt;script type=&quot;math/tex&quot;&gt;e&lt;/script&gt;: &lt;script type=&quot;math/tex&quot;&gt;e \circ g = g \circ e = g&lt;/script&gt;, for all &lt;script type=&quot;math/tex&quot;&gt;g \in G&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;invertible: For every element &lt;script type=&quot;math/tex&quot;&gt;g \in G&lt;/script&gt;, there exists an element &lt;script type=&quot;math/tex&quot;&gt;g^{−1} \in G&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;g \circ g^{−1} = g^{−1} \circ g = e&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More details can be found in [5].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;liegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;lie-groups&quot;&gt;Lie Groups&lt;/h2&gt;

&lt;p&gt;When we are working with pure rotations, we work with Special Orthogonal groups, &lt;script type=&quot;math/tex&quot;&gt;SO(\cdot)&lt;/script&gt;. When we are working with a rotation and a translation together, we work with Special Euclidean groups &lt;script type=&quot;math/tex&quot;&gt;SE(\cdot)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Lie Groups are unique because they are &lt;strong&gt;both a group and a manifold&lt;/strong&gt;. They are continuous manifolds in high-dimensional spaces, and have a group structure. I’ll describe them in more detail below.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;son&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;son&quot;&gt;SO(N)&lt;/h3&gt;

&lt;p&gt;Membership in the Special Orthogonal Group &lt;script type=&quot;math/tex&quot;&gt;SO(N)&lt;/script&gt; requires two matrix properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;R^TR = I&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{det}(R) = +1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This gives us a very helpful property: &lt;script type=&quot;math/tex&quot;&gt;R^{-1} = R^T&lt;/script&gt;, so the matrix inverse is as simple as taking the transpose.  We will generally work with &lt;script type=&quot;math/tex&quot;&gt;SO(N)&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;N=2,3&lt;/script&gt;, meaning the matrices are rotation matrices &lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{2 \times 2}&lt;/script&gt; or &lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{3 \times 3}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;These rotation matrices &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt; are not commutative.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;so2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;so2&quot;&gt;SO(2)&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt; is a 1D manifold living in a 2D Euclidean space, e.g. moving around a circle.  We will be stuck with singularities if we use 2 numbers to parameterize it, which would mean kinematics break down at certain orientations.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt; is the space of orthogonal matrices that corresponds to rotations in the plane.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A simple example&lt;/strong&gt;:
Let’s move from the body frame &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; to a target frame &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_t = {}^tR_b(\theta) P_b&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
5 \mbox{ cos} (\theta) \\
5 \mbox{ sin} (\theta)
\end{bmatrix} = \begin{bmatrix} cos(\theta) &amp; -sin(\theta) \\ sin(\theta) &amp; cos(\theta) \end{bmatrix} * \begin{bmatrix} 5 \\ 0 \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;As described in [3], another way to think of this is to consider that a robot can be rotated counterclockwise by some angle &lt;script type=&quot;math/tex&quot;&gt;\theta \in [0,2 \pi)&lt;/script&gt; by mapping every &lt;script type=&quot;math/tex&quot;&gt;(x,y)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(x, y) \rightarrow (x \mbox{ cos } \theta − y \mbox{ sin } \theta, x \mbox{ sin } \theta + y \mbox{ cos } \theta).&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;so3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;so3&quot;&gt;SO(3)&lt;/h3&gt;

&lt;p&gt;There are several well-known parameterizations of &lt;script type=&quot;math/tex&quot;&gt;R \in SO(3)&lt;/script&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{3 \times 3}&lt;/script&gt; full rotation matrix, 9 parameters – there must be 6 constraints&lt;/li&gt;
  &lt;li&gt;Euler angles, e.g. &lt;script type=&quot;math/tex&quot;&gt;(\phi, \theta, \psi)&lt;/script&gt;, so 3 parameters&lt;/li&gt;
  &lt;li&gt;Angle-Axis parameters &lt;script type=&quot;math/tex&quot;&gt;(\vec{a}, \phi)&lt;/script&gt;, which is 4 parameters and 1 constraint (unit length)&lt;/li&gt;
  &lt;li&gt;Quaternions (&lt;script type=&quot;math/tex&quot;&gt;q_0,q_1,q_2,q_3)&lt;/script&gt;, 4 parameters and 1 constraint (unit length)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are only 3 degrees of freedom in describing a rotation. But this object doesn’t live in 3D space. It is a 3D manifold, embedded in a 4-D Euclidean space.&lt;/p&gt;

&lt;p&gt;Parameterizations 1,3,4 are overconstrained, meaning they employ more parameters than we strictly need. With overparameterized representations, we have to do extra work to make sure we satisfy the constraints of the representation.&lt;/p&gt;

&lt;p&gt;As it turns out &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; cannot be parameterized by only 3 parameters in a non-singular way.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Euler Angles&lt;/strong&gt;
One parameterization of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; is to imagine three successive rotations around different axes. The Euler angles encapsulate yaw-pitch-roll: first, a rotation about the z-axis (yaw, &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;). Then, a rotation about the pitch axis by &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (via right-hand rule), and finally we perform a roll by &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;.&lt;/p&gt;

&lt;div class=&quot;fig figcenter fighighlight&quot;&gt;
  &lt;img src=&quot;/assets/euler_angles.jpg&quot; width=&quot;65%&quot; /&gt;
  &lt;div class=&quot;figcaption&quot;&gt;
    The Euler angles.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The sequence of successive rotations is encapsulated in &lt;script type=&quot;math/tex&quot;&gt;{}^{w}R_b&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{w}R_b = R_R(\phi) R_P(\theta) R_Y (\psi)&lt;/script&gt;

&lt;p&gt;As outlined in [3], these successive rotations by &lt;script type=&quot;math/tex&quot;&gt;(\phi, \theta, \psi)&lt;/script&gt; are defined by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{yaw} = R_y (\psi) = \begin{bmatrix}
\mbox{cos} \psi &amp; -\mbox{sin} \psi  &amp; 0 \\
\mbox{sin} \psi &amp; \mbox{cos} \psi &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{pitch} = R_p (\theta) = \begin{bmatrix}
\mbox{cos} \theta &amp; 0 &amp; \mbox{sin} \theta \\
 0 &amp; 1 &amp; 0 \\
 -\mbox{sin} \theta &amp; 0 &amp; \mbox{cos} \theta \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{roll} = R_R (\phi) = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; \mbox{cos} \phi &amp; -\mbox{sin} \phi \\
0 &amp; \mbox{sin} \phi &amp;  \mbox{cos} \phi \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;You have probably noticed that each rotation matrix &lt;script type=&quot;math/tex&quot;&gt;\in \mathbf{R}^{3 \times 3}&lt;/script&gt; above is a simple extension of the 2D rotation matrix from &lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt;. For example, the yaw matrix &lt;script type=&quot;math/tex&quot;&gt;R_{yaw}&lt;/script&gt; performs a 2D rotation with respect to the &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; coordinates while leaving the &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; coordinate unchanged [3].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;se2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;se2&quot;&gt;SE(2)&lt;/h3&gt;

&lt;p&gt;The real space &lt;script type=&quot;math/tex&quot;&gt;SE(2)&lt;/script&gt; are &lt;script type=&quot;math/tex&quot;&gt;3 \times 3&lt;/script&gt; matrices, moving a point in homogenous coordinates to a new frame. It is important to remember that this represents a rotation followed by a translation (not the other way around).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
T = \begin{bmatrix} x_w \\ y_w \\ 1 \end{bmatrix} = \begin{bmatrix}
 R_{2 \times 2}&amp; &amp; t_{2 \times 1}  \\
&amp; \ddots &amp; \vdots  \\
0 &amp; 0 &amp; 1
\end{bmatrix} * \begin{bmatrix} x_b \\ y_b \\ 1 \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;By adding an extra dimension to the input points and transformation matrix &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; the translational part of the transformation is absorbed [3].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;se3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;se3&quot;&gt;SE(3)&lt;/h3&gt;

&lt;p&gt;The set of rigid body motions, or special Euclidean transformations, is a (Lie) group, the so-called special Euclidean group, typically denoted as SE(3). The real space &lt;script type=&quot;math/tex&quot;&gt;SE(3)&lt;/script&gt; is a 6-dimensional manifold. Its dimensions is exactly the number of degrees of freedom of a free-floating rigid body in space [3]. &lt;script type=&quot;math/tex&quot;&gt;SE(3)&lt;/script&gt; can be parameterized with a &lt;script type=&quot;math/tex&quot;&gt;4 \times 4&lt;/script&gt; matrix as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
&amp; &amp; &amp; \\
&amp; R_{3 \times 3} &amp; &amp;  t_{3 \times 1} \\
&amp; &amp; &amp; \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;conjugation&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conjugation-in-group-theory&quot;&gt;Conjugation in Group Theory&lt;/h2&gt;

&lt;p&gt;Surprisingly, movement in &lt;script type=&quot;math/tex&quot;&gt;SE(2)&lt;/script&gt; can always be achieved by moving somewhere, making a rotation there, and then moving back.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SE(2) = (\cdot) SO(2) (\cdot)&lt;/script&gt;

&lt;p&gt;If we move to a point by vector movement &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;, essentially we perform: &lt;script type=&quot;math/tex&quot;&gt;B-p&lt;/script&gt;, then go back with &lt;script type=&quot;math/tex&quot;&gt;p + \dots&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
B^{\prime} = \begin{bmatrix}
R &amp; t \\
0 &amp; 1
\end{bmatrix}_B = \begin{bmatrix}
I &amp; p \\
0 &amp; 1
\end{bmatrix} \begin{bmatrix}
R &amp; 0 \\
0 &amp; 1
\end{bmatrix} \begin{bmatrix}
I &amp; -p \\
0 &amp; 1
\end{bmatrix}_B %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;lie-algebra&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;connecting-spatial-coordinates-and-spatial-velocities-the-lie-algebra&quot;&gt;Connecting Spatial Coordinates and Spatial Velocities: The Lie Algebra&lt;/h2&gt;

&lt;p&gt;The Lie Algebra maps spatial coordinates to spatial velocity.&lt;/p&gt;

&lt;p&gt;In the case of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt;, the Lie Algebra is the space of skew-symmetric matrices&lt;/p&gt;

&lt;p&gt;Rigid Body Kinematics: we want a differential equation (ODE) that links &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;{}^{^w}R_b&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;in particular,
&lt;script type=&quot;math/tex&quot;&gt;{}^{^w} \dot{R}_r = f({}^{^w}R_b, \vec{\omega})&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\frac{ \partial }{\partial t}(R^R = I)
 \\
\dot{R}^TR + R^T \dot{R} = 0 \\
\dot{R}^TR = -R^T \dot{R} 
\end{aligned}&lt;/script&gt;

&lt;p&gt;we define &lt;script type=&quot;math/tex&quot;&gt;\Omega = R^T \dot{R}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega^T = (R^T \dot{R} )^T = \dot{R}^TR  = -R^T \dot{R}  = -\Omega&lt;/script&gt;

&lt;p&gt;Skew-symmetric! &lt;script type=&quot;math/tex&quot;&gt;\Omega^T = -\Omega&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;In fact,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\Omega = \begin{bmatrix}
0 &amp; -\omega_z &amp; \omega_y \\
\omega_z &amp; 0 &amp; -\omega_x \\
-\omega_y &amp; \omega_x &amp; 0
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega} = \begin{bmatrix} \omega_x \\ \omega_y \\ \omega_z \end{bmatrix}&lt;/script&gt; is the angular velocity&lt;/p&gt;

&lt;p&gt;Notation! the “hat” map&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{\omega}^{\hat{}} =\Omega&lt;/script&gt;

&lt;p&gt;the “v” map&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega^{v} = \bar{\omega}&lt;/script&gt;

&lt;p&gt;So we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\dot{R} = R \Omega \\
\Omega = \bar{\omega}^{\hat{}}
\end{aligned}&lt;/script&gt;

&lt;p&gt;In terms of frames, we have Poisson’s kinematic equation.&lt;/p&gt;

&lt;p&gt;The intrinsic equation is (where &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega}_b&lt;/script&gt; in the body frame is &lt;script type=&quot;math/tex&quot;&gt;\Omega_b&lt;/script&gt;):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{^w}\dot{R}_b =  {}^{^w}R_b \Omega_b&lt;/script&gt;

&lt;p&gt;The “strap-down” equation (extrinsic)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{^b}\dot{R}_w =  - \Omega_b {}^{^b}R_w&lt;/script&gt;

&lt;p&gt;Take vector on aircraft, put it into the coordinate frame of the world&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
{}_{^w}R_b = \begin{bmatrix} | &amp; | &amp; | \\ {}^{^w} \hat{x}_b &amp; {}^{^w}\hat{y}_b &amp; {}^{^w} \hat{z}_b \\ | &amp; | &amp; |  \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega \vec{v}_b = \omega \times \vec{v}_b&lt;/script&gt;

&lt;p&gt;Can we use this for filtering? Can we use &lt;script type=&quot;math/tex&quot;&gt;\dot{R} = R \Omega&lt;/script&gt; directly in an EKF, UKF
We’d have to turn it into discrete-time 
Naively, you might do the first order Euler approximation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{ R_{t + \delta_t} -R_t}{\delta t} \approx R_t \Omega_t&lt;/script&gt;

&lt;p&gt;This does not work!&lt;/p&gt;

&lt;p&gt;You won’t maintain orthogonality! The defining property of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; was orthogonality, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{t + \delta t} \not\in SO(3)&lt;/script&gt;

&lt;p&gt;and pretty soon&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
R_{t + \delta t}^T R_{t + \delta t} \neq I \\
\mbox{det }(R_{t+\delta t}) \neq +1
\end{aligned}&lt;/script&gt;

&lt;p&gt;The 3x3 matrix will not be recognizable of a rotation&lt;/p&gt;

&lt;h2 id=&quot;the-exponential-map&quot;&gt;The Exponential Map&lt;/h2&gt;

&lt;p&gt;The matrix exponential&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e^{ \hat{\omega}t} = I + \hat{\omega}t + \frac{ (\hat{\omega}t)^2}{2!} + \cdots + \frac{ (\hat{\omega}t)^n}{n!} + \cdots&lt;/script&gt;

&lt;p&gt;defines a map from the space &lt;script type=&quot;math/tex&quot;&gt;so(3)&lt;/script&gt; to &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt;, which we often call the &lt;em&gt;exponential map&lt;/em&gt; [5].&lt;/p&gt;

&lt;p&gt;For any rotation matrix &lt;script type=&quot;math/tex&quot;&gt;R \in SO(3)&lt;/script&gt;, there exists a &lt;script type=&quot;math/tex&quot;&gt;\omega \in \mathbf{R}^3, \|\omega\|=1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;t \in \mathbf{R}&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;R = e^{ \hat{\omega}t}&lt;/script&gt;. This theorem is quite powerful: it means that any rotation matrix can be realized by rotating around some fixed axis by a certain angle. This map is not one-to-one.&lt;/p&gt;

&lt;h2 id=&quot;twists&quot;&gt;Twists&lt;/h2&gt;

&lt;p&gt;A &lt;script type=&quot;math/tex&quot;&gt;4 \times 4&lt;/script&gt; matrix of the form &lt;script type=&quot;math/tex&quot;&gt;\hat{\xi}&lt;/script&gt; is called a twist. The set of all twists is denoted as &lt;script type=&quot;math/tex&quot;&gt;se(3)&lt;/script&gt; [4,5]:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
se(3) = \Bigg\{ \hat{\xi} = \begin{bmatrix} \hat{\omega} &amp; v \\ 0 &amp; 0 \end{bmatrix} \mid \hat{\xi} \in so(3), v \in \mathbf{R}^3 \Bigg\} \subset \mathbf{R}^{4 \times 4} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;se(3)&lt;/script&gt; is called the tangent space (or Lie algebra) of the matrix group &lt;script type=&quot;math/tex&quot;&gt;SE(3)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Why do we care about twists? It turns out that a rigid body can be moved from one position to any other by a movement consisting of (1) a rotation about a straight line (2) followed by a translation parallel to that line. This type of motion is &lt;em&gt;screw motion&lt;/em&gt;, and its infinitesimal version is called a &lt;em&gt;twist&lt;/em&gt;. The beauty of a twist is that it describes the instantaneous velocity of a rigid body in terms of its &lt;strong&gt;linear and angular components&lt;/strong&gt; [5]. It is the matrix exponential that maps a twist into its corresponding screw motion.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Frank Dellaert. Lecture Presentations of MM 8803: Mobile Manipulation, taught at the Georgia Institute of Technology, Fall 2018.&lt;/p&gt;

&lt;p&gt;[2] Mac Schwager. Lecture Presentations of AA 273: State Estimation and Filtering for Aerospace Systems, taught at Stanford University in April-June 2018.&lt;/p&gt;

&lt;p&gt;[3] Steven M. LaValle. &lt;em&gt;Planning Algorithms&lt;/em&gt;. Cambridge University Press, 2006, New York, NY, USA.&lt;/p&gt;

&lt;p&gt;[4] Murray, R.M., Li, Z., Sastry, S.S., Sastry, S.S.: A mathematical introduction to robotic manipulation. CRC press (1994). &lt;a href=&quot;https://www.cds.caltech.edu/~murray/books/MLS/pdf/mls94-complete.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[5] Ma, Yi and Soatto, Stefano and Kosecka, Jana and Sastry, S. Shankar: An Invitation to 3-D Vision: From Images to Geometric Models. Springer Verlag (2003). &lt;a href=&quot;https://www.eecis.udel.edu/~cer/arv/readings/old_mkss.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rigid Body Kinematics and Filtering&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kinematics with Euler Angles&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dot{R} = f(R, \vec{w}), (\dot{\phi}, \dot{\theta}, \dot{\psi}) = f(\phi, \theta, \psi, \vec{\omega})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\vec{\omega} = \begin{bmatrix} w_x \\ w_y \\ w_z \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 &amp; -\mbox{sin} \theta \\ 0 &amp; \mbox{cos} \phi &amp; \mbox{sin} \phi \mbox{cos} \phi \\ 0 &amp; -\mbox{sin} \phi &amp; \mbox{cos} \phi \mbox{cos} \theta \end{bmatrix} \begin{bmatrix} \dot{\phi} \\ \dot{\theta} \\ \dot{\psi} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;We want to invert this matrix and solve for &lt;script type=&quot;math/tex&quot;&gt;\begin{bmatrix} \dot{\phi} \\ \dot{\theta} \\ \dot{\psi} \end{bmatrix}&lt;/script&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">SO(2), SO(3), SE(2), SE(3), Lie algebras</summary></entry><entry><title type="html">Stereo and Disparity</title><link href="http://johnwlambert.github.io/stereo/" rel="alternate" type="text/html" title="Stereo and Disparity" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://johnwlambert.github.io/stereo-and-disparity</id><content type="html" xml:base="http://johnwlambert.github.io/stereo/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;Stereo Matching&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Disparity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;stereo-vision-and-stereo-matching&quot;&gt;Stereo Vision and Stereo Matching&lt;/h2&gt;

&lt;p&gt;“Stereo matching” is the task of estimating a 3D model of a scene from two or more images. The task requires finding matching pixels in the two images and converting the 2D positions of these matches into 3D depths [1]&lt;/p&gt;

&lt;p&gt;Humans have stereo vision with a baseline of 60 mm.&lt;/p&gt;

&lt;h2 id=&quot;disparity&quot;&gt;Disparity&lt;/h2&gt;

&lt;p&gt;Consider a simple model of stereo vision: we have two cameras whose optic axes are parallel. Each camera points down the &lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;-axis. A figure is shown below:&lt;/p&gt;

&lt;div class=&quot;fig figcenter fighighlight&quot;&gt;
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
  &lt;img src=&quot;/assets/stereo_vision_setup.jpg&quot; width=&quot;50%&quot; /&gt;
=======
  &lt;img src=&quot;/assets/stereo_vision_setup.png&quot; width=&quot;50%&quot; /&gt;
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; bbabd62b79acfce4d33cc330fc01a5e0b1e16d7f
  &lt;div class=&quot;figcaption&quot;&gt;
    Two cameras L and R are separated by a baseline b. Here the Y-axis is perpendicular to the page. f is our (horizontal) focal length.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In this figure, the world point &lt;script type=&quot;math/tex&quot;&gt;P=(x,z)&lt;/script&gt; is projected into the left image as &lt;script type=&quot;math/tex&quot;&gt;p_l&lt;/script&gt; and into the right image as &lt;script type=&quot;math/tex&quot;&gt;p_r&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;By defining right triangles we can find two similar triangles: with vertices at &lt;script type=&quot;math/tex&quot;&gt;(0,0)-(0,z)-(x,z)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;(0,0)-(0,f)-(f,x_l)&lt;/script&gt;. Since they share the same angle &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;\mbox{tan}(\theta)= \frac{\mbox{opposite}}{\mbox{adjacent}}&lt;/script&gt; for both, meaning:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{z}{f} = \frac{x}{x_l}&lt;/script&gt;

&lt;p&gt;We notice another pair of similar triangles
&lt;script type=&quot;math/tex&quot;&gt;(b,0)-(b,z)-(x,z)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;(b,0)-(b,f)-(b+x_r,f)&lt;/script&gt;, which by the same logic gives us&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{z}{f} = \frac{x-b}{x_r}&lt;/script&gt;

&lt;p&gt;We’ll derive a closed form expression for depth in terms of disparity. We already know that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{z}{f} = \frac{x}{x_l}&lt;/script&gt;

&lt;p&gt;Multiply both sides by &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;, and we get an expression for our depth from the observer:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z = f(\frac{x}{x_l})&lt;/script&gt;

&lt;p&gt;We now want to find an expression for &lt;script type=&quot;math/tex&quot;&gt;\frac{x}{x_l}&lt;/script&gt; in terms of &lt;script type=&quot;math/tex&quot;&gt;x_l-x_r&lt;/script&gt;, the &lt;em&gt;disparity&lt;/em&gt; between the two images.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{x}{x_l} &amp;= \frac{x-b}{x_r} &amp; \text{By similar triangles} \\
x x_r &amp;= x_l (x-b) &amp; \text{Multiply diagonals of the fraction} \\
x x_r &amp;= x_lx - x_l b &amp; \text{Distribute terms} \\
x_r &amp;= \frac{x_lx}{x} - b(\frac{x_l}{x}) &amp; \text{Divide all terms by } x \\
x_r &amp;= x_l - b(\frac{x_l}{x}) &amp; \text{Simplify} \\
b\frac{x_l}{x} &amp;= x_l - x_r &amp; \text{Rearrange terms to opposite sides} \\
b (\frac{x_l}{x}) (\frac{x}{x_l}) &amp;= (x_l - x_r) (\frac{x}{x_l}) &amp; \text{Multiply both sides by fraction inverse} \\
b &amp;= (x_l - x_r) (\frac{x}{x_l}) &amp; \text{Simplify} \\
\frac{b}{x_l - x_r} &amp;= \frac{x}{x_l} &amp; \text{Divide both sides by } (x_l - x_r) \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;We can now plug this back in&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z = f(\frac{x}{x_l}) = f(\frac{b}{x_l - x_r})&lt;/script&gt;

&lt;p&gt;What is our takeaway? The amount of horizontal distance between the object in Image L and image R (&lt;em&gt;the disparity&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;) is inversely proportional to the distance &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; from the observer. This makes perfect sense. Far away objects (large distance from the observer) will move very little between the left and right image. Very closeby objects (small distance from the observer) will move quite a bit more. The focal length &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; and the baseline &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; between the cameras are just constant scaling factors.&lt;/p&gt;

&lt;p&gt;We made two large assumptions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We know the focal length &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; and the baseline &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;. This requires prior knowledge or camera calibration.&lt;/li&gt;
  &lt;li&gt;We need to find point correspondences, e.g. find the corresponding &lt;script type=&quot;math/tex&quot;&gt;(x_r,y_r)&lt;/script&gt; for
each &lt;script type=&quot;math/tex&quot;&gt;(x_l,y_l)&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;the-epipolar-line-plane-and-constraint&quot;&gt;The Epipolar Line, Plane, and Constraint&lt;/h2&gt;

&lt;p&gt;Unfortunately, just because we know&lt;/p&gt;

&lt;p&gt;how to compute for a given pixel in one image the range of possible locations the pixel might appear at in the other image, i.e., its epipolar lin&lt;/p&gt;

&lt;h2 id=&quot;sum-of-squared-differences&quot;&gt;Sum of Squared-Differences&lt;/h2&gt;

&lt;p&gt;The matching cost is the squared difference of intensity values at a given disparity.&lt;/p&gt;

&lt;h2 id=&quot;cost-volumes&quot;&gt;Cost Volumes&lt;/h2&gt;

&lt;p&gt;Appendix B.5 and a recent survey paper on MRF inference (Szeliski, Zabih, Scharstein et al. 2008)&lt;/p&gt;

&lt;h2 id=&quot;simple-example-on-kitti&quot;&gt;Simple Example on KITTI&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E = R \mbox{ } [t]_{\times}&lt;/script&gt;

&lt;h2 id=&quot;object-detection-in-stereo&quot;&gt;Object Detection in Stereo&lt;/h2&gt;

&lt;p&gt;Chen &lt;em&gt;et al.&lt;/em&gt;
3DOP (NIPS 2015) Urtasun [4]&lt;/p&gt;

&lt;h2 id=&quot;unsupervised-learning-of-depth&quot;&gt;Unsupervised Learning of Depth&lt;/h2&gt;

&lt;p&gt;From 2017 [5]&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;p_t&lt;/script&gt; denote homogeneous coordinates in the target view. &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; denotes the camera intrinsic matrix.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_s \sim K \hat{T}_{t \rightarrow s} \hat{D}_t (p_t) K^{-1} p_t&lt;/script&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Richard Szeliski.&lt;/p&gt;

&lt;p&gt;[2] James Hays. &lt;a href=&quot;https://www.cc.gatech.edu/~hays/compvision/lectures/09.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[3] Rajesh Rao. Lecture 16: Stereo and 3D Vision, University of Washington. &lt;a href=&quot;https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect16.pdf&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[4] X. Chen, K. Kundu, Y. Zhu, A. Berneshawi, H. Ma, S. Fidler, R. Urtasun. &lt;em&gt;3D Object Proposals for Accurate Object Class Detection.&lt;/em&gt;  Advances in Neural Information Processing Systems 28 (NIPS 2015). &lt;a href=&quot;https://papers.nips.cc/paper/5644-3d-object-proposals-for-accurate-object-class-detection&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[5]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017/html/Zhou_Unsupervised_Learning_of_CVPR_2017_paper.html&quot;&gt;PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;STEREO http://people.scs.carleton.ca/~c_shu/Courses/comp4900d/notes/simple_stereo.pdf
DEPTH http://www.cse.usf.edu/~r1k/MachineVisionBook/MachineVision.files/MachineVision_Chapter11.pdf
STEREO https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect16.pdf
SFM http://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture6_affine_SFM_notes.pdf
JAMES MULTI-VIEW https://www.cc.gatech.edu/~hays/compvision/lectures/09.pdf&lt;/p&gt;</content><author><name></name></author><summary type="html">focal length, similar triangles, depth</summary></entry><entry><title type="html">Recall and Precision</title><link href="http://johnwlambert.github.io/recall-precision/" rel="alternate" type="text/html" title="Recall and Precision" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://johnwlambert.github.io/precision-recall</id><content type="html" xml:base="http://johnwlambert.github.io/recall-precision/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#recall&quot;&gt;Recall&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#precision&quot;&gt;Precision&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#map&quot;&gt;Mean Average Precision (mAP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;need-for-dr&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-need-for-more-finely-grained-measures-of-accuracy&quot;&gt;The Need for More Finely-Grained Measures of Accuracy&lt;/h2&gt;

&lt;p&gt;We’ll suppose that we are performing binary classification: classifying objects into different classes.&lt;/p&gt;

&lt;p&gt;Mean Average Precision involves computing the area under a curve (an integral), and can actually be quite confusing.&lt;/p&gt;

&lt;h3 id=&quot;recall&quot;&gt;Recall&lt;/h3&gt;

&lt;p&gt;Recall measures how many objects you missed. You can have very high recall by classifying everythin as some class (at the expense of precision).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{Recall} = \frac{tp}{tp+fn}&lt;/script&gt;

&lt;h3 id=&quot;precision&quot;&gt;Precision&lt;/h3&gt;

&lt;p&gt;Precision measures your discriminative ability. If you claimed that all of the objects you saw were of a particular class, and you were usually wrong because they belonged to a different class, you would have low precision. Your judgments can’t be considered &lt;em&gt;precise&lt;/em&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{Precision} = \frac{tp}{tp+fp}&lt;/script&gt;

&lt;h2 id=&quot;mean-average-precision&quot;&gt;Mean Average Precision&lt;/h2&gt;

&lt;p&gt;When performing the task of object detection, we would like to be discriminative not just about two classes&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def voc_eval(detpath,
             annopath,
             imagesetfile,
             classname,
             cachedir,
             ovthresh=0.5,
             use_07_metric=False):
    &quot;&quot;&quot;rec, prec, ap = voc_eval(detpath,
                                annopath,
                                imagesetfile,
                                classname,
                                [ovthresh],
                                [use_07_metric])

    Top level function that does the PASCAL VOC evaluation.

    detpath: Path to detections
        detpath.format(classname) should produce the detection results file.
    annopath: Path to annotations
        annopath.format(imagename) should be the xml annotations file.
    imagesetfile: Text file containing the list of images, one image per line.
    classname: Category name (duh)
    cachedir: Directory for caching the annotations
    [ovthresh]: Overlap threshold (default = 0.5)
    [use_07_metric]: Whether to use VOC07's 11 point AP computation
        (default False)
    &quot;&quot;&quot;
    # assumes detections are in detpath.format(classname)
    # assumes annotations are in annopath.format(imagename)
    # assumes imagesetfile is a text file with each line an image name
    # cachedir caches the annotations in a pickle file

    # first load gt
    if not os.path.isdir(cachedir):
        os.mkdir(cachedir)
    cachefile = os.path.join(cachedir, 'annots.pkl')
    # read list of images
    with open(imagesetfile, 'r') as f:
        lines = f.readlines()
    imagenames = [x.strip() for x in lines]

    if not os.path.isfile(cachefile):
        # load annots
        recs = {}
        for i, imagename in enumerate(imagenames):
            recs[imagename] = parse_rec(annopath.format(imagename))
            if i % 100 == 0:
                print 'Reading annotation for {:d}/{:d}'.format(
                    i + 1, len(imagenames))
        # save
        print 'Saving cached annotations to {:s}'.format(cachefile)
        with open(cachefile, 'w') as f:
            cPickle.dump(recs, f)
    else:
        # load
        with open(cachefile, 'r') as f:
            recs = cPickle.load(f)

    # extract gt objects for this class
    class_recs = {}
    npos = 0
    for imagename in imagenames:
        R = [obj for obj in recs[imagename] if obj['name'] == classname]
        bbox = np.array([x['bbox'] for x in R])
        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)
        det = [False] * len(R)
        npos = npos + sum(~difficult)
        class_recs[imagename] = {'bbox': bbox,
                                 'difficult': difficult,
                                 'det': det}

    # read dets
    detfile = detpath.format(classname)
    with open(detfile, 'r') as f:
        lines = f.readlines()

    splitlines = [x.strip().split(' ') for x in lines]
    image_ids = [x[0] for x in splitlines]
    confidence = np.array([float(x[1]) for x in splitlines])
    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])

    # sort by confidence
    sorted_ind = np.argsort(-confidence)
    sorted_scores = np.sort(-confidence)
    BB = BB[sorted_ind, :]
    image_ids = [image_ids[x] for x in sorted_ind]

    # go down dets and mark TPs and FPs
    nd = len(image_ids)
    tp = np.zeros(nd)
    fp = np.zeros(nd)
    for d in range(nd):
        R = class_recs[image_ids[d]]
        bb = BB[d, :].astype(float)
        ovmax = -np.inf
        BBGT = R['bbox'].astype(float)

        if BBGT.size &amp;gt; 0:
            # compute overlaps
            # intersection
            ixmin = np.maximum(BBGT[:, 0], bb[0])
            iymin = np.maximum(BBGT[:, 1], bb[1])
            ixmax = np.minimum(BBGT[:, 2], bb[2])
            iymax = np.minimum(BBGT[:, 3], bb[3])
            iw = np.maximum(ixmax - ixmin + 1., 0.)
            ih = np.maximum(iymax - iymin + 1., 0.)
            inters = iw * ih

            # union
            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +
                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *
                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)

            overlaps = inters / uni
            ovmax = np.max(overlaps)
            jmax = np.argmax(overlaps)

        if ovmax &amp;gt; ovthresh:
            if not R['difficult'][jmax]:
                if not R['det'][jmax]:
                    tp[d] = 1.
                    R['det'][jmax] = 1
                else:
                    fp[d] = 1.
        else:
            fp[d] = 1.

    # compute precision recall
    fp = np.cumsum(fp)
    tp = np.cumsum(tp)
    rec = tp / float(npos)
    # avoid divide by zero in case the first detection matches a difficult
    # ground truth
    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)
    ap = voc_ap(rec, prec, use_07_metric)

    return rec, prec, ap
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Bharath Hariharan and Ross Girshick. Fast/er R-CNN. &lt;a href=&quot;https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py&quot;&gt;https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">The Histogram Filter</title><link href="http://johnwlambert.github.io/histogram-filter/" rel="alternate" type="text/html" title="The Histogram Filter" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://johnwlambert.github.io/histogram-filter</id><content type="html" xml:base="http://johnwlambert.github.io/histogram-filter/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#need-for-dr&quot;&gt;Need for Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pca&quot;&gt;PCA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;need-for-dr&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-histogram-filter&quot;&gt;The Histogram Filter&lt;/h2&gt;

&lt;p&gt;An alternative to continuous distributions are piecewise constant approximations, such as histograms. These are &lt;em&gt;nonparametric&lt;/em&gt; filters, since they do not utilize parameters like a mean and covariance &lt;script type=&quot;math/tex&quot;&gt;(\mu, \Sigma)&lt;/script&gt; to define a distribution. Thus, nonparametric filters do not rely on a &lt;em&gt;fixed functional form of the posterior&lt;/em&gt;, like the Gaussian does [1].&lt;/p&gt;

&lt;p&gt;The Histogram Filter is a type of nonparametric filters that discretizes the state space into a finite number of regions. The histogram assigns to each region a single cumulative probability.&lt;/p&gt;

&lt;h2 id=&quot;1-d-histogram-filter&quot;&gt;1-D Histogram Filter&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;for all \(k\) do:
    &lt;ul&gt;
      &lt;li&gt;\( \hat{p}&lt;em&gt;{k,t} = \sum\limits_i p(X_t = x_k \mid u_t, X&lt;/em&gt;{t-1} = x_i) p_{i,t-1} \)&lt;/li&gt;
      &lt;li&gt;\( p_{k,t} = \eta p(z_t \mid X_t = x_k) \hat{p}_{k,t}) \)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-d-histogram-filter-and-grid-localization&quot;&gt;2-D Histogram Filter and Grid Localization&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Sebastian Thrun, Wolfram Burgard, Dieter Fox. &lt;em&gt;Probabilistic Robotics&lt;/em&gt;. The MIT Press, Cambridge, MA, 2005.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Spectral Clustering</title><link href="http://johnwlambert.github.io/spectral-clustering/" rel="alternate" type="text/html" title="Spectral Clustering" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://johnwlambert.github.io/spectral-clustering</id><content type="html" xml:base="http://johnwlambert.github.io/spectral-clustering/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#need-for-dr&quot;&gt;Need for Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pca&quot;&gt;PCA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;need-for-dr&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;spectral-clustering&quot;&gt;Spectral Clustering&lt;/h2&gt;

&lt;p&gt;\subsection{Graph Partitioning}
\begin{itemize}
\item Graph-cut problem: partition graph such that (1) edges between groups have a very low weight, and (2) edges within a group have high weight
\item Could use \textbf{Ratio Cut} (by size of the component) or the \textbf{Normalized Cut} (or by volume of the component, aka the sum of degrees)
\item Penalize using very small components, or very large components
\item These are NP-hard combinatorial problems. But Spectral clustering offers a way to solve the relaxation version of these problems
\item NCut -&amp;gt; use random-walk laplacian
\item RatioCut -&amp;gt; use unnormalized laplacian
\item 2-partition: assign by vector values of Fiedler vectors $\in \mathbbm{R}$, which ones $\in \mathbbm{R}&lt;em&gt;+$, or in $\mathbbm{R}&lt;/em&gt;-$
\item Can apply k-means or standard clustering algorithm on the embedded points (transform graph clustering into a point clustering problem!). Take you into point cloud setting
\item K-means minimizes the distortion measure/energy
\begin{equation}
J = \sum\limits_j \sum\limits_k r_{ji}(y_j - \mu_i)^2 ??
\end{equation}
\item Centroid already minimizes the sum of squared distances
\item Can only reduce energy in every step (locally converge to minimum)
\item Can discover number of clusters that you need – look at gap between eigenvalues, where is there a large gap $|\lambda_k - \lambda_{k-1}|$. 
\item Eigenvalues drop fast, then stabilize
\item Spectral clustering can cluster spirals of points, where k-nearest neighbors in this space would epicly fail
\item Look at data at a very different way… Even though data comes from a Euclidean space, easier to understand in the spectral space
\item edge weight $\mbox{exp} (-diff(pixel_{i}, pixel_j)/t^2 )$
\item Get reasonable, but not perfect, results for 3d segmentation
\item Fast and efficient with decent results
\end{itemize}&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Leonidas Guibas. &lt;em&gt;Graph Laplacians, Laplacian Embeddings, and Spectral Clustering&lt;/em&gt;. Lectures of CS233: Geometric and Topological Data Analysis, taught at Stanford University in Spring 2018.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Understanding Multivariate Gaussians and Covariance</title><link href="http://johnwlambert.github.io/learning-point-cloud-features/" rel="alternate" type="text/html" title="Understanding Multivariate Gaussians and Covariance" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://johnwlambert.github.io/learning-point-cloud-features</id><content type="html" xml:base="http://johnwlambert.github.io/learning-point-cloud-features/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;3d-semantic-segmentation-of-features&quot;&gt;3D Semantic Segmentation of Features&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
import torch
import torch.nn as nn
import math
import torch.nn.functional as F

class PointNetBase(nn.Module):

	def __init__(self, opt):
		&quot;&quot;&quot;
		Multilayer perceptrons with shared weights are implemented as 
		convolutions. This is because we are mapping from K inputs to 64 
		outputs, so we can just consider each of the 64 K-dim filters as 
		describing the weight matrix for each point dimension (X,Y,Z,...) to
		each index of the 64 dimension embeddings
		&quot;&quot;&quot;
		# Call the super constructor
		super(PointNetBase, self).__init__()

		self.opt = opt
		# stddev=1e-3,
		# weight_decay=0.0,
		# activation_fn=tf.nn.relu,

		self.autoencoder_mlp = self.make_ae_layers([32,64,64,128,128]) 
		self.decoder_fc = self.make_fc_layers([256, 256, self.opt.n_pc_per_model * 3])

		# 4 part classes
		# dim is 128 + 3
		self.seg_branch = nn.Sequential(nn.Conv1d(128+3,4,1))

		self._initialize_weights()


	def make_ae_layers(self, cfg):
		&quot;&quot;&quot;
		[1,3] kernel, stride [1,1]
		then [1,1] kernel and stride[1,1] everywhere

		Point functions (MLP implemented as conv2d)
		&quot;&quot;&quot;
		layers = []
		in_channels = 3
		for v in cfg:
			conv1d = nn.Conv1d(in_channels, v, 1)
			layers += [conv1d, nn.BatchNorm1d(v), nn.ReLU()]
			in_channels = v
		return nn.Sequential(*layers)


	def make_fc_layers(self, cfg):
		&quot;&quot;&quot;
		MLP on global point cloud vector
		&quot;&quot;&quot;
		layers = []
		in_channels = 128
		for v_idx, v in enumerate(cfg):
			fc = nn.Linear(in_channels, v, 1)
			if v_idx == len(cfg) - 1:
				# on the final layer, no activation fn here
				layers += [fc]
			else:
				layers += [fc, nn.ReLU(True), nn.Dropout(p=self.opt.dropout_prob) ]
			in_channels = v
		return nn.Sequential(*layers)


	def _initialize_weights(self):
		for m in self.modules():
			if isinstance(m, nn.Conv2d):
				n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
				m.weight.data.normal_(0, math.sqrt(2. / n))
				if m.bias is not None:
					m.bias.data.zero_()
			elif isinstance(m, nn.BatchNorm2d):
				m.weight.data.fill_(1)
				m.bias.data.zero_()
			elif isinstance(m, nn.Linear):
				n = m.weight.size(1)
				m.weight.data.normal_(0, 0.01)
				m.bias.data.zero_()


	def forward(self, x):
		&quot;&quot;&quot;
		K = 3
		Take as input a B x K x N matrix of B batches of N points with K 
		dimensions

		Points come in as torch.Size([B=50, N=1024, K=3])
		We turn them into ([B=50 x K=3 x N=1024])
		&quot;&quot;&quot;
		cloned_input = x.clone()
		# Number of points put into the network
		x = torch.transpose(x, 1, 2)
		N = x.size(2)

		# Input is B x K x N
		# Run the transformed inputs through the autoencoder MLP
		x = self.autoencoder_mlp(x)
		# Output is B x 128 x N

		# Pool over the number of points. This results in the &quot;global feature&quot;
		# Output should be B x 128 x 1 --&amp;gt; B x 128 (after squeeze)
		global_feature = F.max_pool1d(x, N).squeeze(2)
		latent_codes = global_feature.clone()

		per_pt_logits = None
		if self.opt.use_parts:
			pdb.set_trace()
			# segmentation fc for scores over num_class
			per_pt_latent_codes = global_feature.clone()
			per_pt_latent_codes = per_pt_latent_codes.repeat(N)
			per_pt_input =  torch.cat( [per_pt_latent_codes, cloned_input] )
			per_pt_logits = self.seg_branch(per_pt_input)

		# output has size ([B=50, N=3072])
		x = self.decoder_fc(global_feature)
		return x, latent_codes, per_pt_logits
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3d-instance-segmentation-of-features&quot;&gt;3D Instance Segmentation of Features&lt;/h2&gt;

&lt;p&gt;The line between 3D object detection and 3D instance segmentation in point clouds is blurry because both representations are easily derived from the other.&lt;/p&gt;

&lt;p&gt;The Similarity Group Proposal Network (SGPN) [1] is the first network architecture designed to perform instance-level and semantic segmentation directly on point clouds.&lt;/p&gt;

&lt;p&gt;It is possible to re-formulate the instance segmentation problem as semantic segmentation of 3 “similarity” classes in the following way. The 3 classes for each pair of points &lt;script type=&quot;math/tex&quot;&gt;\{Pi, Pj\}&lt;/script&gt; are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P_j&lt;/script&gt; belong to the same object instance&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P_j&lt;/script&gt; share the same semantic class but do not belong to the same object instance&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P_j&lt;/script&gt; do not share the same semantic class. Pairs of points should lie progressively further away from each other in feature space as their similarity class increases.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;single network to predict point grouping proposals
and a corresponding semantic class for each proposal, from
which we can directly extract instance segmentation results&lt;/p&gt;

&lt;p&gt;similarity matrix that indicates the similarity between each pair of points in embedded feature space, thus producing an accurate grouping proposal for each point&lt;/p&gt;

&lt;p&gt;a similarity matrix
yielding point-wise group proposals,&lt;/p&gt;

&lt;p&gt;uses PointNet/PointNet++ to extract a descriptive feature vector for each point in the point cloud&lt;/p&gt;

&lt;p&gt;This feature extraction network
produces a matrix F. SGPN then diverges into three
branches that each pass F through a single PointNet layer to
obtain sized Np × Nf feature matrices FSIM, FCF , FSEM,
which we respectively use to obtain a similarity matrix, a
confidence map and a semantic segmentation map. The ith
row in a Np×Nf feature matrix is a Nf -dimensional vector
that represents point Pi
in an embedded feature space&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = L_{sim} + L_{cf} + L_{sem}&lt;/script&gt;

&lt;p&gt;The matrix &lt;script type=&quot;math/tex&quot;&gt;S \in \mathbf{R}^{N_p \times N_p}&lt;/script&gt;, and element &lt;script type=&quot;math/tex&quot;&gt;S_{ij}&lt;/script&gt; classifies whether or
not points &lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P_j&lt;/script&gt; belong to the same object instance.
Each row of &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; can be viewed as a proposed grouping of
points that form a candidate object instance.&lt;/p&gt;

&lt;p&gt;We obtain &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; by, for each pair of
points &lt;script type=&quot;math/tex&quot;&gt;\{Pi, Pj\}&lt;/script&gt;, simply subtracting their corresponding feature vectors &lt;script type=&quot;math/tex&quot;&gt;\{F_{sim_i}, F_{sim_j} \}&lt;/script&gt; and taking the &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; norm such that &lt;script type=&quot;math/tex&quot;&gt;S_{ij} = \|F_{sim_i} − F_{sim_j} \|_2&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Metric Learning With 3 Classes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Operates on matrix &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; which has &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; norm entries&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{sim} = \sum\limits_{i}^{N_p} \sum\limits_{j}^{N_p}l(i, j)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
l(i, j) = \begin{cases}
\|F_{sim_i} − F_{sim_j} \|_2 &amp; C_{ij} = 1 \\
\alpha \max(0, K_1 − \|F_{sim_i} − F_{sim_j} \|_2) &amp; C_{ij} = 2 \\
\max(0, K_2 − \|F_{sim_i} − F_{sim_j} \|_2) &amp; C_{ij} = 3 \end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;such that &lt;script type=&quot;math/tex&quot;&gt;\alpha &gt; 1, K2 &gt; K1&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Confidence Loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;we expect the
ground-truth value in the confidence map CMi
to be the intersection
over union (IoU) between the set of points in the
predicted group Si and the ground truth group Gi
. O&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Merging Group Proposals&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The similarity matrix S produces Np group proposals,
many of which are noisy or represent the same object.&lt;/p&gt;

&lt;p&gt;discard proposals with predicted confidence less than
T hC or cardinality less than T hM2. We further prune
our proposals into clean, non-overlapping object instances
by applying Non-Maximum Suppression; groups with IoU
greater than T hM1 are merged together by selecting the
group with the maximum cardinality&lt;/p&gt;

&lt;p&gt;T hM1 is set to 0.6 and T hM2 is set to 200. T hC is
set to 0.1. Our network is implemented&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instance Segmentation Without the 3-part Multi-Task Loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We also compare instance segmentation performance
with the following method (which we call Seg-Cluster):
Perform semantic segmentation using our network and then
select all points as seeds. Starting from a seed point, BFS
is used to search neighboring points with the same label. If
a cluster with more than 200 points has been found, it is
viewed as a valid group. Our GroupMerging algorithm is
then used to merge these valid groups.&lt;/p&gt;

&lt;p&gt;naive method like Seg-Cluster tends to
properly separate regions far away for large objects like the
ceiling and floor. However for small object, Seg-Cluster
fails to segment instances with the same label if they are
close to each other&lt;/p&gt;

&lt;p&gt;The method of Armeni [2] was …&lt;/p&gt;

&lt;h2 id=&quot;chamfer-distance&quot;&gt;Chamfer Distance&lt;/h2&gt;

&lt;p&gt;The symmetric Chamfer distance is a pseudo-metric, not a metric. It is defined as&lt;/p&gt;

&lt;p&gt;The Chamfer distance is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d_{Chamfer}(\mathbf{A,B}) = \Big( \sum\limits_{x_B \in \mathbf{B}} \underset{x_A \in \mathbf{A}}{\mbox{min}} |X_B - X_A|^2 \Big) + \Big( \sum\limits_{x_A \in \mathbf{A}} \underset{x_B \in \mathbf{B}}{\mbox{min}} |X_B - X_A|^2 \Big)&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np 
import torch

# def tensorflow_chamfer_distance(pc1, pc2):
#     '''
#     Input:
#         pc1: float TF tensor in shape (B,N,C) the first point cloud
#         pc2: float TF tensor in shape (B,M,C) the second point cloud
#     Output:
#         dist1: float TF tensor in shape (B,N) distance from first to second
#         idx1: int32 TF tensor in shape (B,N) nearest neighbor from first to second
#         dist2: float TF tensor in shape (B,M) distance from second to first
#         idx2: int32 TF tensor in shape (B,M) nearest neighbor from second to first
#     '''
#     N = pc1.get_shape()[1].value
#     M = pc2.get_shape()[1].value
#     pc1_expand_tile = tf.tile(tf.expand_dims(pc1,2), [1,1,M,1])
#     pc2_expand_tile = tf.tile(tf.expand_dims(pc2,1), [1,N,1,1])
#     pc_diff = pc1_expand_tile - pc2_expand_tile # B,N,M,C
#     pc_dist = tf.reduce_sum(pc_diff ** 2, axis=-1) # B,N,M
#     dist1 = tf.reduce_min(pc_dist, axis=2) # B,N
#     idx1 = tf.argmin(pc_dist, axis=2) # B,N
#     dist2 = tf.reduce_min(pc_dist, axis=1) # B,M
#     idx2 = tf.argmin(pc_dist, axis=1) # B,M
#     return dist1, idx1, dist2, idx2


# def pytorch_chamfer_distance(pc1, pc2):
#     '''
#     Input:
#         pc1: float TF tensor in shape (B,N,C) the first point cloud
#         pc2: float TF tensor in shape (B,M,C) the second point cloud
#     Output:
#         dist1: float TF tensor in shape (B,N) distance from first to second
#         idx1: int32 TF tensor in shape (B,N) nearest neighbor from first to second
#         dist2: float TF tensor in shape (B,M) distance from second to first
#         idx2: int32 TF tensor in shape (B,M) nearest neighbor from second to first
#     '''
#     N = pc1.size(1)
#     M = pc2.size(1)

# 	pc1_expand_tile = pc1.view(-1, 1).repeat(1, 3).view(1,1,M,1)
# 	pc2_expand_tile = pc2.view(-1, 1).repeat(1, 3).view(1,N,1,1)



#      = tf.tile(tf.expand_dims(pc1,2), [1,1,M,1])
#     pc2_expand_tile = tf.tile(tf.expand_dims(pc2,1), [1,N,1,1])
#     pc_diff = pc1_expand_tile - pc2_expand_tile # B,N,M,C
#     pc_dist = tf.reduce_sum(pc_diff ** 2, axis=-1) # B,N,M
#     dist1 = tf.reduce_min(pc_dist, axis=2) # B,N
#     idx1 = tf.argmin(pc_dist, axis=2) # B,N
#     dist2 = tf.reduce_min(pc_dist, axis=1) # B,M
#     idx2 = tf.argmin(pc_dist, axis=1) # B,M
#     return dist1, idx1, dist2, idx2



def batch_pairwise_dist(x, y, cuda):
    # 32, 2500, 3
    bs, num_points, points_dim = x.size()
    xx = torch.bmm(x, x.transpose(2, 1))
    yy = torch.bmm(y, y.transpose(2, 1))
    zz = torch.bmm(x, y.transpose(2, 1))
    if cuda:
        diag_ind = torch.arange(0, num_points).type(torch.cuda.LongTensor)
    else:
        diag_ind = torch.arange(0, num_points).type(torch.LongTensor)
    rx = xx[:, diag_ind, diag_ind].unsqueeze(1).expand_as(xx)
    ry = yy[:, diag_ind, diag_ind].unsqueeze(1).expand_as(yy)
    P = (rx.transpose(2, 1) + ry - 2 * zz)
    return P


def batch_NN_loss(x, y, cuda):
    bs, num_points, points_dim = x.size()
    dist1 = batch_pairwise_dist(x, y, cuda)
    values1, indices1 = dist1.min(dim=2)

    dist2 = batch_pairwise_dist(y, x, cuda)
    values2, indices2 = dist2.min(dim=2)
    a = torch.div(torch.sum(values1,1), num_points)
    b = torch.div(torch.sum(values2,1), num_points)
    chamfer = torch.div(torch.sum(a), bs) + torch.div(torch.sum(b), bs)

    #print('batch size: %d, and chamfer dist = %f' % (bs, chamfer.data[0]) )

    return chamfer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;graph-neural-networks&quot;&gt;Graph Neural Networks&lt;/h2&gt;

&lt;p&gt;Dynamic Graph CNN (DGCNN) [3] …&lt;/p&gt;

&lt;h2 id=&quot;meanshift&quot;&gt;Meanshift&lt;/h2&gt;

&lt;p&gt;Comaniciu … PAMI 2002&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation. In CVPR, 2018. &lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SGPN_Similarity_Group_CVPR_2018_paper.pdf&quot;&gt;http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SGPN_Similarity_Group_CVPR_2018_paper.pdf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2] I. Armeni, O. Sener, A. R. Zamir, H. Jiang, I. Brilakis, M. Fischer, and S. Savarese. 3d semantic parsing of largescale indoor spaces. In CVPR, 2016.&lt;/p&gt;

&lt;p&gt;[3] Dynamic Graph CNN.&lt;/p&gt;

&lt;p&gt;https://www.mathworks.com/matlabcentral/fileexchange/6110-toolbox-fast-marching&lt;/p&gt;</content><author><name></name></author><summary type="html">PointNet, SPGN, SPLATNet, Dynamic Graph Learning</summary></entry></feed>