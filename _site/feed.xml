<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>John Lambert blog</title>
    <description>Notes on Machine Learning and Optimization.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 05 Apr 2018 03:33:32 -0700</pubDate>
    <lastBuildDate>Thu, 05 Apr 2018 03:33:32 -0700</lastBuildDate>
    <generator>Jekyll v3.7.3</generator>
    
      <item>
        <title>Subgradient Methods in 10 Minutes</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;

&lt;p&gt;Now that we’ve covered topics from convex optimization in a very shallow manner, it’s time to go deeper.&lt;/p&gt;

&lt;h2 id=&quot;subgradient-methods&quot;&gt;Subgradient methods&lt;/h2&gt;

&lt;h3 id=&quot;convexity-review&quot;&gt;Convexity Review&lt;/h3&gt;

&lt;p&gt;To understand subgradients, first we need to review convexity. The Taylor series of a real valued function that is infinitely differentiable at a real number \(x\) is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(y) \approx \sum\limits_{k=0}^{\infty} \frac{f^{(k)}(x)}{k!}(y-x)^k&lt;/script&gt;

&lt;p&gt;Expanding terms, the series resembles&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(y) \approx  f(x) + \frac{f^{\prime}(x)}{1!}(y-x) + \frac{f^{\prime\prime}(x)}{2!}(y-x)^2 + \frac{f^{\prime\prime\prime}(x)}{3!}(y-x)^3 + \cdots.&lt;/script&gt;

&lt;p&gt;If a function is convex, its first order Taylor expansion (a tangent line) will always be a global underestimator:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(y) \geq f(x) + \frac{f^{\prime}(x)}{1!}(y-x)&lt;/script&gt;

&lt;p&gt;If \(y=x + \delta\), then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
f(x+ \delta) \geq f(x) + \nabla f(x)^T (x+\delta-x) \\
f(x+ \delta) \geq f(x) + \nabla f(x)^T \delta
\end{aligned}&lt;/script&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/tangent_underestimates_quadratic.jpg&quot; width=&quot;25%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;From the picture, it’s obvious that an affine function is always an underestimator for this quadratic (thus convex) function. But there is also intuition behind why this is true. A univariate function is convex if its derivative is increasing (thus second derivative is positive). Since slope is a measure of function increase/decrease over some interval \(\delta\), where usually \(\delta=1\), if we multiply slope by \(\delta = y-x = \) “run”, then we will be left with only the change in function value over the interval (\(slope=\frac{rise}{run}\) and \(\frac{rise}{run}\cdot(run)=rise\) ).&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/tangent_underestimates_4cases.jpg&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;If \(y&amp;gt;x\), then \(\delta &amp;gt; 0\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(Case 1 above) If we are to the right of the stationary point (here global minimum) \(0,0)\) then \(\nabla f&amp;gt;0\), and since the derivative is increasing (which an affine function cannot account for), we never predict a large enough function increase (underestimating).&lt;/li&gt;
  &lt;li&gt;(Case 2 above) If we are to the left of \(0,0)\) then \(\nabla f&amp;lt;0\), we estimate too large of a function decrease (the derivative is increasing). So we underestimate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-If \(x&amp;gt;y\), our \(\delta &amp;lt; 0\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(Case 3 above) If we are to the right of \(0,0)\), then \(\nabla f&amp;gt;0\). We predict too large of a function decrease and underestimate.&lt;/li&gt;
  &lt;li&gt;(Case 4 above) If we are to the left of \(0,0)\), then \(\nabla f&amp;lt;0\). We overestimate the function decrease, so we underestimate.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;subgradients&quot;&gt;Subgradients&lt;/h2&gt;

&lt;p&gt;Consider a function \(f\) with a kink inside of it, rendering the function non-differentiable at a point \(x_2\).&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/subgradients.png&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The derivative jumps up by some amount (over some interval) at this kink. Any slope within that interval is a valid subgradient. A subgradient is also a supporting hyperplane to the epigraph of the function. The set of subgradients of \(f\) at \(x\) is called the subdifferential \(\partial f(x)\) (a point-to-set mapping). To determine if a function is subdifferentiable at \(x_0\), we must ask, “is there a global affine lower bound on this function that is tight at this point?”.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If a function is convex, it has at least one point in the relative interior of the domain.&lt;/li&gt;
  &lt;li&gt;If a function is differentiable at \(x\), then \(\partial f(x) = {\nabla f(x)} \) (a singleton set).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, for absolute value, we could say the interval \( [\nabla f_{\text{left}}(x_0), \nabla f_{\text{right}}(x_0)] \) is the range of possible slopes (subgradients):&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/subdifferential.png&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;basic-subgradient-method-negative-subgradient-update&quot;&gt;Basic Subgradient Method: Negative Subgradient Update&lt;/h3&gt;

&lt;p&gt;From [1]: Given a convex function \(f:\mathbb{R}^n \rightarrow \mathbb{R}\), not necessarily differentiable. The subgradient method is just like gradient descent, but replacing gradients with subgradients. i.e., initialize \(x^{(0)}\), then repeat&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
x^{(k+1)} = x^{(k)} − \alpha_k \cdot g^{(k)}, &amp; k = 0, 1, 2, 3, \cdots
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;where \(g^{(k)}\) is &lt;strong&gt;any&lt;/strong&gt; subgradient of \(f\) at \(x^{(k)}\), and \(\alpha_k &amp;gt;0 \) is the \(k\)’th step size.&lt;/p&gt;

&lt;p&gt;Unlike gradient descent, in the negative subgradient update it’s entirely possible that \(-g^{(k)}\) is not a descent direction for \(f\) at \(x^{(k)}\). In such cases, we always have \(f(x^{(k+1)}) &amp;gt; f(x^{(k)})\), meaning an iteration of the subgradient method can increase the objective function. To resolve this issue, we keep track of best iterate \(x_{best}^k\) among \(x^{(1)}, \cdots , x^{(k)}\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_{best}^{(k)}) = \underset{i=1,\cdots ,k}{\mbox{ min  }}  f(x^{(i)})&lt;/script&gt;

&lt;p&gt;To update each \(x^{(i)}\), there are at least 5 common ways to select the step size, all with different convergence properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Constant step size&lt;/li&gt;
  &lt;li&gt;Constant step length&lt;/li&gt;
  &lt;li&gt;Square summable but not summable.&lt;/li&gt;
  &lt;li&gt;Nonsummable diminishing&lt;/li&gt;
  &lt;li&gt;Nonsummable diminishing step lengths.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See &lt;a href=&quot;https://stanford.edu/class/ee364b/lectures/subgrad_method_notes.pdf&quot;&gt;[2]&lt;/a&gt; for details regarding each of these possible step size choices and the &lt;strong&gt;associated guarantees on convergence&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;subgradient-methods-for-constrained-problems&quot;&gt;Subgradient methods for constrained problems&lt;/h3&gt;

&lt;h3 id=&quot;primal-dual-subgradient-methods&quot;&gt;Primal-dual subgradient methods&lt;/h3&gt;

&lt;h3 id=&quot;stochastic-subgradient-method&quot;&gt;Stochastic subgradient method&lt;/h3&gt;

&lt;h3 id=&quot;mirror-descent-and-variable-metric-methods&quot;&gt;Mirror descent and variable metric methods&lt;/h3&gt;

&lt;h2 id=&quot;localization-methods&quot;&gt;Localization methods&lt;/h2&gt;

&lt;h3 id=&quot;localization-and-cutting-plane-methods&quot;&gt;Localization and cutting-plane methods&lt;/h3&gt;

&lt;h3 id=&quot;analytic-center-cutting-plane-method&quot;&gt;Analytic center cutting-plane method&lt;/h3&gt;

&lt;h3 id=&quot;ellipsoid-method&quot;&gt;Ellipsoid method&lt;/h3&gt;

&lt;h2 id=&quot;decomposition-and-distributed-optimization&quot;&gt;Decomposition and distributed optimization&lt;/h2&gt;

&lt;h3 id=&quot;primal-and-dual-decomposition&quot;&gt;Primal and dual decomposition&lt;/h3&gt;

&lt;h3 id=&quot;decomposition-applications&quot;&gt;Decomposition applications&lt;/h3&gt;

&lt;h3 id=&quot;distributed-optimization-via-circuits&quot;&gt;Distributed optimization via circuits&lt;/h3&gt;

&lt;h2 id=&quot;proximal-and-operator-splitting-methods&quot;&gt;Proximal and operator splitting methods&lt;/h2&gt;

&lt;h3 id=&quot;proximal-algorithms&quot;&gt;Proximal algorithms&lt;/h3&gt;

&lt;h3 id=&quot;monotone-operators&quot;&gt;Monotone operators&lt;/h3&gt;

&lt;h3 id=&quot;monotone-operator-splitting-methods&quot;&gt;Monotone operator splitting methods&lt;/h3&gt;

&lt;h3 id=&quot;alternating-direction-method-of-multipliers-admm&quot;&gt;Alternating direction method of multipliers (ADMM)&lt;/h3&gt;

&lt;h2 id=&quot;conjugate-gradients&quot;&gt;Conjugate gradients&lt;/h2&gt;

&lt;h3 id=&quot;conjugate-gradient-method&quot;&gt;Conjugate-gradient method&lt;/h3&gt;

&lt;h3 id=&quot;truncated-newton-methods&quot;&gt;Truncated Newton methods&lt;/h3&gt;

&lt;h2 id=&quot;nonconvex-problems&quot;&gt;Nonconvex problems&lt;/h2&gt;

&lt;h3 id=&quot;l_1-methods-for-convex-cardinality-problems&quot;&gt;\(l_1\) methods for convex-cardinality problems&lt;/h3&gt;

&lt;h3 id=&quot;l_1-methods-for-convex-cardinality-problems-part-ii&quot;&gt;\(l_1\) methods for convex-cardinality problems, part II&lt;/h3&gt;

&lt;h3 id=&quot;sequential-convex-programming&quot;&gt;Sequential convex programming&lt;/h3&gt;

&lt;h2 id=&quot;branch-and-bound-methods&quot;&gt;Branch-and-bound methods&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Gordon, Geoff. CMU 10-725 Optimization Fall 2012 Lecture Slides, &lt;a href=&quot;https://www.cs.cmu.edu/~ggordon/10725-F12/scribes/10725_Lecture6.pdf&quot;&gt;Lecture 6&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2] Boyd, Stephen. &lt;a href=&quot;https://stanford.edu/class/ee364b/lectures/subgrad_method_notes.pdf&quot;&gt;Subgradient Methods: Notes for EE 364B&lt;/a&gt;, January 2007.&lt;/p&gt;

</description>
        <pubDate>Mon, 02 Apr 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/04/02/subgradient/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/04/02/subgradient/</guid>
        
        
      </item>
    
      <item>
        <title>Convex Optimization Without the Agonizing Pain</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;

&lt;h2 id=&quot;convexity&quot;&gt;Convexity&lt;/h2&gt;

&lt;h3 id=&quot;first-order-condition&quot;&gt;First-Order Condition&lt;/h3&gt;

&lt;p&gt;If \(f\) is convex and differentiable, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) + \nabla f(x)^T (y-x) \leq f(y)&lt;/script&gt;

&lt;p&gt;That is to say, a tangent line to \(f\) is a &lt;strong&gt;global underestimator&lt;/strong&gt; of the function.&lt;/p&gt;

&lt;h3 id=&quot;second-order-condition&quot;&gt;Second-Order Condition&lt;/h3&gt;

&lt;p&gt;Assuming \(f\) is twice differentiable, that is, its Hessian or second derivative \(\nabla^2f\) exists at each point in the domain of \(f\), then \(f\) is convex **if and only if ** the domain of \(f\) is convex and its Hessian is positive semidefinite.&lt;/p&gt;

&lt;p&gt;Formally, we state, for all \(x \in \mbox{dom}(f)\),&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\nabla^2 f(x) \succeq 0&lt;/script&gt;
This condition can be interpreted geometrically as the requirement that the graph of the function have positive (upward) curvature at \(x\).&lt;/p&gt;

&lt;h3 id=&quot;known-convex-and-concave-functions&quot;&gt;Known Convex and Concave Functions&lt;/h3&gt;

&lt;p&gt;Convex:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linear.&lt;/li&gt;
  &lt;li&gt;Affine. \(f(x) = Ax+b\), where \(A \in \mathbb{R}^{m \times n}\) and \(b \in \mathbb{R}^m\). This is the sum of a linear function and a constant.&lt;/li&gt;
  &lt;li&gt;Exponential. \(e^{ax}\) is convex on \(\mathbb{R}\), for any \(a \in \mathbb{R}\).&lt;/li&gt;
  &lt;li&gt;Powers. \(x^a\) is convex on \(R_{++}\) when \(a \geq 1\) or \(a \leq 0\).&lt;/li&gt;
  &lt;li&gt;Powers of absolute value. \(|x|^p\), for \(p\geq 1\), is convex on \(\mathbb{R}\).&lt;/li&gt;
  &lt;li&gt;Negative Entropy. \(x \mbox{log}(x)\) is convex on \(\mathbb{R}_{++}\).&lt;/li&gt;
  &lt;li&gt;Norms. Every norm on \(\mathbb{R}^n\) is convex.&lt;/li&gt;
  &lt;li&gt;Max function. \(f(x) = \mbox{max} { x_1, \dots, x_n } \) is convex on \(\mathbb{R}^n\).&lt;/li&gt;
  &lt;li&gt;Quadratic-over-linear function.&lt;/li&gt;
  &lt;li&gt;Log-sum-exp. \(f(x) = \mbox{log }(e^{x_1}+\cdots+e^{x_n})\) is convex on \(\mathbb{R}^n\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Concave:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logarithm. \(\mbox{log}(x)\) concave on \(\mathbb{R}_{++}\).&lt;/li&gt;
  &lt;li&gt;Powers. \(x^a\) is concave for \(0 \leq a \leq 1\).&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Geometric mean. \(f(x) = (\prod\limits_{i=1}^n x_i)^{1/n}\) is concave on \(\mathbb{R}_{++}^n\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Log-determinant. \(f(X) = \mbox{log } \mbox{det } X\) is concave on \(S_{++}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;constrained-optimization-problems&quot;&gt;Constrained Optimization Problems&lt;/h2&gt;

&lt;p&gt;These problems take on a very general form, that we’ll revisit over and over again. In math, that form is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) &amp; \\
\mbox{subject to} &amp; f_i(x) \leq 0, &amp; i=1,\dots,m \\
&amp; h_i(x) = 0, &amp; i=1,\dots,p
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In prose, the problem is to find an \(x\) that minimizes \(f_0(x)\) among all \(x\) that satisfy the conditions \( f_i(x) \leq 0\) for \(i=1,\dots,m \) and \( h_i(x) = 0\) for \( i=1,\dots,p\).&lt;/p&gt;

&lt;p&gt;The inequalities \(f_i(x) \leq 0\) are called inequality constraints, and the equations \(h_i(x) = 0\) are called the equality constraints.&lt;/p&gt;

&lt;h3 id=&quot;the-epigraph-form-of-the-above-standard-problem-is-the-problem&quot;&gt;The Epigraph form of the above standard problem is the problem&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; t &amp; \\
\mbox{subject to} &amp; f_0(x) - t \leq 0 &amp; \\
&amp; f_i(x) \leq 0, &amp; i=1,\dots,m \\
&amp; h_i(x) = 0, &amp; i=1,\dots,p
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Geometrically, from [1]:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/epigraph_problem.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-lagrangian&quot;&gt;The Lagrangian&lt;/h2&gt;

&lt;p&gt;The basic idea in Lagrangian duality is to take the constraints in the standard problem into account by &lt;strong&gt;augmenting the objective function with a weighted sum of the constraint functions&lt;/strong&gt;. The Lagrangian associated with the standard problem is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(x, \lambda, \nu) = f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x)&lt;/script&gt;

&lt;p&gt;We call \(\lambda_i\) as the Lagrange multiplier associated with the \(i\)’th &lt;strong&gt;inequality&lt;/strong&gt; constraint \(f_i(x) \leq 0\).  We refer to \(\nu_i\) as the Lagrange multiplier associated with the \(i\)’th &lt;strong&gt;equality&lt;/strong&gt; constraint \(h_i(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;the-lagrange-dual-function&quot;&gt;The Lagrange Dual Function&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }} L(x,\lambda,\nu)&lt;/script&gt;

&lt;p&gt;In detail, the dual function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g(\lambda, \nu) = \underset{x \in \mathcal{D}}{\mbox{inf }}\Bigg( f_0(x) + \sum\limits_{i=1}^{m} \lambda_i f_i(x) + \sum\limits_{i=1}^p \nu_i h_i(x) \Bigg)&lt;/script&gt;

&lt;p&gt;This is the pointwise infimum of a family of affine functions of \( (\lambda, \nu)\), so the dual function is &lt;strong&gt;concave&lt;/strong&gt;, even when the standard optimization problem is not convex.&lt;/p&gt;

&lt;h3 id=&quot;the-lagrange-dual-problem&quot;&gt;The Lagrange Dual Problem&lt;/h3&gt;

&lt;p&gt;For each pair \( (\lambda, \nu)\), the Lagrange dual function gives us a lower bound on the optimal value \(p^{*}\) of the standard optimization problem. It is a &lt;strong&gt;lower bound&lt;/strong&gt; that depends on some parameters \( (\lambda,\nu)\). But the question of interest for us is, what is the &lt;strong&gt;best&lt;/strong&gt; lower bound that can be obtained from the Lagrange dual function. This leads to the following optimization problem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{ll}
\mbox{maximize} &amp; g(\lambda, \nu) \\
\mbox{subject to} &amp; \lambda \succeq 0
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We refer to this problem as the &lt;strong&gt;Lagrange dual problem&lt;/strong&gt; associated with the standard optimization problem.&lt;/p&gt;

&lt;h3 id=&quot;weak-duality&quot;&gt;Weak Duality&lt;/h3&gt;

&lt;p&gt;Let us define \( d^* \) as the optimal value of the Lagrange dual problem. This is &lt;strong&gt;the best lower bound&lt;/strong&gt; on \( p^* \) that can be obtained from the Lagrange dual function.&lt;/p&gt;

&lt;p&gt;Even if the original problem is not convex, we can always say \(d^* \leq p^*\). We call this property weak duality.&lt;/p&gt;

&lt;h3 id=&quot;slaters-constraint-qualification&quot;&gt;Slater’s Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Slater’s condition is a qualification on the problem constraints. It states that there exists an \(x \in \mbox{relint}(\mathcal{D})\) such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{lll}
f_i(x) &lt; 0, &amp; i=1,\dots,m, &amp; Ax=b.
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Why is that important? Well, because if the problem is convex, and &lt;strong&gt;if Slater’s condition&lt;/strong&gt; holds, then &lt;strong&gt;strong duality&lt;/strong&gt; holds.&lt;/p&gt;

&lt;h2 id=&quot;kkt-conditions-see1-p-243&quot;&gt;KKT Conditions (See[1] p. 243)&lt;/h2&gt;

&lt;p&gt;Let \(x^{\star}\) and \(\lambda^{\star}, \nu^{\star})\) be any primal and dual optimal points with “zero duality gap” (we will explain what this means shortly).&lt;/p&gt;

&lt;p&gt;Since this is a feasible (and optimal) point, each of the \(p\) equality constraints must be fulfilled, meaning:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
h_i(x^{\star}) = 0, i = 1, \dots, p
\end{array}&lt;/script&gt;

&lt;p&gt;Also, we can certainly say that each of the inequality constraints \(f_i\) must also be fulfilled:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_i(x^{\star}) \leq 0, i = 1, \dots , m&lt;/script&gt;

&lt;p&gt;The point \(x^{\star}\) minimizes \(L(x, \lambda^{\star}, \nu^{\star}\) over \(x\in \mathbb{R}^n\), so its gradient must vanish at \(x^{\star}\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla f_0(x^{\star}) + \sum\limits_{i=1}^m \lambda_i^{\star} \nabla f_i(x^{\star} ) + \sum\limits_{i=1}^p \nu_i^{\star} \nabla h_i(x^{\star}) = 0.&lt;/script&gt;

&lt;h3 id=&quot;complementary-slackness&quot;&gt;Complementary Slackness&lt;/h3&gt;
&lt;p&gt;The next condition is called “complementary slackness”, which at first makes absolutely zero sense. However, I will explain it, from [1] and [2]&lt;/p&gt;

&lt;p&gt;Suppose that primal and dual optimal values are attained and equal (so, in
particular, strong duality holds). Let \(x^{\star}\) be a primal optimal and \( (\lambda^{\star}, \nu^{\star})\)  be a dual optimal point. This means that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{ll}
\mbox{primal value} = \mbox{dual value}, &amp; (\mbox{ bc optimal duality gap is zero})\\
f_0(x^{\star}) = g(\lambda^{\star}, \nu^{\star}) &amp; (\mbox{ by definitions of primal and dual function values})\\
= \underset{x}{\mbox{inf }} \Bigg(f_0(x) + \sum\limits_{i=1}^m \lambda_i^{\star} f_i(x) + \sum\limits_{i=1}^p \nu_i^{\star} h_i(x) \Bigg) &amp; (\mbox{ by definition of the dual function})\\
\leq f_0(x^{\star}) + \sum\limits_{i=1}^m \lambda_i^{\star} f_i(x^{\star}) + \sum\limits_{i=1}^p \nu_i^{\star} h_i(x^{\star}) &amp;  \mbox{ (bc the infimum of the Lagrangian over } x \mbox{ is less than or equal to its value at } x = x^{\star} )\\
\leq f_0(x^{\star}) &amp; (\mbox{ bc } \lambda_i^{\star} \geq 0, f_i(x^{\star}) \leq 0, i= 1,\dots,m \mbox{ and } h_i(x^{\star}) = 0, i = 1, \dots, p)
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;This is a somewhat suprising result: all these inequalities are actually equalities.&lt;/p&gt;

&lt;p&gt;We can safely conclude from this proof that the following term is zero:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^m \lambda_i^{\star} + f_i(x^{\star}) = 0.&lt;/script&gt;

&lt;p&gt;At the same time, we know that at \(x^{\star}\) our inequality constraints \(f_i(x^{\star}) \leq 0\) are all fulfilled (\(\forall i)\). Thus, combining this fact with the above result, we know that every single term in the sum must also equal zero:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda_i^{\star} f_i(x^{\star}) = 0, i = 1, \dots , m&lt;/script&gt;

&lt;p&gt;This is &lt;strong&gt;complementary slackness&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the Lagrange dual required that each element of \(\mathbf{\lambda}\) be positive:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;λ_i^{\star} \geq 0, i = 1, \dots , m&lt;/script&gt;

&lt;p&gt;We call these 5 conditions the &lt;strong&gt;Karush-Kuhn-Tucker (KKT) conditions&lt;/strong&gt;. In short, If \(x^{\star}\) and \(u^{\star}, v^{\star}\)
are primal and dual solutions, with zero duality gap, then \(x^{\star}, \lambda^{\star}, \nu^{\star}\) satisfy the KKT conditions.&lt;/p&gt;

&lt;p&gt;In stating this, we have assumed nothing a priori about convexity of our problem, i.e. of \(f_0, f_i, h_i\).&lt;/p&gt;

&lt;h2 id=&quot;simple-example-with-matrix-vector-product-see-2&quot;&gt;Simple Example with Matrix-vector product (See [2])&lt;/h2&gt;

&lt;p&gt;Consider for \(Q \succeq 0\) (i.e. positive semidefinite),&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
\underset{x \in \mathbb{R}^n}{\mbox{min}} &amp; \frac{1}{2}x^TQx + c^Tx \\
\mbox{subject to} &amp; Ax = 0
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;This is a convex problem, so by the KKT conditions, \(x\) is a solution iff&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla L(x,\lambda) = \nabla \Bigg(\frac{1}{2}x^TQx + c^Tx + \lambda^T (Ax) \Bigg) = 0 \\&lt;/script&gt;

&lt;p&gt;For \(\nabla_x\), \( Qx + c + A^T \lambda = 0  \).&lt;/p&gt;

&lt;p&gt;For \(\nabla_{\lambda}\), \(Ax=0\).&lt;/p&gt;

&lt;p&gt;This system of equations can be written in matrix form as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix} Q &amp; A^T \\ A &amp; 0 \end{bmatrix} \begin{bmatrix} x \\ \lambda \end{bmatrix} = \begin{bmatrix} -c \\ 0 \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;for some \(\lambda\).&lt;/p&gt;

&lt;h2 id=&quot;newtons-method&quot;&gt;Newton’s Method&lt;/h2&gt;

&lt;p&gt;Instead of minimizing the first-order Taylor approximation of a function \(f\), we may want to minimize the second-order Taylor approximation, \(f^k(\mathbf{x})\). That approximation around a point \(\mathbf{x}^k\) is given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f^k(\mathbf{x}) = f(\mathbf{x}^k) + \nabla f(\mathbf{x}^k)^T (\mathbf{x}-\mathbf{x}^k) + \frac{1}{2}(\mathbf{x}-\mathbf{x}^k)^T \nabla^2 f(\mathbf{x}^k) (\mathbf{x}-\mathbf{x}^k)&lt;/script&gt;

&lt;p&gt;By setting derivative w.r.t \(\mathbf{x}\) to 0, we find:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla f(\mathbf{x}^k) + \nabla^2 f(\mathbf{x}^k) (\mathbf{x} - \mathbf{x}^k) = 0&lt;/script&gt;

&lt;p&gt;Multiply all terms on the left by the inverse of the Hessian, \(H^{-1}= (\nabla^2 f)^{-1} \),&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\nabla^2 f)^{-1} \nabla f(\mathbf{x}^k) + (\mathbf{x}-\mathbf{x}^k) = 0&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbf{x} = \mathbf{x}^{k} - (\nabla^2 f)^{-1} \nabla f(\mathbf{x}^k)&lt;/script&gt;
The expression you may be familiar with for a Newton step is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{x}^{k+1} = \mathbf{x}^{k} - \frac{ \nabla f(\mathbf{x}^k) }{(\nabla^2 f)}&lt;/script&gt;

&lt;p&gt;However, a Newtons step requires not only the computation of the Hessian, but also being able to invert it. Thus, one may need to regularize \(H=\nabla^2 f\) so that your Hessian \(H\) is invertible (if the Hessian is not positive definite).&lt;/p&gt;

&lt;p&gt;If the function \(f\) is quadratic, then minimizing the 2nd order Taylor approximation given above, \(f^k\), will give us an exact minimizer of \(f\). If the function \(f\) is nearly quadratic, intuition suggests that minimizing this 2nd order expansion should be a very good estimate of the minimizer of \(f\), i.e., \(x^*\).&lt;/p&gt;

&lt;h2 id=&quot;interior-point-methods&quot;&gt;Interior Point Methods&lt;/h2&gt;

&lt;p&gt;Suppose we have the following inequality constrained optimization problem:&lt;/p&gt;

&lt;p&gt;We can approximate the problem as an &lt;strong&gt;equality constrained problem&lt;/strong&gt;. This is highly desirable because we know that Newton’s method can be applied to equality constrained problems. We can make the inequality constraints implicit in the objective:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) + \sum\limits_{i=1}^m I_{-}\bigg(f_i(x)\bigg) &amp; \\
\mbox{subject to} &amp; Ax = b
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The indicator function expresses our displeasure with respect to the satisfaction of the inequality constraints. If the indicator function is violated, its value becomes negative infinity:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
I_{-}(u) = \begin{cases} 0 &amp; u\leq 0 \\ \infty &amp; u &gt; 0 \end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;Otherwise, we ignore its presence in the objective function.  Although we were able to remove the inequality constraints, the objective function is, in general, &lt;strong&gt;not differentiable&lt;/strong&gt;, so Newton’s method cannot be applied.&lt;/p&gt;

&lt;h3 id=&quot;the-log-barrier&quot;&gt;The Log-Barrier&lt;/h3&gt;

&lt;p&gt;However, we could approximate the indicator function \(I_{-}\) with the &lt;strong&gt;log-barrier&lt;/strong&gt; function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{I}_{-}(u) = -\bigg(\frac{1}{t}\bigg) \mbox{log }(-u)&lt;/script&gt;

&lt;p&gt;Here, \(t\) is a parameter that sets the accuracy of the approximation. As \(t\) increases, the approximation becomes more accurate.&lt;/p&gt;

&lt;p&gt;A figure shows the quality of the approximation [1]:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/log_barrier_approximation.png&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We now have a new problem:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\begin{array}{lll}
\mbox{minimize} &amp; f_0(x) + \sum\limits_{i=1}^m -\bigg(\frac{1}{t}\bigg) \mbox{log }\bigg(-f_i(x)\bigg) &amp; \\
\mbox{subject to} &amp; Ax = b
\end{array}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;This objective function is convex, and as long as an &lt;strong&gt;appropriate closedness condition&lt;/strong&gt; holds, Newton’s method can be used to solve it.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References:&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Stephen Boyd and Lieven Vandenberghe. 2004. &lt;a href=&quot;http://stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf&quot;&gt;Convex Optimization&lt;/a&gt;. Cambridge University Press, New York, NY, USA.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gordon, Geoff. CMU 10-725 Optimization Fall 2012 Lecture Slides, &lt;a href=&quot;https://www.cs.cmu.edu/~ggordon/10725-F12/slides/16-kkt.pdf&quot;&gt;Lecture 16&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 01 Apr 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/04/01/cvx/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/04/01/cvx/</guid>
        
        
      </item>
    
      <item>
        <title>Gauss-Newton Optimization in 10 Minutes</title>
        <description>&lt;h2 id=&quot;unconstrained-optimization&quot;&gt;Unconstrained Optimization&lt;/h2&gt;

&lt;h3 id=&quot;the-gauss-newton-method&quot;&gt;The Gauss-Newton Method&lt;/h3&gt;

&lt;p&gt;Suppose our residual is no longer affine, but rather nonlinear. We want to minimize \(\lVert r(x) \rVert^2\). Generally speaking, we cannot solve this problem, but rather can use good heuristics to find local minima.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Start from initial guess for your solution&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Repeat:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;(1) Linearize \(r(x)\) around current guess \(x^{(k)}\). This can be accomplished by using a Taylor Series and Calculus (Standard Gauss-Newton), or one can use a least-squares fit to the line.&lt;/li&gt;
  &lt;li&gt;(2) Solve least squares for linearized objective, get \(x^{(k+1)}\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The linearized residual \(r(x)\) will resemble:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx r(x^{(k)}) + Dr(x^{(k)}) (x-x^{(k)})&lt;/script&gt;

&lt;p&gt;where \(Dr\) is the Jacobian, meaning \( (Dr)_{ij} = \frac{\partial r_i}{\partial x_j}\)&lt;/p&gt;

&lt;p&gt;Distributing the rightmost product, we obtain&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx Dr(x^{(k)})x - \bigg(Dr(x^{(k)}) (x^{(k)}) - r(x^{(k)}) \bigg)&lt;/script&gt;

&lt;p&gt;With a single variable \(x\), we can re-write the above equation as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(x) \approx A^{(k)}x - b^{(k)}&lt;/script&gt;

&lt;h3 id=&quot;levenberg-marquardt-algorithm-trust-region-gauss-newton-method&quot;&gt;Levenberg-Marquardt Algorithm (Trust-Region Gauss-Newton Method)&lt;/h3&gt;

&lt;p&gt;In Levenberg-Marquardt, we have add a term to the objective function to emphasize that we should not move so far from \( \theta^{(k)} \) that we cannot trust the affine approximation. We often refer to this concept as remaining within a “trust region” (&lt;a href=&quot;https://arxiv.org/abs/1502.05477&quot;&gt;TRPO&lt;/a&gt; is named after the same concept). Thus, we wish 
&lt;script type=&quot;math/tex&quot;&gt;|| \theta - \theta^{(k)} ||^2&lt;/script&gt;
 to be small. Our new objective is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;||A^{(k)} \theta - b^{(k)}||^2 + \lambda^{(k)} || \theta − \theta^{(k)}||^2&lt;/script&gt;

&lt;p&gt;This objective can be written inside a single \(\ell_2\)-norm, instead using two separate \(\ell_2\)-norms:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;|| \begin{bmatrix} A^{(k)} \\ \sqrt{\lambda^{(k)}} I \end{bmatrix} \theta - \begin{bmatrix} b^{(k)} \\ \sqrt{\lambda^{(k)}} \theta^{(k)} \end{bmatrix} ||^2&lt;/script&gt;

&lt;p&gt;Suppose we have some input data \(x\) and labels \(y\). Our prediction function could be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f} = x^T\theta_1 + \theta_2&lt;/script&gt;

&lt;p&gt;Suppose at inference time we use \(f(x) = \mbox{sign }\bigg(\hat{f}(x)\bigg)\), where \(\mbox{sign }(a) = +1\) for \(a \geq 0\) and −1 for \(a &amp;lt; 0\). At training time, we use its smooth (and differentiable) approximation, the hyperbolic tangent, tanh:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi(u) = \frac{e^u - e^{-u}}{e^u + e^{-u}}&lt;/script&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The gradient of \(\mbox{tanh}\): \(\nabla_x \mbox{tanh } = 1-\mbox{tanh }(x)^2\). We call this \(\phi^{\prime}\) in code:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;phiprime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Suppose our objective function is the MSE loss, with a regularization term:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J = \sum\limits_{i=1}^{N} \Bigg(y_i - \phi\big(x_i^T\theta_1 + \theta_2\big)\Bigg)^2 + \mu ||\theta_1||^2&lt;/script&gt;

&lt;p&gt;The residual for a single training example \(i\) is \(r_i\) is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_i - \phi\big(x_i^T\theta_1 + \theta_2\big)&lt;/script&gt;

&lt;p&gt;For a vector of training examples \(\mathbf{X}\) and labels \(\mathbf{Y}\), our nonlinear residual function is:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;'*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To linearize the residual, we compute its Jacobian \(Dr(\theta_1,\theta_2)\) via matrix calculus:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial r_i}{\partial \theta_1} = -\phi^{\prime}(x_i^T\theta_1 + \theta_2)x_i^T&lt;/script&gt;

&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;jacobian_0_entr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phiprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'*theta(1:400)+theta(end))* X(:,i)'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial r_i}{\partial \theta_2} = -\phi^{\prime}(x_i^T\theta_1 + \theta_2)&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;jacobian_1_entr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phiprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(:,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;'*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The the full Jacobian evaluated at a certain point \(X_i\) is just these stacked individual entries:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Dr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Dr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jacobian_0_entr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jacobian_1_entr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Let \(\theta= \begin{bmatrix} \theta_1^T &amp;amp; \theta_2 \end{bmatrix}^T \in \mathbb{R}^{401}\). The linearized residual follows the exact form outlined in the Gauss-Newton section above:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r(\theta) \approx A^{(k)}\theta - b^{(k)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b^{(k)} = A^{(k)} \theta^{(k)} - r\bigg(\theta^{(k)}\bigg)&lt;/script&gt;

&lt;p&gt;In code, this term is computed as:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A_k_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;% computed above&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b_k_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We solve a least-squares problem in every iteration, with a 3-part objective function (penalizing the residual, large step sizes, and also large \(\theta_1\)-norm weights):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
|| \begin{bmatrix} A^{(k)} \\ \sqrt{\lambda^{(k)}} I_{401} \\ \begin{bmatrix} \sqrt{\mu} I_{400 } &amp; 0\end{bmatrix} \end{bmatrix} \theta - \begin{bmatrix} b^{(k)} \\ \sqrt{\lambda^{(k)}} \theta^{(k)} \\ 0 \end{bmatrix} ||^2. %]]&gt;&lt;/script&gt;

&lt;p&gt;We represent the left term by&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_k_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and the right term by&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;b_k = [b_k_temp; sqrt(lambda(itr))*theta; zeros(length(theta)-1,1)];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We solve for the next iterate of \(\theta\) with the pseudo-inverse:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;theta_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The full algorithm might resemble:&lt;/p&gt;
&lt;div class=&quot;language-matlab highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;%regularization coefficient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;%initial lambda for Levenberg-Marquardt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;401&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;%initial value for theta (last entry is theta_2)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;%calculate Jacobian at the current iteration (see code above)&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;%linearize the objective function (see code above)&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;% stopping condition ...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sat, 31 Mar 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/03/31/gaussnewton/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/31/gaussnewton/</guid>
        
        
      </item>
    
      <item>
        <title>Linear Algebra Without the Agonizing Pain</title>
        <description>&lt;!-- 
&lt;svg width=&quot;800&quot; height=&quot;200&quot;&gt;
	&lt;rect width=&quot;800&quot; height=&quot;200&quot; style=&quot;fill:rgb(98,51,20)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;20&quot; y=&quot;100&quot; style=&quot;fill:rgb(189,106,53)&quot; /&gt;
	&lt;rect width=&quot;20&quot; height=&quot;50&quot; x=&quot;760&quot; y=&quot;30&quot; style=&quot;fill:rgb(77,175,75)&quot; /&gt;
	&lt;rect width=&quot;10&quot; height=&quot;10&quot; x=&quot;400&quot; y=&quot;60&quot; style=&quot;fill:rgb(225,229,224)&quot; /&gt;
&lt;/svg&gt;
 --&gt;
&lt;h2 id=&quot;linear-algebra-definitions&quot;&gt;Linear Algebra Definitions&lt;/h2&gt;
&lt;p&gt;Before we do anything interesting with machine learning or optimization, we’ll need to review some absolutely &lt;strong&gt;essential&lt;/strong&gt; linear algebra concepts.&lt;/p&gt;
&lt;h3 id=&quot;matrix-rank&quot;&gt;Matrix Rank&lt;/h3&gt;

&lt;h3 id=&quot;vector-space&quot;&gt;Vector Space&lt;/h3&gt;

&lt;h3 id=&quot;null-space-of-a-matrix&quot;&gt;Null Space of a Matrix&lt;/h3&gt;

&lt;p&gt;Given \(A \in \mathbb{R}^{m \times n}\), the &lt;strong&gt;null space&lt;/strong&gt; of \(A\) is the set of vectors which are sent to the zero vector:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(A) = \{ x \in \mathbb{R}^n \mid Ax = 0 \}&lt;/script&gt;

&lt;p&gt;Multiplication by \(A\) can be seen as a function which sends a vector \(x \in \mathbb{R}^n\) to a vector \(Ax \in \mathbb{R}^m\).&lt;/p&gt;

&lt;p&gt;Of course, \(\mathcal{N}(A)\) always contains the zero vector, i.e. \({0} \in \mathcal{N}(A)\). But the question is, does it contain any other vectors? If the columns of \(A\) are linearly independent, then we can always say \(\mathcal{N}(A) = {0} \).&lt;/p&gt;

&lt;h3 id=&quot;column-space-range-of-a-matrix&quot;&gt;Column Space (Range) of a Matrix&lt;/h3&gt;

&lt;p&gt;Given an \(m \times n\) matrix \(A\), we would like to know for which vectors \(b \in \mathbb{R}^m\) the system \(Ax = b\) has a solution. Let’s define the columns of \(A\) as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A = \begin{bmatrix} | &amp; | &amp; &amp; | \\ v_1 &amp; v_2 &amp; \cdots &amp; v_n \\ | &amp; | &amp; &amp; | \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;The column space of \(A\) is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(A) = \mbox{span}(v_1, v_2, \dots, v_n)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(A) = \{ Ax \mid x \in \mathbb{R}^n \}&lt;/script&gt;

&lt;p&gt;The system \(Ax = b\) has a solution &lt;strong&gt;if and only if&lt;/strong&gt; \(b \in C(A)\), equivalent to stating \(b\) is in the range of \(A\): \(b \in R(A)\).&lt;/p&gt;

&lt;h3 id=&quot;rank-nullity-theorem&quot;&gt;Rank-Nullity Theorem&lt;/h3&gt;
&lt;p&gt;Let \(A\) be any matrix such that \(A \in \mathbb{R}^{m \times n}\).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{rank}(A) + \mbox{nullity}(A) = n&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{dim}\bigg(C(A)\bigg) + \mbox{dim}\bigg(N(A)\bigg) = n&lt;/script&gt;

&lt;h3 id=&quot;orthogonal-complement&quot;&gt;Orthogonal Complement&lt;/h3&gt;

&lt;h3 id=&quot;matrix-calculus&quot;&gt;Matrix Calculus&lt;/h3&gt;

&lt;p&gt;Two identities are essential: gradients of matrix-vector products and of quadratic forms.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\( \nabla_x (Ax) = A^T\)&lt;/li&gt;
  &lt;li&gt;\(\nabla_x (x^TAx) = Ax + A^Tx\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When \(A\) is symmetric, which is often the case, \(A = A^T\) and thus \(\nabla_x (x^TAx) = 2Ax \)&lt;/p&gt;

&lt;p&gt;John Duchi explains exactly why identies are true in &lt;a href=&quot;https://web.stanford.edu/~jduchi/projects/matrix_prop.pdf&quot;&gt;[1]&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;gram-schmidt&quot;&gt;Gram Schmidt&lt;/h3&gt;

&lt;h2 id=&quot;solving-systems-of-equations&quot;&gt;Solving Systems of Equations&lt;/h2&gt;

&lt;h3 id=&quot;overdetermined-systems&quot;&gt;Overdetermined Systems&lt;/h3&gt;
&lt;p&gt;Here, matrix \(A\) is a skinny, full-rank matrix. We cannot solve such a system, so instead we minimize a residual \(r\), i.e. we minimize \(\lVert r \rVert^2 = \lVert Ax-y \rVert^2\).  We find an approximate solution to \(Y=Ax\). Formally, we minimize some objective function \(J\):
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\begin{array}{ll}
\mbox{minimize} &amp; J \\
&amp; \lVert r \rVert^2 \\
 &amp;  \lVert Ax-y \rVert^2 \\
&amp; (Ax-y)^T (Ax-y) \\
&amp; (Ax)^T(Ax) - y^TAx - (Ax)^Ty + y^Ty \\
&amp; x^TA^TAx - y^TAx - x^TA^Ty + y^Ty
\end{array}
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can set its gradient to zero, and since the objective is the square of an affine function, it is convex, so we can find its true, global minimum:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla_x J = 2(A^TA)x - 2A^Ty = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2(A^TA)x = 2A^Ty&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(A^TA)x = A^Ty&lt;/script&gt;

&lt;p&gt;Multiply on the left by \((A^TA)^{-1}\), and we recover the least squares solution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ls} = (A^TA)^{-1}A^Ty = A^{\dagger}y&lt;/script&gt;

&lt;p&gt;We call \(A^{\dagger}\) a &lt;strong&gt;left-inverse&lt;/strong&gt; of \(A\) because \(A^{\dagger}A=I\).&lt;/p&gt;

&lt;h3 id=&quot;underdetermined-systems&quot;&gt;Underdetermined Systems&lt;/h3&gt;
&lt;p&gt;Here \(A\) is a fat, full-rank matrix. We can &lt;strong&gt;always&lt;/strong&gt; solve such a system, and there will be an infinite # of solutions.&lt;/p&gt;

&lt;p&gt;We often choose to find the smallest solution, i.e. the one closest to the origin. We call this a least-norm (\(x_{ln}\) ) solution, because we minimize \(\lVert x \rVert\):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{ln} = A^T(AA^T)^{-1}y = A^{\dagger}y&lt;/script&gt;

&lt;p&gt;We call \(A^{\dagger}\) a right-inverse of \(A\) because \(AA^{\dagger}=I\).&lt;/p&gt;

&lt;h2 id=&quot;singular-value-decomposition-svd&quot;&gt;Singular Value Decomposition (SVD)&lt;/h2&gt;

&lt;h3 id=&quot;svd-definition&quot;&gt;SVD Definition&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A=U\Sigma V^T = \begin{bmatrix} u_1 &amp; \dots &amp; u_r \end{bmatrix} \begin{bmatrix} \sigma_1 &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_r \end{bmatrix} \begin{bmatrix} v_1^T \\ \vdots \\ v_r^T \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where \(U\), \(V\) are orthogonal matrices, meaning \(U^TU = I\), \(UU^T=I\).&lt;/p&gt;

&lt;p&gt;We call \(V=\begin{bmatrix} v_1, \dots, v_r \end{bmatrix}\) the right/input singular vectors, because this is the first matrix to interact with an input vector \(x\) when we compute \(y=Ax\).&lt;/p&gt;

&lt;p&gt;We call \(U=\begin{bmatrix} u_1, \dots, u_r \end{bmatrix}\) the left/output singular vectors, because this is the last matrix that the intermediate results are multiplied before we obtain our result ( \(y=Ax\) ).&lt;/p&gt;

&lt;h3 id=&quot;computation-of-the-svd&quot;&gt;Computation of the SVD&lt;/h3&gt;

&lt;p&gt;To find this decomposition for a matrix \(A\), we’ll need to compute the \(V\)’s.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^TA = (V\Sigma U^T) (U \Sigma V^T)&lt;/script&gt;

&lt;p&gt;This reduces to \(V \Sigma^2 V^T\). We need to find orthonormal eigenvectors, and the \(V_i\)’s are simply the eigenvectors of \(A^TA\).&lt;/p&gt;

&lt;p&gt;Now, we’ll need to compute the \(U\)’s.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;AA^T = (U \Sigma V^T)(V\Sigma U^T) = U \Sigma^2 U^T&lt;/script&gt;

&lt;p&gt;The \(U_i\)’s are the eigenvectors of \(AA^T\).&lt;/p&gt;
&lt;h3 id=&quot;svd-applications&quot;&gt;SVD Applications&lt;/h3&gt;

&lt;p&gt;We can use the SVD to compute the general pseudo-inverse of a matrix for \(y=Ax\):&lt;/p&gt;

&lt;p&gt;For skinny/full-rank matrices:&lt;/p&gt;

&lt;h2 id=&quot;extremal-trace-problems&quot;&gt;Extremal Trace Problems&lt;/h2&gt;

&lt;h2 id=&quot;eigenvectors&quot;&gt;Eigenvectors&lt;/h2&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Duchi, John. &lt;a href=&quot;https://web.stanford.edu/~jduchi/projects/matrix_prop.pdf&quot;&gt;Properties of the Trace and Matrix Derivatives&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Fri, 30 Mar 2018 04:00:00 -0700</pubDate>
        <link>http://localhost:4000/2018/03/30/linalg/</link>
        <guid isPermaLink="true">http://localhost:4000/2018/03/30/linalg/</guid>
        
        
      </item>
    
  </channel>
</rss>
