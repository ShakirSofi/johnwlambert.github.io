<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-01-01T01:09:35-05:00</updated><id>http://localhost:4000/</id><title type="html">John Lambert</title><subtitle>Ph.D. Candidate in Computer Vision.
</subtitle><entry><title type="html">Lie Groups and Rigid Body Kinematics</title><link href="http://localhost:4000/lie-groups/" rel="alternate" type="text/html" title="Lie Groups and Rigid Body Kinematics" /><published>2018-12-28T06:00:00-05:00</published><updated>2018-12-28T06:00:00-05:00</updated><id>http://localhost:4000/lie-groups</id><content type="html" xml:base="http://localhost:4000/lie-groups/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#whyliegroups&quot;&gt;Why do we need Lie Groups?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#liegroups&quot;&gt;Lie Groups&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#son&quot;&gt;SO(N)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so2&quot;&gt;SO(2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#so3&quot;&gt;SO(3)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#se2&quot;&gt;SE(2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#se3&quot;&gt;SE(3)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conjugation&quot;&gt;Conjugation in Group Theory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lie-algebra&quot;&gt;The Lie Algebra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;whyliegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-do-we-need-lie-groups&quot;&gt;Why do we need Lie Groups?&lt;/h2&gt;

&lt;p&gt;Rigid bodies have a state which consists of position and orientation. When sensors are placed on a rigid body (e.g. a robot), they provide measurements in the body frame. Suppose we wish to take a measurement &lt;script type=&quot;math/tex&quot;&gt;y_b&lt;/script&gt; from the body frame and move it to the world frame, &lt;script type=&quot;math/tex&quot;&gt;y_w&lt;/script&gt;. We can do this via left multiplication with a transformation matrix &lt;script type=&quot;math/tex&quot;&gt;{}^{w}T_{b}&lt;/script&gt;, a member of the matrix Lie groups, that transports the point from one space to another space:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_w = {}^{w}T_{b} y_b&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;liegroups&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;lie-groups&quot;&gt;Lie Groups&lt;/h2&gt;

&lt;p&gt;When we are working with pure rotations, we work with Special Orthogonal groups, &lt;script type=&quot;math/tex&quot;&gt;SO(\cdot)&lt;/script&gt;. When we are working with a rotation and a translation together, we work with Special Euclidean groups &lt;script type=&quot;math/tex&quot;&gt;SE(\cdot)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Lie Groups are unique because they are &lt;strong&gt;both a group and a manifold&lt;/strong&gt;. They are continuous manifolds in high-dimensional spaces, and have a group structure. I’ll describe them in more detail below.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;son&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;son&quot;&gt;SO(N)&lt;/h3&gt;

&lt;p&gt;Membership in the Special Orthogonal Group &lt;script type=&quot;math/tex&quot;&gt;SO(N)&lt;/script&gt; requires two matrix properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;R^TR = I&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{det}(R) = +1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This gives us a very helpful property: &lt;script type=&quot;math/tex&quot;&gt;R^{-1} = R^T&lt;/script&gt;, so the matrix inverse is as simple as taking the transpose.  We will generally work with &lt;script type=&quot;math/tex&quot;&gt;SO(N)&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;N=2,3&lt;/script&gt;, meaning the matrices are rotation matrices &lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{2 \times 2}&lt;/script&gt; or &lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{3 \times 3}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;These rotation matrices &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt; are not commutative.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;so2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;so2&quot;&gt;SO(2)&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt; is a 1D manifold living in a 2D Euclidean space, e.g. moving around a circle.  We will be stuck with singularities if we use 2 numbers to parameterize it, which would mean kinematics break down at certain orientations.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt; is the space of orthogonal matrices that corresponds to rotations in the plane.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A simple example&lt;/strong&gt;:
Let’s move from the body frame &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; to a target frame &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_t = {}^tR_b(\theta) P_b&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
5 \mbox{ cos} (\theta) \\
5 \mbox{ sin} (\theta)
\end{bmatrix} = \begin{bmatrix} cos(\theta) &amp; -sin(\theta) \\ sin(\theta) &amp; cos(\theta) \end{bmatrix} * \begin{bmatrix} 5 \\ 0 \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;As described in [3], another way to think of this is to consider that a robot can be rotated counterclockwise by some angle &lt;script type=&quot;math/tex&quot;&gt;\theta \in [0,2 \pi)&lt;/script&gt; by mapping every &lt;script type=&quot;math/tex&quot;&gt;(x,y)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(x, y) \rightarrow (x \mbox{ cos } \theta − y \mbox{ sin } \theta, x \mbox{ sin } \theta + y \mbox{ cos } \theta).&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;so3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;so3&quot;&gt;SO(3)&lt;/h3&gt;

&lt;p&gt;There are several well-known parameterizations of &lt;script type=&quot;math/tex&quot;&gt;R \in SO(3)&lt;/script&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(1.) &lt;script type=&quot;math/tex&quot;&gt;R \in \mathbf{R}^{3 \times 3}&lt;/script&gt; full rotation matrix, 9 parameters – there must be 6 constraints&lt;/li&gt;
  &lt;li&gt;(2.) Euler angles, e.g. &lt;script type=&quot;math/tex&quot;&gt;(\phi, \theta, \psi)&lt;/script&gt;, so 3 parameters&lt;/li&gt;
  &lt;li&gt;(3.) Angle-Axis parameters &lt;script type=&quot;math/tex&quot;&gt;(\vec{a}, \phi)&lt;/script&gt;, which is 4 parameters and 1 constraint (unit length)&lt;/li&gt;
  &lt;li&gt;(4.) Quaternions (&lt;script type=&quot;math/tex&quot;&gt;q_0,q_1,q_2,q_3)&lt;/script&gt;, 4 parameters and 1 constraint (unit length)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are only 3 degrees of freedom in describing a rotation. But this object doesn’t live in 3D space. It is a 3D manifold, embedded in a 4-D Euclidean space.&lt;/p&gt;

&lt;p&gt;Parameterizations 1,3,4 are overconstrained, meaning they employ more parameters than we strictly need. With overparameterized representations, we have to do extra work to make sure we satisfy the constraints of the representation.&lt;/p&gt;

&lt;p&gt;As it turns out &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; cannot be parameterized by only 3 parameters in a non-singular way.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Euler Angles&lt;/strong&gt;
One parameterization of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; is to imagine three successive rotations around different axes. The Euler angles encapsulate yaw-pitch-roll: first, a rotation about the z-axis (yaw, &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;). Then, a rotation about the pitch axis by &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (via right-hand rule), and finally we perform a roll by &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;.&lt;/p&gt;

&lt;div class=&quot;fig figcenter fighighlight&quot;&gt;
  &lt;img src=&quot;/assets/euler_angles.jpg&quot; width=&quot;65%&quot; /&gt;
  &lt;div class=&quot;figcaption&quot;&gt;
    The Euler angles.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The sequence of successive rotations is encapsulated in &lt;script type=&quot;math/tex&quot;&gt;{}^{w}R_b&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{w}R_b = R_R(\phi) R_P(\theta) R_Y (\psi)&lt;/script&gt;

&lt;p&gt;As outlined in [3], these successive rotations by &lt;script type=&quot;math/tex&quot;&gt;(\phi, \theta, \psi)&lt;/script&gt; are defined by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{yaw} = R_y (\psi) = \begin{bmatrix}
\mbox{cos} \psi &amp; -\mbox{sin} \psi  &amp; 0 \\
\mbox{sin} \psi &amp; \mbox{cos} \psi &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{pitch} = R_p (\theta) = \begin{bmatrix}
\mbox{cos} \theta &amp; 0 &amp; \mbox{sin} \theta \\
 0 &amp; 1 &amp; 0 \\
 -\mbox{sin} \theta &amp; 0 &amp; \mbox{cos} \theta \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
R_{roll} = R_R (\phi) = \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; \mbox{cos} \phi &amp; -\mbox{sin} \phi \\
0 &amp; \mbox{sin} \phi &amp;  \mbox{cos} \phi \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;You have probably noticed that each rotation matrix &lt;script type=&quot;math/tex&quot;&gt;\in \mathbf{R}^{3 \times 3}&lt;/script&gt; above is a simple extension of the 2D rotation matrix from &lt;script type=&quot;math/tex&quot;&gt;SO(2)&lt;/script&gt;. For example, the yaw matrix &lt;script type=&quot;math/tex&quot;&gt;R_{yaw}&lt;/script&gt; performs a 2D rotation with respect to the &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; coordinates while leaving the &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; coordinate unchanged [3].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;se2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;se2&quot;&gt;SE(2)&lt;/h3&gt;

&lt;p&gt;The real space &lt;script type=&quot;math/tex&quot;&gt;SE(2)&lt;/script&gt; are &lt;script type=&quot;math/tex&quot;&gt;3 \times 3&lt;/script&gt; matrices, moving a point in homogenous coordinates to a new frame. It is important to remember that this represents a rotation followed by a translation (not the other way around).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
T = \begin{bmatrix} x_w \\ y_w \\ 1 \end{bmatrix} = \begin{bmatrix}
 R_{2 \times 2}&amp; &amp; t_{2 \times 1}  \\
&amp; \ddots &amp; \vdots  \\
0 &amp; 0 &amp; 1
\end{bmatrix} * \begin{bmatrix} x_b \\ y_b \\ 1 \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;By adding an extra dimension to the input points and transformation matrix &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; the translational part of the transformation is absorbed [3].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;se3&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;se3&quot;&gt;SE(3)&lt;/h3&gt;

&lt;p&gt;The real space &lt;script type=&quot;math/tex&quot;&gt;SE(3)&lt;/script&gt; are &lt;script type=&quot;math/tex&quot;&gt;4 \times 4&lt;/script&gt; matrices, the real space resembles:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
&amp; &amp; &amp; \\
&amp; R_{3 \times 3} &amp; &amp;  t_{3 \times 1} \\
&amp; &amp; &amp; \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;conjugation&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conjugation-in-group-theory&quot;&gt;Conjugation in Group Theory&lt;/h2&gt;

&lt;p&gt;Surprisingly, movement in &lt;script type=&quot;math/tex&quot;&gt;SE(2)&lt;/script&gt; can always be achieved by moving somewhere, making a rotation there, and then moving back.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SE(2) = (\cdot) SO(2) (\cdot)&lt;/script&gt;

&lt;p&gt;If we move to a point by vector movement &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;, essentially we perform: &lt;script type=&quot;math/tex&quot;&gt;B-p&lt;/script&gt;, then go back with &lt;script type=&quot;math/tex&quot;&gt;p + \dots&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
B^{\prime} = \begin{bmatrix}
R &amp; t \\
0 &amp; 1
\end{bmatrix}_B = \begin{bmatrix}
I &amp; p \\
0 &amp; 1
\end{bmatrix} \begin{bmatrix}
R &amp; 0 \\
0 &amp; 1
\end{bmatrix} \begin{bmatrix}
I &amp; -p \\
0 &amp; 1
\end{bmatrix}_B %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;a name=&quot;lie-algebra&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;connecting-spatial-coordinates-and-spatial-velocities-the-lie-algebra&quot;&gt;Connecting Spatial Coordinates and Spatial Velocities: The Lie Algebra&lt;/h2&gt;

&lt;p&gt;The Lie Algebra maps spatial coordinates to spatial velocity.&lt;/p&gt;

&lt;p&gt;In the case of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt;, the Lie Algebra is the space of skew-symmetric matrices&lt;/p&gt;

&lt;p&gt;Rigid Body Kinematics: we want a differential equation (ODE) that links &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;{}^{^w}R_b&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;in particular,
&lt;script type=&quot;math/tex&quot;&gt;{}^{^w} \dot{R}_r = f({}^{^w}R_b, \vec{\omega})&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\frac{ \partial }{\partial t}(R^R = I)
 \\
\dot{R}^TR + R^T \dot{R} = 0 \\
\dot{R}^TR = -R^T \dot{R} 
\end{aligned}&lt;/script&gt;

&lt;p&gt;we define &lt;script type=&quot;math/tex&quot;&gt;\Omega = R^T \dot{R}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega^T = (R^T \dot{R} )^T = \dot{R}^TR  = -R^T \dot{R}  = -\Omega&lt;/script&gt;

&lt;p&gt;Skew-symmetric! $\Omega^T = -\Omega$&lt;/p&gt;

&lt;p&gt;In fact,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\Omega = \begin{bmatrix}
0 &amp; -\omega_z &amp; \omega_y \\
\omega_z &amp; 0 &amp; -\omega_x \\
-\omega_y &amp; \omega_x &amp; 0
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega} = \begin{bmatrix} \omega_x \\ \omega_y \\ \omega_z \end{bmatrix}&lt;/script&gt; is the angular velocity&lt;/p&gt;

&lt;p&gt;Notation! the “hat” map&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{\omega}^{\hat{}} =\Omega&lt;/script&gt;

&lt;p&gt;the “v” map&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega^{v} = \bar{\omega}&lt;/script&gt;

&lt;p&gt;So we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\dot{R} = R \Omega \\
\Omega = \bar{\omega}^{\hat{}}
\end{aligned}&lt;/script&gt;

&lt;p&gt;\item In terms of frames, we have Poisson’s kinematic equation&lt;/p&gt;

&lt;p&gt;\item The intrinsic equation is (where &lt;script type=&quot;math/tex&quot;&gt;\vec{\omega}_b&lt;/script&gt; in the body frame is $\Omega_b$):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{^w}\dot{R}_b =  {}^{^w}R_b \Omega_b&lt;/script&gt;

&lt;p&gt;The “strap-down” equation (extrinsic)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{}^{^b}\dot{R}_w =  - \Omega_b {}^{^b}R_w&lt;/script&gt;

&lt;p&gt;Take vector on aircraft, put it into the coordinate frame of the world&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
{}_{^w}R_b = \begin{bmatrix} | &amp; | &amp; | \\ {}^{^w} \hat{x}_b &amp; {}^{^w}\hat{y}_b &amp; {}^{^w} \hat{z}_b \\ | &amp; | &amp; |  \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega \vec{v}_b = \omega \times \vec{v}_b&lt;/script&gt;

&lt;p&gt;Can we use this for filtering? Can we use &lt;script type=&quot;math/tex&quot;&gt;\dot{R} = R \Omega&lt;/script&gt; directly in an EKF, UKF
We’d have to turn it into discrete-time 
Naively, you might do the first order Euler approximation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{ R_{t + \delta_t} -R_t}{\delta t} \approx R_t \Omega_t&lt;/script&gt;

&lt;p&gt;This does not work!&lt;/p&gt;

&lt;p&gt;You won’t maintain orthogonality! The defining property of &lt;script type=&quot;math/tex&quot;&gt;SO(3)&lt;/script&gt; was orthogonality, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{t + \delta t} \not\in SO(3)&lt;/script&gt;

&lt;p&gt;and pretty soon&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
R_{t + \delta t}^T R_{t + \delta t} \neq I \\
\mbox{det }(R_{t+\delta t}) \neq +1
\end{aligned}&lt;/script&gt;

&lt;p&gt;The 3x3 matrix will not be recognizable of a rotation&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Frank Dellaert. Lecture Presentations of MM 8803: Mobile Manipulation, taught at the Georgia Institute of Technology, Fall 2018.&lt;/p&gt;

&lt;p&gt;[2] Mac Schwager. Lecture Presentations of AA 273: State Estimation and Filtering for Aerospace Systems, taught at Stanford University in April-June 2018.&lt;/p&gt;

&lt;p&gt;[3] Steven M. LaValle. &lt;em&gt;Planning Algorithms&lt;/em&gt;. Cambridge University Press, 2006, New York, NY, USA.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rigid Body Kinematics and Filtering&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kinematics with Euler Angles&lt;/p&gt;

&lt;p&gt;\begin{equation}
\dot{R} = f(R, \vec{w}), (\dot{\phi}, \dot{\theta}, \dot{\psi}) = f(\phi, \theta, \psi, \vec{\omega})
\end{equation}&lt;/p&gt;

&lt;p&gt;\item&lt;/p&gt;

&lt;p&gt;\begin{equation}
\vec{\omega} = \begin{bmatrix} w_x \ w_y \ w_z \end{bmatrix} = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; -\mbox{sin} \theta \ 0 &amp;amp; \mbox{cos} \phi &amp;amp; \mbox{sin} \phi \mbox{cos} \phi \ 0 &amp;amp; -\mbox{sin} \phi &amp;amp; \mbox{cos} \phi \mbox{cos} \theta \end{bmatrix} \begin{bmatrix} \dot{\phi} \ \dot{\theta} \ \dot{\psi} \end{bmatrix}
\end{equation}&lt;/p&gt;

&lt;p&gt;\item We want to invert this matrix and solve for $\begin{bmatrix} \dot{\phi} \ \dot{\theta} \ \dot{\psi} \end{bmatrix}$&lt;/p&gt;</content><author><name></name></author><summary type="html">SO(2), SO(3), SE(2), SE(3), Lie algebras</summary></entry><entry><title type="html">Spectral Clustering</title><link href="http://localhost:4000/spectral-clustering/" rel="alternate" type="text/html" title="Spectral Clustering" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/spectral-clustering</id><content type="html" xml:base="http://localhost:4000/spectral-clustering/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#need-for-dr&quot;&gt;Need for Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pca&quot;&gt;PCA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;need-for-dr&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;spectral-clustering&quot;&gt;Spectral Clustering&lt;/h2&gt;

&lt;p&gt;\subsection{Graph Partitioning}
\begin{itemize}
\item Graph-cut problem: partition graph such that (1) edges between groups have a very low weight, and (2) edges within a group have high weight
\item Could use \textbf{Ratio Cut} (by size of the component) or the \textbf{Normalized Cut} (or by volume of the component, aka the sum of degrees)
\item Penalize using very small components, or very large components
\item These are NP-hard combinatorial problems. But Spectral clustering offers a way to solve the relaxation version of these problems
\item NCut -&amp;gt; use random-walk laplacian
\item RatioCut -&amp;gt; use unnormalized laplacian
\item 2-partition: assign by vector values of Fiedler vectors $\in \mathbbm{R}$, which ones $\in \mathbbm{R}&lt;em&gt;+$, or in $\mathbbm{R}&lt;/em&gt;-$
\item Can apply k-means or standard clustering algorithm on the embedded points (transform graph clustering into a point clustering problem!). Take you into point cloud setting
\item K-means minimizes the distortion measure/energy
\begin{equation}
J = \sum\limits_j \sum\limits_k r_{ji}(y_j - \mu_i)^2 ??
\end{equation}
\item Centroid already minimizes the sum of squared distances
\item Can only reduce energy in every step (locally converge to minimum)
\item Can discover number of clusters that you need – look at gap between eigenvalues, where is there a large gap $|\lambda_k - \lambda_{k-1}|$. 
\item Eigenvalues drop fast, then stabilize
\item Spectral clustering can cluster spirals of points, where k-nearest neighbors in this space would epicly fail
\item Look at data at a very different way… Even though data comes from a Euclidean space, easier to understand in the spectral space
\item edge weight $\mbox{exp} (-diff(pixel_{i}, pixel_j)/t^2 )$
\item Get reasonable, but not perfect, results for 3d segmentation
\item Fast and efficient with decent results
\end{itemize}&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Leonidas Guibas. &lt;em&gt;Graph Laplacians, Laplacian Embeddings, and Spectral Clustering&lt;/em&gt;. Lectures of CS233: Geometric and Topological Data Analysis, taught at Stanford University in Spring 2018.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Understanding Multivariate Gaussians and Covariance</title><link href="http://localhost:4000/learning-point-cloud-features/" rel="alternate" type="text/html" title="Understanding Multivariate Gaussians and Covariance" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/learning-point-cloud-features</id><content type="html" xml:base="http://localhost:4000/learning-point-cloud-features/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;semantic-segmentation-of-features&quot;&gt;Semantic Segmentation of Features&lt;/h2&gt;

&lt;h2 id=&quot;instance-segmentation-of-features&quot;&gt;Instance Segmentation of Features&lt;/h2&gt;

&lt;p&gt;SPGN…&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;</content><author><name></name></author><summary type="html">PointNet, SPGN, SPLATNet, Dynamic Graph Learning</summary></entry><entry><title type="html">Dimensionality Reduction</title><link href="http://localhost:4000/dimensionality-reduction/" rel="alternate" type="text/html" title="Dimensionality Reduction" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/dimensionality-reduction</id><content type="html" xml:base="http://localhost:4000/dimensionality-reduction/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#need-for-dr&quot;&gt;Need for Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pca&quot;&gt;PCA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nonlinear-dr-methods&quot;&gt;Nonlinear Dimensionality Reduction Methods&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#isomap&quot;&gt;ISOMAP&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lle&quot;&gt;LLE&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sne&quot;&gt;SNE&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#t-sne&quot;&gt;t-SNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;need-for-dr&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-need-for-dimensionality-reduction&quot;&gt;The Need for Dimensionality Reduction&lt;/h2&gt;

&lt;p&gt;&lt;a name=&quot;pca&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;linear-methods--pca&quot;&gt;Linear Methods &amp;amp; PCA&lt;/h3&gt;

&lt;p&gt;PCA is a surprisingly confusing algorithm for linear dimensionality reduction.&lt;/p&gt;

&lt;p&gt;https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch18.pdf&lt;/p&gt;

&lt;p&gt;http://theory.stanford.edu/~tim/s17/l/l8.pdf&lt;/p&gt;

&lt;p&gt;\subsection{Data as Points in a Euclidean Space}
\begin{itemize}
\item Many scalar &lt;code class=&quot;highlighter-rouge&quot;&gt;attributes''
\item Could  be very high dim space, where real space of data is low-dim
\item But data just lives in high-dim subspace
\item Find lower-dim subspace, where close to living inside the high-dim space (lower-d structure corresponds to linear subspaces in high-dim space)
\item Pearson (1901) -- find a single lower dimensional subspace that captures most of the variation in the data
\item What should be the dimensionality of the lower-dim space? How many dimensions do we need to explain most of the variability in the data
\item Acts as a proxy for the real space
\item Minimize errors introudced by projecting the data into this subspace
\item Assumption: data has zero mean,&lt;/code&gt;centered data’’
\item Move the origin to the middle of the data, the data will live in the hyperplane. Becomes subspace in new translated coordinate system
\item As a consequence, variance becomes just the 2nd moment
\item Data points in 2D -&amp;gt; project onto the best fit line (projection onto 1D), then assess how well the data looks now when you lay out the projected points onto the best fit line (this is the reconstruction)
\item Bring it back onto the best fit line (multiply by vector)
\begin{equation}
x_{||} = vv^Tx
\end{equation}
\item Minimize an error function: error equivalent to maximizing the variance of the projected data
\begin{equation}
E = \frac{1}{M} \sum\limits_I \sum\limits_M … = &amp;lt; |x^{\prime \mu} - x_{||}^{\prime \mu}|^2 &amp;gt;&lt;em&gt;{\mu}
\end{equation}
$I$ dimensions
\item WHY IS THIS?
\item Trying to find the directions of maximum variance
\item Knowing the covariance matrix tells us about the 2nd order moments, but not about the highest-order structure of the data (unless data is normal)
\item If the covariance matrix is diagonal, then finding the direction of maximum variance is easy
\item Rotate your coordinate system so that the covariance matrix becomes diagonal.
\item This becomes an eigenvalue problem: the eigenvectors of the covariance matrix point in the directions of maximal variance?
\item Solve all top-k possible subspaces
\item Valid for all of them
\item Check the error depending on many dimensions we used. A tradeoff
\item $\mathbf{V}^T \mathbf{V} = I$ because $\mathbf{V}$ is an orthonormal matrix
\item Projection $x&lt;/em&gt;{||} = \mathbf{V}y = \mathbf{V}\mathbf{V}^Tx$
\item Projection operator = $\mathbf{V}\mathbf{V}^T$
\item But in general $P$ is of low rank and loses info
\item Variance and reconstruction error
\begin{equation}
&amp;lt;x^Tx&amp;gt; - &amp;lt;y_{||}^T y_{||}&amp;gt;
\end{equation}
\item Want to be able to maximize the variance in the projected subspace… (FIND OUT WHY THAT IS)
\item Spectral analysis of the covariance matrix:
if covariance matrix is symmetric, it always has real eigenvalues and orthogonal eigenvectors
\item The total variance fo the data is just the sum of the eigenvalues of the covariance matrix, all non-negative
\item Have diagonalized the covariance matrix, aligned, which was what we set out to do
\item This is an extremal trace problem?
\item 
\begin{equation}
\sum\limits_i \lambda_i \sum\limits_p (v_{ip}^{\prime})^2
\end{equation}
\item $ = \mbox{tr }(V^{\prime T} \Lambda V^{\prime})$
\item To maximize the variance, need to put as mucch weight as possible on the large eigenvalues
\item The reconstruction error is 
\begin{equation}
\sum\limits_{i=P+1}^I \lambda_i
\end{equation}
\item Aligns the axis with your data, so that for any $P$, can find $P$-dimensional subspace
\item \textbf{Main Lesson from PCA}: For any P, the optimal $P$-dimensional subspace is the one spanned by the first $P$ eigenvectors of the covariance matrix
\item The eigenvectors give us the frame that we need – align with it
\end{itemize}
\subsection{PCA Examples}
\begin{itemize}
\item First principal component does not always have semantic meaning (combination of arts, recreation, transportation, health, and housing explain the ratings of places the most)
\item This is simply what the analysis gives.
\item The math is beautiful, but semantic meaning is not always clear. Sparse PCA tries to fix this (linear combinations of only a small number of variables)
\item Geography of where an individual came from is reflected in their genetic material
\item Machinery gives us a way to understand distortions of changes: a recipe encoded as a matrix
\item PCA works very well here
\item View matrices as points in high-dimensional space
\item Recover grid structure for deformed sphere
\item Get circular pattern of galloping horse from points
\end{itemize}
\subsection{Trick}
\begin{itemize}
\item What if we have fewer data points than dimensions $M&amp;lt;I$? Think of images…
\item By SVD, transpose your data
\item Think of your data as rows, not columns
\item Data becomes first pixel across 1000 images
\item Covariance matrix $C_2$ of transposed problem
\item Rows of transformed X (PCA’d X) are just eigenvectors of $C_1$
\item Corresponding eigenvalues are just those of $C_2$, scaled by $I/M$&lt;/p&gt;

&lt;p&gt;ntroduced by Pearson (1901)
and Hotelling (1933) to
describe the variation in a set
of multivariate data in terms of
a set of uncorrelated variables.
PCA looks for a single lower
dimensional subspace that
captures most of the variation
in the data.
Specifically, we aim to
minimize the error introduced
by projecting the data into this
linear subspace.&lt;/p&gt;

&lt;p&gt;Use spectral analysis of the covariance matrix C of the
data
For any integer p, the error-minimizing p-dimensional
subspace is the one spanned by the first p eigenvectors
of the covariance matrix&lt;/p&gt;

&lt;p&gt;Eigenfaces (PCA on face images)&lt;/p&gt;

&lt;p&gt;M. Turk and A. Pentland, Face Recognition using Eigenfaces, CVPR 1991&lt;/p&gt;

&lt;h2 id=&quot;multi-dimensional-scaling-mds&quot;&gt;Multi-Dimensional Scaling (MDS)&lt;/h2&gt;

&lt;p&gt;&lt;a name=&quot;nonlinear-dr-methods&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;non-linear-methods&quot;&gt;Non-Linear Methods&lt;/h2&gt;

&lt;p&gt;Many data sets contain essential nonlinear structures and unfortunately these structures are invisible to linear methods like PCA [1].&lt;/p&gt;

&lt;p&gt;For example, Euclidean distance between points cannot disentangle or capture the structure of manifolds like the “swiss roll.” Instead, we need geodesic distance: distance directly on the manifold.&lt;/p&gt;

&lt;p&gt;Furthermore, PCA cares about large distances. The goal is to maximize variance, and variance comes from things that are far apart. If you care about small distances, PCA is the wrong tool to use.&lt;/p&gt;

&lt;h2 id=&quot;creating-graphs-from-geometric-point-data&quot;&gt;Creating Graphs from Geometric Point Data&lt;/h2&gt;

&lt;p&gt;Rely upon neighborhood relations. A graph can be constructed via (1) k-nearest neighbors or (2) &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;-balls.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;isomap&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;isometric-feature-mapping-isomap&quot;&gt;Isometric Feature Mapping (ISOMAP)&lt;/h3&gt;

&lt;p&gt;In the case of the swiss roll, Isometric Feature Mapping (ISOMAP) produces an unrolled, planar version of data that respects distances [5]. This is “isometric” unrolling.&lt;/p&gt;

&lt;p&gt;The ISOMAP algorithm involves three main steps, as outlined by Guibas [1]:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(1.) Form a nearest-neighbor graph &lt;script type=&quot;math/tex&quot;&gt;\mathcal{G}&lt;/script&gt; on the original data points, weighing the edges by their original distances &lt;script type=&quot;math/tex&quot;&gt;d_x(i,j)&lt;/script&gt;. One can build the NN-graph either (A) with a fixed radius/threshold &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;, or by using a (B) fixed # of neighbors.&lt;/li&gt;
  &lt;li&gt;(2.) Estimate the geodesic distances &lt;script type=&quot;math/tex&quot;&gt;d_{\mathcal{G}}(i,j)&lt;/script&gt; between all pairs of points on the sampled manifold by computing their shortest path distances in the graph &lt;script type=&quot;math/tex&quot;&gt;\mathcal{G}&lt;/script&gt;. This can be done with classic graph algorithms for all-pairs shortest-path algorithm (APSP)s: Floyd/Warshall’s algorithm or Dijkstra’s algorithm. Initially, all pairs given distance &lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;, except for neighbors, which are connected.&lt;/li&gt;
  &lt;li&gt;(3.) Construct an embedding of the data in &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;-dimensional Euclidean space that best preserves the inter-point distances &lt;script type=&quot;math/tex&quot;&gt;d_{\mathcal{G}}(i,j)&lt;/script&gt;. This is performed via Multi-Dimensional Scaling (MDS).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ISOMAP actually comes with recovery guarantees that discovered structure equal to actual structure of the manifold, especially as the graph point density increases. MDS and ISOMAP both converge, but ISOMAP gets there more quickly.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;lle&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;locally-linear-embedding-lle&quot;&gt;Locally Linear Embedding (LLE)&lt;/h3&gt;

&lt;p&gt;LLE is a method that learns linear weights that locally reconstruct points in order to map points to a lower dimension [1,4]. The method requires solving two successive optimization problems and requires a connectivity graph. Almost all methods start with the nearest neihgbor graph, since it’s the only thing that we can trust.&lt;/p&gt;

&lt;p&gt;In the &lt;strong&gt;first step of LLE&lt;/strong&gt;, we find weights that reconstruct each data point from its neighbors:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
\underset{w}{\mbox{minimize }} &amp; \| x_i - \sum\limits_{j \in N(i)} w_{ij}x_j \|^2 \\
\mbox{subject to} &amp; \sum\limits_j w_{ij} = 1
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;We can use linear least squares with Lagrange multipliers to obtain optimal linear combinations.&lt;/p&gt;

&lt;p&gt;In the &lt;strong&gt;second step of LLE&lt;/strong&gt;, We then &lt;strong&gt;fix these weights&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;w_{ij}&lt;/script&gt; while optimizing for &lt;script type=&quot;math/tex&quot;&gt;x_i^{\prime}&lt;/script&gt;. We try to find low-dimensional coordinates:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{ll}
\underset{x_1^{\prime}, \dots, x_n^{\prime}}{\mbox{minimize }} \sum\limits_i \| x_i^{\prime} - \sum\limits_{j \in N(i)} w_{ij}x_j^{\prime} \|^2
\end{array}&lt;/script&gt;

&lt;p&gt;This is a sparse eigenvalue problem that requires constraints in order to prevent degenerate solutions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(1.) The coordinates &lt;script type=&quot;math/tex&quot;&gt;x_i^{\prime}&lt;/script&gt; can be translated by a constant
displacement without affecting the cost. We can remove this degree of freedom by requiring the coordinates to be centered on the origin.&lt;/li&gt;
  &lt;li&gt;(2.) We constrain the embedding vectors to have unit covariance.
The optimization problem becomes:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
\underset{x_1^{\prime}, \dots, x_n^{\prime}}{\mbox{minimize }} &amp; \sum\limits_i \| x_i^{\prime} - \sum\limits_{j \in N(i)} w_{ij}x_j^{\prime} \|^2 \\
\mbox{subject to} &amp; \sum\limits_i x_i^{\prime} = 0 \\
&amp; \frac{1}{n} \sum\limits_i x_i^{\prime}x_i^{\prime T} = I
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;These weights &lt;script type=&quot;math/tex&quot;&gt;w_{ij}&lt;/script&gt; capture the local shape. As Roweis and Saul point out, “&lt;em&gt;LLE illustrates a general principle of manifold learning…that overlapping
local neighborhoods – collectively analyzed – can provide information about global
geometry&lt;/em&gt;”” [4].&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;sne&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;stochastic-neighbor-embedding-sne&quot;&gt;Stochastic Neighbor Embedding (SNE)&lt;/h3&gt;

&lt;p&gt;The Stochastic Neighbor Embedding (SNE) converts high-dimensional points to low-dimensional points by preserving distances. The method takes a probabilistic point of view: high-dimensional Euclidean point distances are converted into conditional probabilities that represent similarities [2,3].&lt;/p&gt;

&lt;p&gt;Similarity of datapoints in &lt;strong&gt;high himension&lt;/strong&gt;: The conditional probability is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{j \mid i} = \frac{\mbox{exp }\big( - \frac{\|x_i - x_j\|^2}{2 \sigma_i^2}\big) }{ \sum\limits_{k \neq i} \mbox{exp }\big( - \frac{\|x_i - x_k\|^2}{2 \sigma_i^2} \big)}&lt;/script&gt;

&lt;p&gt;Similarity of datapoints in &lt;strong&gt;the low dimension&lt;/strong&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{j \mid i} = \frac{\mbox{exp }\big( - \|y_i - y_j\|^2\big) }{ \sum\limits_{k \neq i} \mbox{exp }\big( - \|y_i - y_k\|^2 \big)}&lt;/script&gt;

&lt;p&gt;If similarities between &lt;script type=&quot;math/tex&quot;&gt;x_i,x_j&lt;/script&gt; are correctly mapped to similarities between &lt;script type=&quot;math/tex&quot;&gt;y_i,y_j&lt;/script&gt; by SNE, then the conditional probabilities should be equal: &lt;script type=&quot;math/tex&quot;&gt;q_{j \mid i} = p_{j \mid i}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;SNE seeks minimize the following cost function using gradient descent, which measures the dissimilarity between the two distributions (Kullback-Leibler divergence):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = \sum\limits_i KL(P_i || Q_i) = \sum\limits_i \sum\limits_j p_{j \mid i} \mbox{ log } \frac{p_{j \mid i}}{q_{j \mid i}}&lt;/script&gt;

&lt;p&gt;This is known as asymetric SNE. The gradient turns out to be analytically simple:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial C}{\partial y_i} = 2 \sum\limits_j (p_{j \mid i} - q_{j \mid i} - p_{i \mid j} - q_{i \mid j} )(y_i - y_j)&lt;/script&gt;

&lt;p&gt;However, the Kullback-Leibler divergence is not symmetric, so a formulation with a joint distribution can be made.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;t-sne&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;t-sne&quot;&gt;t-SNE&lt;/h3&gt;

&lt;p&gt;An improvement to SNE is t-Distributed Stochastic Neighbor Embedding (t-SNE). t-SNE employs a Gaussian in the high-dimension, but a t-Student distribution in low-dim. The t-Student distribution has longer tails than a Gaussian and is thus happier to have points far away than a Gaussian. The motivation for doing so is that in low-D, you have have less freedom than you would in the high-dimension to put many things closeby. This is because there is not much space around (crowded easily), so we penalize having points far away less.&lt;/p&gt;

&lt;p&gt;The joint distribution in the low-distribution is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{ij} = \frac{ (1+ \| y_i −y_j \|^2)^{−1} }{ \sum\limits_{k \neq l} (1+ \|y_k −y_l\|^2)^{−1} }&lt;/script&gt;

&lt;h3 id=&quot;mnist-examples&quot;&gt;MNIST examples&lt;/h3&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Leonidas Guibas. &lt;em&gt;Multi-Dimensional Scaling, Non-Linear Dimensionality Reduction&lt;/em&gt;. Class lectures of CS233: Geometric and Topological Data Analysis, taught at Stanford University in 18 April 2018.&lt;/p&gt;

&lt;p&gt;[2] Geoffrey Hinton and Sam Roweis. &lt;em&gt;Stochastic Neighbor Embedding&lt;/em&gt;. Advances in Neural Information Processing Systems (NIPS) 2003, pages 857–864. &lt;a href=&quot;http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf&quot;&gt;http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[3] L.J.P. van der Maaten and G.E. Hinton. &lt;em&gt;Visualizing High-Dimensional Data Using t-SNE&lt;/em&gt;. Journal of Machine Learning Research 9 (Nov):2579-2605, 2008.&lt;/p&gt;

&lt;p&gt;[4] Sam T. Roweis and Lawrence K. Saul. &lt;em&gt;Nonlinear Dimensionality Reduction by Locally Linear Embedding&lt;/em&gt;. Science Magazine, Vol. 290,  22 Dec. 2000.&lt;/p&gt;

&lt;p&gt;[5] J. B. Tenenbaum, V. de Silva and J. C. Langford. &lt;em&gt;A Global Geometric Framework for Nonlinear Dimensionality Reduction&lt;/em&gt;. Science 290 (5500): 2319-2323, 22 December 2000.&lt;/p&gt;

&lt;p&gt;[6] Laurenz Wiskott. &lt;em&gt;Principal Component Analysis&lt;/em&gt;. 11 March 2004. &lt;a href=&quot;https://pdfs.semanticscholar.org/d657/68e1dad46bbdb5cfb17eb19eb07cc0f5947c.pdf&quot;&gt;Online PDF&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[7] Karl Pearson. &lt;em&gt;On Lines and Planes of Closest Fit to Systems of Points in Space&lt;/em&gt;. 1901. Philosophical Magazine. 2 (11): 559–572.&lt;/p&gt;

&lt;p&gt;[8] H Hotelling. &lt;em&gt;Analysis of a complex of statistical variables into principal components&lt;/em&gt;. 1933. Journal of Educational Psychology, 24, 417–441, and 498–520.
Hotelling, H (1936). “Relations between two sets of variates”. Biometrika. 28 (3/4): 321–377. doi:10.2307/2333955. JSTOR 2333955.&lt;/p&gt;</content><author><name></name></author><summary type="html">PCA, geodesic distances, ISOMAP, LLE, SNE, t-SNE</summary></entry><entry><title type="html">Understanding Multivariate Gaussians and Covariance</title><link href="http://localhost:4000/gauss-covariance/" rel="alternate" type="text/html" title="Understanding Multivariate Gaussians and Covariance" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/gaussians-and-covariance</id><content type="html" xml:base="http://localhost:4000/gauss-covariance/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-multivariate-gaussian-random-variable&quot;&gt;What is a multivariate Gaussian random variable?&lt;/h2&gt;

&lt;p&gt;Gaussian R.V.s are parameterized by two quantities:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X \sim p(x)  = \mathcal{N}(\mu_x, \Sigma_x)&lt;/script&gt;

&lt;p&gt;Preceded by a term for normalization&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(\mu_x, \Sigma_x) = 
\frac{1}{\sqrt{(2\pi)^n|\Sigma_x|}}\mbox{exp}
\Bigg\{ -\frac{1}{2} (x - \mu_x)^T \Sigma_x^{-1} (x - \mu_x) \Bigg\}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the dimension, i.e. &lt;script type=&quot;math/tex&quot;&gt;X \in \mathbbm{R}^n&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;And of course in the scalar case, we see&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(\mu_x, \sigma_x) =&lt;/script&gt;

&lt;p&gt;Level sets trace out ellipses that are centered at &lt;script type=&quot;math/tex&quot;&gt;\mu_x&lt;/script&gt;, have minor and major axes (in 2D), and ellipsoids in higher dimensions&lt;/p&gt;

&lt;p&gt;Mean:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[X] = \int_x x p(x) dx&lt;/script&gt;

&lt;p&gt;need to show&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_x = \int_x x \mathcal{N}(\mu_x,\Sigma_x) dx&lt;/script&gt;

&lt;p&gt;Covariance&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[(X- \mu_x)(X - \mu_x)^T] = \int_x (x-\mu_x)(x-\mu_x)^T p(x) dx&lt;/script&gt;

&lt;p&gt;need to show&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma_x = \int_x (x- \mu_x) (x-\mu_x)^T \mathcal{N}(\mu_x, \Sigma_x) dx&lt;/script&gt;

&lt;p&gt;Gaussian distribution is a second-order distribution, which does not mean that the higher order moments are zero (not true in general)
Convert between a standard normal, and any multivariate Gaussian&lt;/p&gt;

&lt;h2 id=&quot;the-standard-normal-distribution&quot;&gt;The Standard Normal Distribution&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_s \sim \mathcal{N}(0, I)&lt;/script&gt;

&lt;p&gt;unit (identity) covariance, so each axis decouples, compute integral over each axis separately&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How to generate any Gaussian R.V. from standard normal&lt;/strong&gt; $$X_s$?$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X = \Sigma_x^{1/2}X_s + \mu_x&lt;/script&gt;

&lt;p&gt;Can obtain by scaling by covariance matrix, and by translating by mean
Very good for simulating
With MATLAB, can generate scalar, unit variance, 0 mean Gaussian R.V. with \texttt{randn}
Call \texttt{randn} $n$ times to populate $X_s$, and them multiply, then add
And we can compute via Cholesky Decomposition (unique if positive definite)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma = \Sigma_x^{1/2}(\Sigma_x^{1/2})^T&lt;/script&gt;

&lt;h2 id=&quot;matrix-square-roots&quot;&gt;Matrix Square Roots&lt;/h2&gt;

&lt;p&gt;\item There are other possible matrix square roots
\item \textbf{How to transform any Gaussian R.V. to the standard normal} $X_s$?
\item Do so via rearrangement:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
X_s = \Sigma_x^{-1/2}(X - \mu_x), &amp; X \sim \mathcal{N}(\mu_x, \Sigma_x)
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Much easier to integrate over the form on the RHS, not LHS
Comes from method of derived distributions
Derived Distributions: Given &lt;script type=&quot;math/tex&quot;&gt;X \sim p(x)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;Y=f(X)&lt;/script&gt;, find &lt;script type=&quot;math/tex&quot;&gt;p(y)&lt;/script&gt;
Here &lt;script type=&quot;math/tex&quot;&gt;X = X_s&lt;/script&gt;, and function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is the linear distribution &lt;script type=&quot;math/tex&quot;&gt;AX + b&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;properties-of-multivariate-gaussians&quot;&gt;Properties of Multivariate Gaussians&lt;/h2&gt;

&lt;h2 id=&quot;how-can-we-understand-a-covariance-matrix&quot;&gt;How can we understand a covariance matrix?&lt;/h2&gt;

&lt;p&gt;Larger covariance means more uncertainty. Isocontours/error ellipses&lt;/p&gt;

&lt;p&gt;We set &lt;script type=&quot;math/tex&quot;&gt;P=0.95&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\varepsilon = \frac{1-P}{2 \pi |\Sigma|^{1/2}} = \frac{1-0.95}{2 \pi |\Sigma|^{1/2}} = \frac{0.05}{2 \pi |\Sigma|^{1/2}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{B}(\varepsilon) = \Big\{ x \mid p(x) \geq \varepsilon \Big\}&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
import numpy as np
import pdb
import matplotlib.pyplot as plt
import seaborn as sns


import scipy

sns.set_style({'font.family': 'Times New Roman'})

def plot_gauss_ellipse(mu, cov, color='g', rad=2, ):
	&quot;&quot;&quot;
	Adapted from Piotr Dollar's https://github.com/pdollar/toolbox/
	Plots a 2D ellipse derived from a 2D Gaussian specified by mu &amp;amp; cov.
	
	USAGE:
		hs = plotGaussEllipses( mus, Cs, [rad] )
	
	Args:
	-	mus: Numpy array of shape (2,), representing mean
	-	Cs: Numpy array of shape (2,2), representing covariance matrix
	-	color: string representing Matplotlib color
	-	rad: [2] Number of std to create the ellipse to
	
	Returns:
	-	None
	
	color choices: ['b', 'g', 'r', 'c', 'm', 'y', 'k']
	&quot;&quot;&quot;
	cRow, ccol, ra, rb, phi = gauss2ellipse( mu, cov, rad)
	plotEllipse( cRow, ccol, ra, rb, phi, color)



def gauss2ellipse(mu, C, rad=2):
	&quot;&quot;&quot;
	Adapted from Piotr Dollar's https://github.com/pdollar/toolbox/
	Creates an ellipse representing the 2D Gaussian distribution.
	
	Creates an ellipse representing the 2D Gaussian distribution with mean mu
	and covariance matrix C.  Returns 5 parameters that specify the ellipse.
	
	USAGE
	 [cRow, cCol, ra, rb, phi] = gauss2ellipse( mu, C, [rad] )
	
	Args:
	-	mu: 1x2 vector representing the center of the ellipse
	-	C: 2x2 cov matrix
	-	rad: [2] Number of std to create the ellipse to
	
	OUTPUTS
	-	cRow: the row location of the center of the ellipse
	-	cCol: the column location of the center of the ellipse
	-	ra: semi-major axis length (in pixels) of the ellipse
	-	rb: semi-minor axis length (in pixels) of the ellipse
	-	phi: rotation angle (radians) of semimajor axis from x-axis
	
	EXAMPLE
	#  [cRow, cCol, ra, rb, phi] = gauss2ellipse( [5 5], [1 0; .5 2] )
	#  plotEllipse( cRow, cCol, ra, rb, phi );
	&quot;&quot;&quot;
	# error check
	if mu.size != 2 or C.shape != (2,2):
		print('Works only for 2D Gaussians')
		quit()

	# decompose using SVD
	_,D,Rh = np.linalg.svd(C)
	R = Rh.T
	normstd = np.sqrt(D)

	# get angle of rotation (in row/column format)
	phi = np.arccos(R[0,0])

	if R[1,0] &amp;lt; 0:
		phi = 2*np.pi - phi
	phi = np.pi/2 - phi

	# get ellipse radii
	ra = rad * normstd[0]
	rb = rad * normstd[1]

	# center of ellipse
	cRow = mu[0]
	cCol = mu[1]

	return cRow, cCol, ra, rb, phi



def plotEllipse(cRow,cCol,ra,rb,phi,color='b',nPnts=100,lw=1,ls='-'):
	&quot;&quot;&quot;
	Adapted from Piotr Dollar's https://github.com/pdollar/toolbox/
	Adds an ellipse to the current plot.
	
	USAGE:
	-	h,hc,hl = plotEllipse(cRow,cCol,ra,rb,phi,[color],[nPnts],[lw],[ls])
	
	Args:
	-	cRow: the row location of the center of the ellipse
	-	cCol: the column location of the center of the ellipse
	-	ra: semi-major axis radius length (in pixels) of the ellipse
	-	rb: semi-minor axis radius length (in pixels) of the ellipse
	-	phi: rotation angle (radians) of semimajor axis from x-axis
	-	color: ['b'] color for ellipse
	-	nPnts: [100] number of points used to draw each ellipse
	-	lw: [1] line width
	-	ls: ['-'] line style

	Returns:
	-	h : handle to ellipse
	-	hc: handle to ellipse center
	-	hl: handle to ellipse orient

	EXAMPLE:
		plotEllipse( 3, 2, 1, 5, pi/6, 'g');
	&quot;&quot;&quot;
	# plot ellipse (rotate a scaled circle):
	ts = np.linspace(-np.pi, np.pi, nPnts+1)
	cts = np.cos(ts)
	sts = np.sin(ts)

	x = ra * cts * np.cos(-phi) + rb * sts * np.sin(-phi) + cCol
	y = rb * sts * np.cos(-phi) - ra * cts * np.sin(-phi) + cRow
	h = plt.plot(x,y, color=color, linewidth=lw, linestyle=ls)

	# plot center point and line indicating orientation
	hc = plt.plot(cCol, cRow, 'k+', color=color, linewidth=lw, linestyle=ls)

	x = [cCol, cCol+np.cos(-phi)*ra]
	y = [cRow, cRow-np.sin(-phi)*ra]
	hl = plt.plot(x, y, color=color, linewidth=lw, linestyle=ls)

	return h,hc,hl


def gen_from_distribution():



	Sigma_sqrt = scipy.linalg.sqrtm(Sigma)
	Sigma_inv = np.linalg.inv(Sigma)
	tiled_mu = np.tile(mu,(1000,1)).T
	samples = np.matmul( Sigma_sqrt, np.random.randn(2,1000) ) + tiled_mu
	exterior_samples = np.zeros((1,2))
	interior_samples = np.zeros((1,2))

	for i in range(samples.shape[1]):
			X = samples[:,i]
			f_val = 0.5 * np.matmul( np.matmul( (X - mu).T, Sigma_inv), X - mu )
			if f_val &amp;lt; -np.log(0.05):
				interior_samples = np.vstack([interior_samples, np.reshape(X,(1,2)) ])
			else:
				exterior_samples = np.vstack([exterior_samples, np.reshape(X,(1,2)) ])

	plt.scatter(interior_samples[:,0], interior_samples[:,1], c= 'b')
	plt.scatter(exterior_samples[:,0], exterior_samples[:,1], c= 'b')

def plot_gauss_ellipse_v2():
	&quot;&quot;&quot;
	&quot;&quot;&quot;
	d = 2 # dimension of samples
	p = 0.95 # probability
	num_samples = 1000

	mu = np.array(0,0) # dimension (2,)

	# define covar matrices of dim (2,2)
	cov_mats[0] = np.array([[1,0],
							[0,1]])
	cov_mats[1] = np.array([[2,0],
							[0,2]])
	cov_mats[2] = np.array([[0.25, 0.3]
							[0.3, 1]])
	cov_mats[3] = np.array([[10., 5]
							[5., 5]])

	for covar_mat in cov_mats:


		# generate and plot 1000 samples
		generate_gaussian_samples()
		plt.plot()

		# plot the error ellipse
		r = np.sqrt(ellipse_const)
		n_pts = int((2*np.pi) / 0.01)+1
		theta = np.linspace(0,2*np.pi,n_pts)
		w1 = r * np.cos(theta)
		w2 = r * np.sin(theta)
		w = np.array([w1,w2]).reshape(2,1)

		# transferred back to x coordinates
		x = scipy.linalg.sqrtm(sigma).dot(w) + mu
		plt.plot()


def unit_test1():
	&quot;&quot;&quot;
	&quot;&quot;&quot;

	# plot_gauss_ellipse(mu=np.array([10., 10.]), cov=np.eye(2))
	# plot_gauss_ellipse(mu=np.array([10., 10.]), cov=np.eye(2)*2.)
	# plt.show()

	fig()

	plot_gauss_ellipse(mu=np.array([10., 10.]), cov=np.array([[5,0],[0,3]]) )
	plt.show()




if __name__ == '__main__':
	unit_test1()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">error ellipses, uncertainty</summary></entry><entry><title type="html">Conjugate Gradients</title><link href="http://localhost:4000/conjugate-gradients/" rel="alternate" type="text/html" title="Conjugate Gradients" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/conjugate-gradients</id><content type="html" xml:base="http://localhost:4000/conjugate-gradients/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conjugate-gradients&quot;&gt;Conjugate Gradients&lt;/h2&gt;</content><author><name></name></author><summary type="html">Krylov subspaces ...</summary></entry><entry><title type="html">Simultaneous Localization and Mapping (SLAM)</title><link href="http://localhost:4000/slam/" rel="alternate" type="text/html" title="Simultaneous Localization and Mapping (SLAM)" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/slam</id><content type="html" xml:base="http://localhost:4000/slam/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;slam&quot;&gt;SLAM&lt;/h2&gt;

&lt;h2 id=&quot;orbslam&quot;&gt;ORBSlam&lt;/h2&gt;

&lt;h2 id=&quot;graphslam&quot;&gt;GraphSLAM&lt;/h2&gt;

&lt;p&gt;SLAM methods [2, 10, 13, 14, 21, 30]&lt;/p&gt;

&lt;p&gt;M. Bosse, P. Newman, J. Leonard, M. Soika, W. Feiten, and S. Teller. Simultaneous localization and map building in large-scale cyclic envi- ronments using the atlas framework. IJRR, 23(12), 2004.&lt;/p&gt;

&lt;p&gt;T. Duckett, S. Marsland, and J. Shapiro. Learning globally consistent
maps by relaxation. ICRA 2000.&lt;/p&gt;

&lt;p&gt;J. Folkesson and H. I. Christensen. Robust SLAM. ISAV 2004.
[14] U. Frese, P. Larsson, and T. Duckett. A multigrid algorithm for
simultaneous localization and mapping. IEEE Transactions on Robotics,
2005.&lt;/p&gt;

&lt;p&gt;K. Konolige. Large-scale map-making. AAAI, 2004.&lt;/p&gt;

&lt;p&gt;S. Thrun and M. Montemerlo. The GraphSLAM algorithm with
applications to large-scale mapping of urban structures. IJRR, 25(5/6),
2005.&lt;/p&gt;

&lt;p&gt;. Folkesson and H. I. Christensen. Robust SLAM. ISAV 2004.&lt;/p&gt;</content><author><name></name></author><summary type="html">GraphSLAM, loop closures</summary></entry><entry><title type="html">Structure From Motion</title><link href="http://localhost:4000/sfm/" rel="alternate" type="text/html" title="Structure From Motion" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/sfm</id><content type="html" xml:base="http://localhost:4000/sfm/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-basic-structure-from-motion-sfm-pipeline&quot;&gt;A Basic Structure-from-Motion (SFM) Pipeline&lt;/h2&gt;

&lt;p&gt;As described in [1], there are generally four steps to the algorithm:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(1) Find interest points in each image&lt;/li&gt;
  &lt;li&gt;(2) Find candidate correspondences (match descriptors for each interest point)&lt;/li&gt;
  &lt;li&gt;(3) Perform geometric verification of correspondences (RANSAC + fundamental matrix)&lt;/li&gt;
  &lt;li&gt;(4) Solve for 3D points and camera that minimize reprojection error.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;costfunctions&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cost-functionserror-modelling&quot;&gt;Cost Functions/Error Modelling&lt;/h2&gt;

&lt;p&gt;The choice of cost function quantifies the total prediction error of the model. It measures how well the model fits the observations and background knowledge.&lt;/p&gt;

&lt;h3 id=&quot;reprojection-error-for-a-single-keypoint-in-two-images&quot;&gt;Reprojection Error for a Single Keypoint in Two Images&lt;/h3&gt;

&lt;p&gt;Imagine we have matched two keypoints, &lt;script type=&quot;math/tex&quot;&gt;x_1,x_2&lt;/script&gt; in two different images &lt;script type=&quot;math/tex&quot;&gt;I_1,I_2&lt;/script&gt; via a SIFT-like feature matching pipeline. We are viewing the projection of the same 3D point &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; in both images. We now wish to identify the coordinates describing the location of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;If image &lt;script type=&quot;math/tex&quot;&gt;I_1&lt;/script&gt; was captured with projection matrix &lt;script type=&quot;math/tex&quot;&gt;M_1&lt;/script&gt;, and image &lt;script type=&quot;math/tex&quot;&gt;I_2&lt;/script&gt; was captured with projection matrix &lt;script type=&quot;math/tex&quot;&gt;M_2&lt;/script&gt;, we can enforce that the 3D point &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; is projected into the image into the right location in both images. This is called &lt;em&gt;triangulation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;If the camera calibration determining &lt;script type=&quot;math/tex&quot;&gt;M_1,M_2&lt;/script&gt; are &lt;strong&gt;known&lt;/strong&gt;, then the optimization problem for a single matched keypoint in two images becomes:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\mathbf{X}} f(\mathbf{X}) = \| x_1 - Proj(\mathbf{X},M_1)\|^2 + \| x_2 - Proj(\mathbf{X},M_2)\|^2&lt;/script&gt;

&lt;h3 id=&quot;reprojection-error-for-many-keypoints-in-many-cameras&quot;&gt;Reprojection Error for Many Keypoints in Many Cameras&lt;/h3&gt;

&lt;p&gt;Imagine now that we have &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; different cameras, and each camera has a &lt;strong&gt;known&lt;/strong&gt; projection matrix &lt;script type=&quot;math/tex&quot;&gt;\{M_i\}_{i=1}^m&lt;/script&gt;. Suppose we match &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; different keypoints across the images, denoted &lt;script type=&quot;math/tex&quot;&gt;\{\mathbf{X}_j\}_{j=1}^n&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The optimization problem becomes:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\mathbf{X}_1,\mathbf{X}_2, \dots} \sum\limits_{i=1}^m \sum\limits_{j=1}^n \| x_{ij} - Proj(\mathbf{X_j},M_i)\|^2&lt;/script&gt;

&lt;p&gt;In this case &lt;script type=&quot;math/tex&quot;&gt;x_{ij}&lt;/script&gt; is the observed location of the &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;‘th keypoint into the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;‘th image, as discovered by a keypoint detector in the SIFT-like pipeline. We penalize solutions for &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}_1,\mathbf{X}_2,\dots&lt;/script&gt; in which &lt;script type=&quot;math/tex&quot;&gt;x_{ij}&lt;/script&gt; is not very close to &lt;script type=&quot;math/tex&quot;&gt;Proj(\mathbf{X_j},M_i)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;bundleadjustment&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;bundle-adjustment&quot;&gt;Bundle Adjustment&lt;/h2&gt;

&lt;p&gt;Imagine now that we are working with arbitrary images for which we have no calibration information. Thus, the projection matrices &lt;script type=&quot;math/tex&quot;&gt;\{M_i\}_{i=1}^m&lt;/script&gt; are &lt;strong&gt;unknown&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Bundle adjustment is the process of minimizing reprojection error over (1) multiple 3D points and (2) multiple cameras. Triggs &lt;em&gt;et al.&lt;/em&gt; define it as &lt;em&gt;“the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates”&lt;/em&gt; [2]. The optimization problem changes only by adding new, additional variables for which we solve.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\mathbf{X}_1,\mathbf{X}_2, \dots, M_1,M_2,\dots} \sum\limits_{i=1}^m \sum\limits_{j=1}^n \| x_{ij} - Proj(\mathbf{X_j},M_i)\|^2&lt;/script&gt;

&lt;p&gt;According to [2], the name “Bundle Adjustment” refers to &lt;em&gt;bundles&lt;/em&gt; of light rays leaving each 3D point and converging on each camera center, &lt;em&gt;“which are ‘adjusted’ optimally with respect to both feature and camera positions”&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;gauss-newton&quot;&gt;Gauss-Newton&lt;/h2&gt;

&lt;p&gt;Gauss-Newton is generally preferred to Second Order methods like Newton’s Method for a simple reason: deriving and implementing calculations of the second derivatives of the projection model &lt;script type=&quot;math/tex&quot;&gt;Proj(X_j,M_i)&lt;/script&gt; is difficult and error-prone [2].&lt;/p&gt;

&lt;p&gt;For example, the seminal work in SfM, “Building Rome in a Day” [3] uses Trust-Region Gauss-Newton optimization (Levenberg-Marquardt) that chooses between a truncated and an exact step Levenberg-Marquardt algorithm.&lt;/p&gt;

&lt;!-- ## Network Graph  shows which features are seen in which images, --&gt;

&lt;h2 id=&quot;exploiting-sparsity&quot;&gt;Exploiting Sparsity&lt;/h2&gt;

&lt;p&gt;Those who use generic optimization routines to solve SfM problems will find the optimization slow. This would be unwise, however, since the problem sparsity can be exploited.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Ramanan, Deva. &lt;em&gt;Structure from Motion.&lt;/em&gt; &lt;a href=&quot;http://16720.courses.cs.cmu.edu/lec/sfm.pdf&quot;&gt;http://16720.courses.cs.cmu.edu/lec/sfm.pdf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2] Bill Triggs, Philip McLauchlan, Richard Hartley and Andrew Fitzgibbon. &lt;em&gt;Bundle Adjustment — A Modern Synthesis&lt;/em&gt;. &lt;a href=&quot;https://hal.inria.fr/inria-00548290/document&quot;&gt;https://hal.inria.fr/inria-00548290/document&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[3] Sameer Agarwal, Noah Snavely, Ian Simon, Steven M. Seitz, Richard Szeliski. &lt;em&gt;Building Rome in a Day&lt;/em&gt;. Communications of the ACM,Volume 54 Issue 10, October 2011. Pages 105-112. &lt;a href=&quot;https://grail.cs.washington.edu/rome/rome_paper.pdf&quot;&gt;https://grail.cs.washington.edu/rome/rome_paper.pdf&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Deriving bundle adjustment</summary></entry><entry><title type="html">Particle Filter</title><link href="http://localhost:4000/particle-filter/" rel="alternate" type="text/html" title="Particle Filter" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/particle-filter</id><content type="html" xml:base="http://localhost:4000/particle-filter/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;particle-filter&quot;&gt;Particle Filter&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Particle Filter&lt;/strong&gt; is a filtering algorithm that, unlike the Kalman Filter or EKF, can represent multi-modal distributions. This is because it contains no assumptions about the form of the state distribution. It was published in 1995 [2,3] by Simon Julier, Jeffrey Uhlmann, and Hugh Durrant-Whyte at Oxford. It is often called the &lt;strong&gt;“Unscented Kalman Filter” (UKF)&lt;/strong&gt; because the inventors thought “it didn’t stink” like the EKF.&lt;/p&gt;

&lt;p&gt;The main idea is to Represent a distribution &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; with a collection of samples (particles) from &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt;: &lt;script type=&quot;math/tex&quot;&gt;x^i \sim p(x), i=1,\dots, N&lt;/script&gt; i.i.d. We know that empirical moments are related to true distribution by the Law of Large Numbers. The algorithm is simple, but expensive to compute with a for loop.&lt;/p&gt;

&lt;h2 id=&quot;whats-wrong-with-the-ekf&quot;&gt;What’s Wrong With the EKF?&lt;/h2&gt;

&lt;p&gt;The Particle Filter addresses a number of problems with the EKF:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem No. 1&lt;/strong&gt; The initial conditions (I.C.s)!
&lt;em&gt;If your initial guess is wrong, the Kalman filter will tell you exactly the wrong thing. The linearization can be vastly different at different parts of the state space&lt;/em&gt;. For example, the EKF could diverge if the residual $| \mu_{0 \mid 0} - x |$ on the initial condition is large. In fact, if $ | \mu_{t \mid t} - x_t |$ large at any time, then the EKF could diverge. This has to do with severity of non-linearity. This is the most commonly found problem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem No. 2: Covariance&lt;/strong&gt;
&lt;em&gt;In the EKF, the “covariance matrix” does not literally represent the covariance.&lt;/em&gt; Unfortunately, the covariance matrix only literally captures the covariance in the Kalman Filter. In the EKF, it is just a matrix! We don’t know what it means! If we treat it as confidence, then it is reasonable enough. And commonly true, as long as $\mu$ is tracking $x$ pretty well. However, this estimate tends to be overconfident since we are not incorporating linearization errors! Instead, &lt;script type=&quot;math/tex&quot;&gt;\Sigma_{t \mid t}&lt;/script&gt; incorporates only the noise errors &lt;script type=&quot;math/tex&quot;&gt;Q_t, R_t&lt;/script&gt;. Thus, &lt;script type=&quot;math/tex&quot;&gt;\Sigma_{t \mid t}&lt;/script&gt;  tends to be smaller than the true covariance matrix.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem No. 3: No Canary in the Goldmine&lt;/strong&gt;
An additional problem with the EKF is that we have no signal to know if we’re going awry.&lt;/p&gt;

&lt;h2 id=&quot;a-different-parameterization-particles&quot;&gt;A Different Parameterization: Particles&lt;/h2&gt;

&lt;p&gt;The UKF represents a different type of compromise than the EKF. In the Kalman Filter and its Extended variant, &lt;script type=&quot;math/tex&quot;&gt;\mu, \Sigma&lt;/script&gt; are the parameters that define the distribution &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mu, \Sigma)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The UKF parameterizes the state distribution in a different way by using “Sigma points.” Consequently, the parameterization is called the (&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;-points) parameterization. Thus, we move from &lt;script type=&quot;math/tex&quot;&gt;(\mu, \Sigma)&lt;/script&gt; to a set of points with a weight associated with each, e.g. &lt;script type=&quot;math/tex&quot;&gt;\{ (x^0,w^0), \cdots, (x^{2n}, w^{2n}) \}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The “Unscented Transform” is a curve-fitting exercise that converts individual points to a mean and covariance, i.e. &lt;script type=&quot;math/tex&quot;&gt;UT(\mu, \Sigma) = \{ (x^i, w^i) \}_i&lt;/script&gt;. An advantage of the UKF is that it is very easy to propagate these individual points through nonlinearities like non-linear dynamics, whereas it is harder to push &lt;script type=&quot;math/tex&quot;&gt;\mu, \Sigma&lt;/script&gt; through the nonlinearities.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Properties that we want the unscented transform to have&lt;/em&gt;
\item UT(&lt;script type=&quot;math/tex&quot;&gt;\cdot&lt;/script&gt;):&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;(\mu, \Sigma) = \{ (x^i, w^i) \}_i&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;UT^{-1}(\cdot)&lt;/script&gt; &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\{ (x^i, w^i) \}_i = (\mu, \Sigma)&lt;/script&gt;
We want the sample sigma points to share the same mean, covariance&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu = \sum\limits_{i=0}^{2n} w^ix^i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma = \sum\limits_{i=0}^{2n} w^i (x^i - \mu)(x^i - \mu)^T&lt;/script&gt;

&lt;p&gt;They are redundant (an overparameterization of the Gaussian)&lt;/p&gt;

&lt;p&gt;We have redundancy for a smoothing effect, since won’t be for a perfect Gaussian&lt;/p&gt;

&lt;p&gt;Here is the transform &lt;script type=&quot;math/tex&quot;&gt;UT(\cdot)&lt;/script&gt;:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;x^0 = \mu&lt;/script&gt; &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;x^i = \mu + ( \sqrt{(n+\lambda) \Sigma } )_i, i = 1, \dots, n&lt;/script&gt;\&lt;/p&gt;

&lt;p&gt;This is a matrix square root&lt;/p&gt;

&lt;p&gt;The index $i$ is the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;‘th column in the matrix square root&lt;/p&gt;

&lt;p&gt;We also have a mirror image set:&lt;br /&gt;
$x^i = \mu - ( \sqrt{(n+\lambda) \Sigma } )_{i-n}, i =n+ 1, \dots, 2n$\&lt;/p&gt;

&lt;p&gt;Those were the points. The weights themselves:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^0 = \frac{\lambda}{n+\lambda}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^i = \frac{1}{2(n+\lambda)}, i \geq 1&lt;/script&gt;

&lt;p&gt;Each of these points plot points around the circle/ellipse
Break ellipse into major and minor axes. $x_1, x_2, x_3, x_4$ at the corners of the principal axes and the parameters.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; matrix is &lt;script type=&quot;math/tex&quot;&gt;\sqrt{(n+\lambda) \Sigma}&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;verify-inverse-unscented-transform&quot;&gt;Verify Inverse Unscented Transform**&lt;/h2&gt;

&lt;p&gt;We verify &lt;script type=&quot;math/tex&quot;&gt;UT^{-1}(\cdot)&lt;/script&gt; as claimed&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=0}^{2n} w^ix^i = \frac{\lambda}{n+\lambda}(\mu) + \sum\limits_{i=1}^n  \frac{1}{2(n+\lambda)} \Bigg(\mu + ( \sqrt{(n+\lambda) \Sigma } )_i \Bigg) + \sum\limits_{i=n+1}^{2n} \frac{1}{2(n+\lambda)} \Bigg(\mu +  - ( \sqrt{(n+\lambda) \Sigma })_{i-n} \Bigg)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \frac{\lambda}{n+\lambda}(\mu) +  \frac{n}{2(n+\lambda)} \Bigg(\mu  \Bigg) +  \frac{n}{2(n+\lambda)} \Bigg(\mu \Bigg) - \mu&lt;/script&gt;

&lt;p&gt;Everything also cancels in the $\Sigma$ calculation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^n \frac{ (\sqrt{n_\lambda})(\sqrt{n_\lambda})}{ (n+\lambda)} (\sqrt{\Sigma}_i) (\sqrt{\Sigma})_i^T = \Sigma&lt;/script&gt;

&lt;p&gt;We notice that if $AA^T = B$, then we can decompose $A$ as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A = \begin{bmatrix}
| &amp; \cdots &amp; | \\
a_1 \cdots a_n \\
| &amp; \cdots &amp; | 
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;then &lt;script type=&quot;math/tex&quot;&gt;AA^T&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
= \begin{bmatrix}
| &amp; \cdots &amp; | \\
a_1 &amp; \cdots  &amp; a_n \\
| &amp; \cdots &amp; | 
\end{bmatrix}
\begin{bmatrix}
-- &amp; a_1^T &amp; -- \\
-- &amp; \cdots &amp; -- \\
-- &amp; a_n^T &amp; -- | 
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Inverting the transform is just as simple
We get &lt;script type=&quot;math/tex&quot;&gt;a_1 a_1^T + a_2 a_2^T + \cdots + a_n a_n^T&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^n a_i a_i^T = AA^T = B&lt;/script&gt;

&lt;p&gt;therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{i=1}^n (\sqrt{\Sigma})_i (\sqrt{\Sigma})_i^T = (\sqrt{\Sigma}) (\sqrt{\Sigma})^T = \Sigma&lt;/script&gt;

&lt;h2 id=&quot;matrix-square-roots&quot;&gt;Matrix Square Roots&lt;/h2&gt;

&lt;p&gt;You might prefer the Cholesky Factorization for numerical versions
Matrix Square Root! Can use SVD or Cholesky Factorization
There are SVD matrix square roots:
(i) &lt;script type=&quot;math/tex&quot;&gt;\sqrt{\Sigma} = U \Lambda^{1/2}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sqrt{\Sigma} (\sqrt{\Sigma})^T = U \Lambda^{1/2} (U \Lambda^{1/2})^T = \Sigma&lt;/script&gt;

&lt;p&gt;Columns of $U$ matrix are principal directions of ellipse. SVD gives you this geometric intution of the points around the semi axes, etc.&lt;/p&gt;

&lt;p&gt;(ii)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sqrt{\Sigma} = U \Lambda^{1/2} U^T = \Sigma&lt;/script&gt;

&lt;p&gt;SVD computation takes $O(4n^3)$ time&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cholesky Decomposition&lt;/strong&gt;
&lt;script type=&quot;math/tex&quot;&gt;M = LU&lt;/script&gt;, where lower triangular times upper triangular
When &lt;script type=&quot;math/tex&quot;&gt;M=M^T&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;L = U^T&lt;/script&gt;
Let &lt;script type=&quot;math/tex&quot;&gt;M=LL^T&lt;/script&gt;
(iii) &lt;script type=&quot;math/tex&quot;&gt;L = \sqrt{\Sigma}&lt;/script&gt;
People prefer cholesky in UKF because it has complexity &lt;script type=&quot;math/tex&quot;&gt;O( \frac{1}{6} n^3)&lt;/script&gt;, just a constant savings.&lt;/p&gt;

&lt;p&gt;We choose &lt;script type=&quot;math/tex&quot;&gt;\sqrt{\Sigma} \sqrt{\Sigma}^T = LL^T = \Sigma&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Zero out successive row elements of your vector, it is not along semi axes, but more along different axis-aligned directions as you zero  out rows&lt;/p&gt;

&lt;h2 id=&quot;ukf-sigma-point-filter&quot;&gt;UKF (Sigma Point Filter)&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\mu, \Sigma) \rightarrow UT(\cdot) \rightarrow (x^i, w^i) \rightarrow predict \rightarrow (\bar{x}^i, \bar{w}^i) \rightarrow UT^{-1}(\cdot) \rightarrow  (\bar{\mu}, \bar{\Sigma}) \rightarrow UT(\cdot) \rightarrow (x^i, w^i) \rightarrow update \rightarrow&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Predict Step&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;UT(\cdot)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
x_{t \mid t}^0 = \mu_{t \mid t} \\
x_{t \mid t}^i = \mu_{t \mid t} + (\sqrt{(n+\lambda) \Sigma_{t \mid t}})_i, i = 1, \dots, n \\
x_{t \mid t}^i = \mu_{t \mid t} - (\cdots), i = n+1, \dots, 2n \\
\bar{x}_{t +1 \mid t}^i = f(x_{t \mid t}^i, u_t)
\end{aligned}&lt;/script&gt;

&lt;p&gt;We predict through nonlinear dynamics&lt;/p&gt;

&lt;p&gt;Now we run &lt;script type=&quot;math/tex&quot;&gt;UT^{-1}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\mu_{t+1 \mid t} = \sum\limits_{i=0}^{2n} w^i \bar{x}_{t+1 \mid t}^i \\
\Sigma_{t+1 \mid t} = \sum\limits_{i=0}^{2n} w^i (\bar{x}_{t+1 \mid t}^i - \mu_{t+1 \mid t})(\bar{x}_{t+1 \mid t}^i - \mu_{t+1 \mid t})^T
\end{aligned}&lt;/script&gt;

&lt;p&gt;We recall the Gaussian estimate!&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\mu_{t \mid t} = \mu + \Sigma_{XY} \Sigma_{YY}^{-1} (y - \hat{y}) \\
\Sigma_{t \mid t} = \Sigma - \Sigma_{XY} \Sigma_{YY}^{-1} \Sigma_{YX}
\end{aligned}&lt;/script&gt;

&lt;p&gt;\item Now the UPDATE step:&lt;br /&gt;
We run &lt;script type=&quot;math/tex&quot;&gt;UT(\cdot)&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;x_{t +1 \mid t}^0&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;x_{t+1 \mid t}^{2n}&lt;/script&gt;\&lt;/p&gt;

&lt;p&gt;Let’s build $\hat{y}&lt;em&gt;{t+1 \mid t}$ and $\Sigma&lt;/em&gt;{t+1 \mid t}^{XY}$, $\Sigma_{t+1 \mid t}^{YY}$
\item Now&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y}_{t+1 \mid t} = \sum\limits_{i=0}^{2n} w^i \hat{y}_{t+1 \mid t}^i&lt;/script&gt;

&lt;p&gt;which is the expected measurment
Now,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\Sigma_{t+1 \mid t}^{YY} = \sum\limits_{i=0}^{2n} w^i (\hat{y}_{t+1 \mid t}^i - \hat{y}_{t+1 \mid t}) (\hat{y}_{t+1 \mid t}^i - \hat{y}_{t+1 \mid t})^T
\end{aligned}&lt;/script&gt;

&lt;p&gt;Now&lt;/p&gt;

&lt;p&gt;\begin{equation}
\begin{aligned}
\Sigma_{t+1 \mid t}^{XY} = \sum\limits_{i=0}^{2n} w^i (x_{t+1 \mid t}^i - \mu_{t+1 \mid t}) (\hat{y}&lt;em&gt;{t+1 \mid t}^i - \hat{y}&lt;/em&gt;{t+1 \mid t})^T
\end{aligned}
\end{equation}&lt;/p&gt;

&lt;p&gt;We are doing a fitting operation. That is why we have more sigma points than we need. Smooth out the anomalies due to any one point getting weird.&lt;/p&gt;

&lt;p&gt;\begin{equation}
\Sigma_{t+1 \mid t+1} = \Sigma_{t+1 \mid t} - \Sigma_{t+1 \mid t}^{XY} \Sigma_{t+1 \mid t}^{YY}
\end{equation}&lt;/p&gt;

&lt;p&gt;\begin{equation}
\mu_{t+1 \mid t+1 } = \mu_{t+1 \mid t } + \Sigma_{t+1 \mid t}^{XY} (\Sigma_{t+1 \mid t}^{YY})^{-1} (y_{t+1} - \hat{y}&lt;em&gt;{t+1 \mid t})
\end{equation}
where $y&lt;/em&gt;{t+1}$ is the actual measurement.&lt;/p&gt;

&lt;h2 id=&quot;choosing-lambda&quot;&gt;Choosing Lambda&lt;/h2&gt;

&lt;p&gt;What is &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;? Problem specific.  Consider SVD square root, so that sigma points will be along principal axes.&lt;/p&gt;

&lt;p&gt;Suppose we have &lt;script type=&quot;math/tex&quot;&gt;x^0&lt;/script&gt; at the center of the ellipse, and &lt;script type=&quot;math/tex&quot;&gt;x^1, \dots, x^4&lt;/script&gt; lie at each corner of the principal semi-axes&lt;/p&gt;

&lt;p&gt;$$\lambda$ is the “confidence-value” of the error ellipse&lt;/p&gt;

&lt;p&gt;If &lt;script type=&quot;math/tex&quot;&gt;n+\lambda = 1&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;x^i = \mu \pm \sqrt{\Sigma}_i&lt;/script&gt; and each column represents one standard deviation&lt;/p&gt;

&lt;p&gt;Standard deviation in each direction. Bigger &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is, then the bigger is the ellipse (And vice versa: smaller &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; gives smaller ellipse)&lt;/p&gt;

&lt;p&gt;The size of the ellipse matters because this is what we take as the region about which we create our linearization&lt;/p&gt;

&lt;p&gt;UKF is a linearization, takes average slope over a neighborhood. But it is not from the Taylor Series Expansion&lt;/p&gt;

&lt;p&gt;Why does size of ellipse matter? Blurring over a bigger neighborhood. (neighborhood about which we fit the Gaussian is determined by  &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The smaller &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is, the closer it will be to an EKF, which fits about a single-point (linearizing it there)&lt;/p&gt;

&lt;p&gt;Interesting value of &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;: &lt;script type=&quot;math/tex&quot;&gt;\lambda=2&lt;/script&gt;. For a quadratic non-linearity, then the inverse unscented transform fits the mean and the covariance of the Gaussian, and also the Kurtosis (the 4th moment) of the Gaussian (but only for a quadratic nonlinearity)
\item Fitting the Kurtosis is good! We can do it beacause the extra degrees of freedom of the sigma points overparameterize
\end{itemize}
\subsection{PRO version of UKF}
\begin{itemize}
\item Other Form of UKF:&lt;/p&gt;

&lt;p&gt;\begin{equation}
\lambda = \alpha^2 ( n + k) - n
\end{equation}
this gives us two parameters to tune&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x^i = \mu \pm \alpha ( \sqrt{(n+k) \Sigma})_i&lt;/script&gt;

&lt;p&gt;where the two parameters are &lt;script type=&quot;math/tex&quot;&gt;\alpha,k&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We now have to redefine the weights to be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_c^0 = \frac{\lambda}{n+\lambda} + (1 - \alpha^2 + \beta)&lt;/script&gt;

&lt;p&gt;where $\beta$ is another parameter&lt;/p&gt;

&lt;p&gt;Hugh Durrant White, the original paper has this original form&lt;/p&gt;

&lt;p&gt;How does it work?&lt;/p&gt;

&lt;p&gt;Algorithm is simple, but expensive to compute (with for loop)&lt;/p&gt;

&lt;p&gt;In UKF, samples deterministally extracted&lt;/p&gt;

&lt;p&gt;In Particle filter, no assumption about form of distribution, but need many form of them, and probabilistically extracted&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Main Idea:&lt;/strong&gt; Represent a distribution $p(x)$ with a collection of samples from &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt;: &lt;script type=&quot;math/tex&quot;&gt;x^i \sim p(x), i=1,\dots, N&lt;/script&gt; i.i.d.&lt;/p&gt;

&lt;p&gt;What does it mean to ``represent’’ a distribution &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; with a bunch of particles &lt;script type=&quot;math/tex&quot;&gt;\{ x_1, \dots, x_N \}&lt;/script&gt;?&lt;/p&gt;

&lt;p&gt;We know that empirical moments are related to true distribution by the law of large number&lt;/p&gt;

&lt;p&gt;Recall&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{lll}
\mu = \mathbbm{E}[X] = \int_x p(x) dx \approx \frac{1}{N} \sum\limits_{i=1}^N x_i = \bar{\mu}, &amp; x_i \sim p(x), &amp; i=1,\dots, N, i.i.d
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
\Sigma = \mathbbm{E}[(X-\mu)(X-\mu)^T] = \dots \approx \frac{1}{N} \sum\limits_{i=1}^N (x_i - \bar{\mu})(x_i - \bar{\mu})^T, &amp; x_i \sim p(x)
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Also,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbbm{E}[f(x)] \approx \frac{1}{N} \sum\limits_{i=1}^N f(x_i)&lt;/script&gt;

&lt;p&gt;The Law of Large numbers states that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{N} \sum\limits_{i=1}^N f(x_i) \rightarrow \mathbbm{E}[f(X)]&lt;/script&gt;

&lt;p&gt;as &lt;script type=&quot;math/tex&quot;&gt;N \rightarrow \infty&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Problem: Given a set of particles&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\{ x_{t+1 \mid t}^1, \dots, x_{t+1  \mid t}^N \} \sim p(x_{t+1} \mid y_{1:t} )&lt;/script&gt;

&lt;p&gt;drawn from the above distribution&lt;/p&gt;

&lt;p&gt;We recall the update step&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t \mid y_{1:t} ) = \frac{ p(y_t \mid x_t) p(x_t \mid y_{1:t-1}) }{ \int_{x_t} p(y_t \mid x_t) p(x_t \mid y_{1:t-1}) dx_t }&lt;/script&gt;

&lt;p&gt;We have particles from the top right expression, &lt;script type=&quot;math/tex&quot;&gt;x_{t \mid t-1}^i \sim p( x_t \mid y_{1:t-1})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We want to use Bayes Rule so that we can transform our particles so that they approximate the posterior (this will be one step of the Bayesian Filter)&lt;/p&gt;

&lt;p&gt;We will use :&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;q(x)&lt;/script&gt; the proposal distribution, the particles are actually from here&lt;/p&gt;

&lt;p&gt;We want them to be from $p(x)$ the target distribution, we wish they were from here&lt;/p&gt;

&lt;p&gt;We use Particle Weights&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbbm{E}_p [ f(X)] = \int_x f(x) p(x) dx = \int_x f(x) p(x) \frac{q(x)}{q(x)} dx&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbbm{E}_p [ f(X)] = \int_x f(x) w(x) q(x) dx  = \mathbbm{E}_q [ f(X) w(x) ]&lt;/script&gt;

&lt;p&gt;Given ${x^1, \dots, x^N }$
New set: ${ (x^1,w^1), \dots, (x^N,w^N) }$ where $w^i = w(x^i)$
Now the expectation is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbbm{E}_p[f(X)] \approx \frac{1}{N} \sum\limits_{i=1}^N f(x^i) w^i&lt;/script&gt;

&lt;p&gt;and &lt;script type=&quot;math/tex&quot;&gt;w(x) = \frac{p(x)}{q(x)}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;If we knew &lt;script type=&quot;math/tex&quot;&gt;p,q&lt;/script&gt;, then we would know the weights
But in the filtering setup, we don’t know the posterior, the distribution we are trying to hit! But in fact, we don’t need the target distribution!&lt;/p&gt;

&lt;p&gt;Proposal: What we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(x) = p(x_t \mid y_{1:t-1})&lt;/script&gt;

&lt;p&gt;Target: What we want&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x) = p(x_t \mid y_{1:t})&lt;/script&gt;

&lt;p&gt;So we get weights:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^i = w(x^i) = \frac{ p(x^i) }{ q(x^i) } = \frac{p(x_t^i \mid y_{1:t})^i}{p(x_t^i \mid y_{1:t-1}) }&lt;/script&gt;

&lt;p&gt;Now, by Bayes Rule, we can say that the PRIOR cancels out, which was the only thing we didn’t know???&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \frac{     \frac{p(y_t \mid x_t) p(x_t \mid y_{1:t-1}) }{ \int_{x_t} \cdots dx_t }     }{ p(x_t \mid y_{1:t-1}) }&lt;/script&gt;

&lt;p&gt;When the prior cancels, we get&lt;/p&gt;

&lt;p&gt;\begin{equation}
w(x_t^i) = \frac{p(y_t \mid x_t^i ) }{ \int_{x_t} \cdots dx_t } 
\end{equation}&lt;/p&gt;

&lt;p&gt;We just care about the relative weights, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{w} (x_t^i) = p(y_t \mid x_t^i)&lt;/script&gt;

&lt;p&gt;(unnormalized)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w(x_t^i) = \frac{ \bar{w}(x_t^i) }{  \sum\limits_{i=1}^N \bar{w}(x_t^i) }&lt;/script&gt;

&lt;p&gt;Example: suppose we have measurement noise $v_t \sim \mathcal{N}(0, R_t)$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_t = g(x_t) + v_t&lt;/script&gt;

&lt;p&gt;Given $x_{t \mid t-1}^i \sim p(x_t \mid y_{1:t-1})$, then find&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\{ (x_{t \mid t}^i, w_{t \mid t}^i \}_i&lt;/script&gt;

&lt;p&gt;to represent $p(x_t \mid y_{1:t})$. The weights are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{w}_{t \mid t}^i = p(y_t \mid x_t = x_{t \mid t-1}^i) \sim \mathcal{N}( g(x_{t \mid t-1}^i, R_t)&lt;/script&gt;

&lt;p&gt;And now&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{w}_{t \mid t}^i = \eta \mbox{exp } \{ -\frac{1}{2} (y_t - g(x_{t \mid t-1}^i)^T R_t^{-1} (y_t - g(x_{t \mid t-1}^i) ) \}&lt;/script&gt;

&lt;p&gt;Renormalize&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w(x_t^i) = \frac{ \bar{w}(x_t^i) }{ \sum\limits_{i=1}^N \bar{w}(x_t^i)  }&lt;/script&gt;

&lt;p&gt;Then multiply the weights, and renormalize (could have started with weighted particles instead of just particles)&lt;/p&gt;

&lt;p&gt;Only the weight changes in the UPDATE step (but we keep two different time indices for weights). Time indices are redundant for the &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; particles, which are the input&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\{ (x_t^i, w_{t \mid t-1}^i) \}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{w}_{t \mid t}^i = p(y_t \mid x_t = x_t^i) w_{t \mid t-1}^i&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t \mid t}^i  = \frac{ \bar{w}_{t \mid t}^i }{ \sum\limits_{i=1}^N \bar{w}_{t \mid t}^i  }&lt;/script&gt;

&lt;h2 id=&quot;predict-step&quot;&gt;Predict Step&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{t+1} \mid y_{1:t}) = \int_x p(x_{t+1} \mid x_t) p(x_t \mid y_{1:t}) dx_t&lt;/script&gt;

&lt;p&gt;the left side is the transition distribution (which we have)&lt;/p&gt;

&lt;p&gt;the right side is ${ (x_t^i, w_{t \mid t}^i) }$&lt;/p&gt;

&lt;p&gt;Let’s just “simulate” &lt;script type=&quot;math/tex&quot;&gt;p(x_{t+1} \mid x_t)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Draw &lt;script type=&quot;math/tex&quot;&gt;x_{t+1}^i \sim p(x_{t+1} \mid x_t = x_t^i )&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;x_{t+1} = f(x_t, u_t) + w_t&lt;/script&gt;, the process noise &lt;script type=&quot;math/tex&quot;&gt;w_t \sim \mathcal{N}(0, Q_t)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We sample 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{array}{ll}
w_t \sim \mathcal{N}(0, Q_t), &amp; \rightarrow x_{t+1}^i = f(x_{t}^i, u_t) + w_t 
\end{array} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;1000 particles per dimension &lt;script type=&quot;math/tex&quot;&gt;(1000^{D}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;=dimension&lt;/p&gt;

&lt;p&gt;Exponential explosion of particles required to keep the same resolution&lt;/p&gt;

&lt;p&gt;Full Filter: Given&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\{ (x_{t }^i, w_{t \mid t}^i \}_i&lt;/script&gt;

&lt;p&gt;Predict:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{t+1}^i \sim p(x_{t+1} \mid x_t = x_t^i )&lt;/script&gt;

&lt;p&gt;Update:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{w}_{t+1 \mid t+1}^i = p(y_{t+1} \mid x_{t+1} = x_{t+1}^i) w_{t \mid t}^i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t+1 \mid t+1 }^i  = \frac{ \bar{w}_{t+1 \mid t+1}^i }{ \sum\limits_{i=1}^N \bar{w}_{t+1 \mid t+1}^i  }&lt;/script&gt;

&lt;h2 id=&quot;sample-degeneracy&quot;&gt;Sample Degeneracy&lt;/h2&gt;

&lt;p&gt;Unfortunately, it is easy to end up with degenerate samples in the UKF, meaning the samples won’t do anything for you because they are all spread apart. TODO: Only one takes the weight, why?&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;solution&lt;/strong&gt;: resample points in a very clever way, via importance (re-)sampling. In a &lt;em&gt;survival of the fittest&lt;/em&gt;, those samples with high weight end up lots of children, and those with low weight disappear. I&lt;/p&gt;

&lt;p&gt;\item We sample a new set of particles at time $t$, get new $x_t^i$ s.t.
\item This is sequential important re-sampling.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Pr( x_t^i = x_t^j) = w_t^j&lt;/script&gt;

&lt;p&gt;The noisy prediction will disperse them. The new weights are uniform, i.e. &lt;script type=&quot;math/tex&quot;&gt;w_t^i = \frac{1}{N}&lt;/script&gt;
\item Particle impoverishment; all particles clumped at one point because not enough noise to disperse them
\item If the resampling happens too frequently, in comparison with the dispersal via noise, then we get sample impoverishment!&lt;/p&gt;

&lt;p&gt;We will get that all $x_t^i \approx x_t^j$, and $w_t^i \approx \frac{1}{N}, \forall i$&lt;/p&gt;

&lt;p&gt;So no diversity in the distribution anymore&lt;/p&gt;

&lt;p&gt;To fix it, resample less often&lt;/p&gt;

&lt;p&gt;Or you could just throw some random particles into your bag&lt;/p&gt;

&lt;p&gt;Check how different weights are at every time. If too different, trigger a resample (variance without subtracting mean is &lt;script type=&quot;math/tex&quot;&gt;\sum\limits_{i=1}^N (w_t^i)^2 \geq \mbox{thresh}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;If maximally different, then you would get &lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;, maximally different&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Low Variance Resampling:&lt;/strong&gt; in previous formulation, you could have gotten all copies of the same particle
One number line is &lt;script type=&quot;math/tex&quot;&gt;r \sim v[0, \frac{1}{N}]&lt;/script&gt;
Then map each of these to the right interval above in the weighted bins. Determinsitic resampling
Make &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; copies of it in every uniform bin&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Swept under Rug&lt;/strong&gt;
All filters have tried to compute the Bayesian posterior (either exactly or approximately)
The particle filter does not do this (look at prediction step)
PF tracks approximates the posterior of the trajectory instead&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{0:t} \mid y_{1:t})&lt;/script&gt;

&lt;p&gt;Because of the prediction step, where we say draw sample&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{t+1}^i \sim p(x_{t+1} \mid x_t  = x_t^i )&lt;/script&gt;

&lt;p&gt;What we really wanted was&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{t+1}^i \sim p(x_{t+1} \mid y_{1:t} ) = \int_{x_t} p(x_{t+1} \mid x_t) p(x_t \mid y_{1:t}) dx_t&lt;/script&gt;

&lt;p&gt;\item Instead, the Particle Filter finds&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{t+1}^i \sim p(x_{t+1}, x_t \mid y_{1:t}) = p(x_{t+1} \mid x_t = x_t^i) p(x_t = x_t^i \mid y_{1:t})&lt;/script&gt;

&lt;p&gt;Track distribution of the whole TRAJECTORY, given all of the measurements.
Important for SLAM, because in SLAM we often want to estimate the history of the trajectory of the robot
\end{itemize}&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Mac Schwager. Lecture Presentations of AA 273: State Estimation and Filtering for Aerospace Systems, taught at Stanford University in April-June 2018.&lt;/p&gt;

&lt;p&gt;[2] SJ Julier, JK Uhlmann, HF Durrant-Whyte. &lt;em&gt;A new approach for filtering nonlinear systems&lt;/em&gt;. Proceedings of the American Control Conference, June 1995, Volume 3, pages 1628-1632.&lt;/p&gt;

&lt;p&gt;[3] Simon Julier, Jeffrey Uhlmann, and Hugh F. Durrant-Whyte. &lt;em&gt;A New Method for the Nonlinear Transformation of Means and Covariances in Filters and Estimators&lt;/em&gt;. IEEE Transactions on Automatic Control, Volume 45, No. 3. March 2000, page 477.&lt;/p&gt;</content><author><name></name></author><summary type="html">multi-modal distributions, sigma point transform, matrix square roots ...</summary></entry><entry><title type="html">Robot Localization</title><link href="http://localhost:4000/robot-localization/" rel="alternate" type="text/html" title="Robot Localization" /><published>2018-12-27T06:00:00-05:00</published><updated>2018-12-27T06:00:00-05:00</updated><id>http://localhost:4000/localization</id><content type="html" xml:base="http://localhost:4000/robot-localization/">&lt;p&gt;Table of Contents:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#sfmpipeline&quot;&gt;A Basic SfM Pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#costfunctions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bundleadjustment&quot;&gt;Bundle Adjustment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;sfmpipeline&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;localization&quot;&gt;Localization&lt;/h2&gt;

&lt;p&gt;Navigation in urban environments requires clever solutions because sensors like GPS can’t provide centimeter-level accuracy.  Precise localization requires fusing signals from sensors like GPS, IMU, wheel odometry, and LIDAR data in concert with pre-built maps [1].&lt;/p&gt;

&lt;p&gt;In order for an autonomous robot to stay in a specific lane, it needs to know where the lane is. For an autonomous robot to stay in a lane, the localization requirements are in the order of decimeters [1].&lt;/p&gt;

&lt;p&gt;I’ll review some methods from 2007-2018.&lt;/p&gt;

&lt;h2 id=&quot;building-a-map&quot;&gt;Building a Map&lt;/h2&gt;

&lt;p&gt;The dominant method is to learn a detailed map of the environment, and then to use a vehicle’s LIDAR sensor to localize relative to this map [1]. In [1], a “map” was a 2-D overhead view of the road surface, taken in the infrared spectrum with 5-cm resolution. This 2-D grid assigns to each x-y location in the environment an infrared reflectivity value. Thus, their ground map is a orthographic infrared photograph of the ground. To acquire such a map, multiple laser range finders are mounted on a vehicle, pointing downwards at the road surface. Obtain range + infrared reflectivity. GraphSLAM is employed to map roads.&lt;/p&gt;

&lt;p&gt;To make a map, one has to differentiate between static and dynamic objects. There are two good ways to do this, as described in [1]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;track or remove objects that move at the time of mapping.&lt;/li&gt;
  &lt;li&gt;reducing the map to features are very likely to be static.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A 2D-world assumption is often not enough. In [2], localization is desired within a multi-level parking garage. They utilize multi-level surface maps to compactly represent such buildings, with a graph-based optimization procedure to establish the consistency of the map. Store surface height and variance &lt;script type=&quot;math/tex&quot;&gt;\sigma_{ij}^{l}&lt;/script&gt; to represent the uncertainty in the height of the surface.&lt;/p&gt;

&lt;p&gt;build an accurate map of the environment offline through aligning multiple
sensor passes over the same area. [9]&lt;/p&gt;

&lt;h2 id=&quot;online-localization-feature-matching-in-the-map&quot;&gt;Online Localization: Feature Matching in the Map&lt;/h2&gt;

&lt;p&gt;In the online stage, sensory input must be matched against the HD-map.&lt;/p&gt;

&lt;p&gt;In [1], the authors correlate via the Pearson product-moment correlation the measured infrared reflectivity with the map. The importance weight of each particle is a function of the correlation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_t^{[k]} = \mbox{exp}\{ -\frac{1}{2} (x_t^{[k]} − y_t)^T \Gamma_t^{−1} (x_t^{[k]} − y_t)\} \cdot \Bigg( \mbox{corr} \Bigg[ \begin{pmatrix} h_1(m,x_t^{[k]}) \\ \vdots \\ h_{180}(m,x_t^{[k]}) \end{pmatrix}, \begin{pmatrix} z_t^1 \\ \vdots \\ z_t^{180} \end{pmatrix} \Bigg] + 1 \Bigg)&lt;/script&gt;

&lt;p&gt;In [2], online localization is performed via the iterative closest points (ICP) algorithm to obtain a maximum likelihood estimate of the robot motion between subsequent observations. Instead of performing ICP on raw 3D point clouds, the ICP is performed on local MLS-maps.&lt;/p&gt;

&lt;h2 id=&quot;points-planes-poles-gaussian-bars-over-2d-grids-feature-representation-method&quot;&gt;Points Planes Poles Gaussian Bars over 2D Grids (Feature representation method)&lt;/h2&gt;

&lt;p&gt;point-to-plane ICP between the raw 3D LiDAR points against the 3D pre-scanned localization prior at 10Hz
particle filter method for correlating LIDAR measurements [1]&lt;/p&gt;

&lt;h2 id=&quot;2d-grids&quot;&gt;2D grids&lt;/h2&gt;

&lt;h2 id=&quot;using-deep-learning&quot;&gt;Using Deep Learning&lt;/h2&gt;

&lt;p&gt;Barsan &lt;em&gt;et al.&lt;/em&gt; are the first to use CNNs on LiDAR orthographic (bird’s-eye-view) images of the ground for the online localization, feature matching step [9].  embeds both LiDAR intensity maps
and online LiDAR sweeps in a common space where calibration is not required. In this scenario, online localization can be performed by searching exhaustively over 3-DoF poses – 2D position on the map manifold plus rotation. The authors score the quality of pose matches by the cross-correlation between the embeddings.&lt;/p&gt;

&lt;p&gt;They use a histogram filter, the discretized Bayes’ filter, to perform the search over 3D space. The three grid dimensions are &lt;script type=&quot;math/tex&quot;&gt;x,y,\theta&lt;/script&gt;, and they compute the belief likelihood for every cell in the search space.&lt;/p&gt;

&lt;p&gt;Barsan &lt;em&gt;et al.&lt;/em&gt; generate ground-truth poses 
Our ground-truth poses are acquired through an expensive high
precision offline matching procedure with up to several centimeter uncertainty. We rasterize the
aggregated LiDAR points to create a LiDAR intensity image. Both the online intensity image and
the intensity map are discretized at a spatial resolution of 5cm covering a 30m×24m region.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] J. Levinson, M. Montemerlo, and S. Thrun. &lt;em&gt;Map-based precision vehicle localization in urban environments&lt;/em&gt;. In Robotics: Science and Systems, volume 4, page 1. Citeseer, 2007.&lt;/p&gt;

&lt;p&gt;[2] R. Kummerle, D. Hahnel, D. Dolgov, S. Thrun, and W. Burgard. &lt;em&gt;Autonomous driving in a multi-level parking structure&lt;/em&gt;. In IEEE International Conference on Robotics and Automation (ICRA), pages 3395–3400, May 2009.&lt;/p&gt;

&lt;p&gt;[3] J. Levinson and S. Thrun. &lt;em&gt;Robust vehicle localization in urban environments using probabilistic maps&lt;/em&gt;. In IEEE International Conference on Robotics and Automation (ICRA), 934 pages 4372–4378, May 2010.&lt;/p&gt;

&lt;p&gt;[4] R. W. Wolcott and R. M. Eustice. &lt;em&gt;Fast LIDAR localization using multiresolution gaussian mixture maps&lt;/em&gt;. In IEEE International Conference on Robotics and Automation (ICRA), pages 2814–2821, May 2015.&lt;/p&gt;

&lt;p&gt;[5] R. W. Wolcott and R. M. Eustice. &lt;em&gt;Robust LIDAR localization using multiresolution gaussian mixture maps for autonomous driving&lt;/em&gt;. The International Journal of Robotics Research, 36(3):292–319, 2017.&lt;/p&gt;

&lt;p&gt;[6] H. Kim, B. Liu, C. Y. Goh, S. Lee, and H. Myung. &lt;em&gt;Robust vehicle localization using entropy-weighted particle filter-based data fusion of vertical and road intensity information for a large scale urban area&lt;/em&gt;. IEEE Robotics and Automation 923 Letters, 2(3):1518–1524, July 2017.&lt;/p&gt;

&lt;p&gt;[7] R. Dub, M. G. Gollub, H. Sommer, I. Gilitschenski, R. Siegwart, C. Cadena, and J. Nieto. &lt;em&gt;Incremental-segment-based localization in 3-D point clouds&lt;/em&gt;. IEEE Robotics and Automation Letters, 3(3):1832–1839, July 2018. 1&lt;/p&gt;

&lt;p&gt;[8] G. Wan, X. Yang, R. Cai, H. Li, Y. Zhou, H. Wang, and S. Song. &lt;em&gt;Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes&lt;/em&gt;. In IEEE International Conference on Robotics and Automation (ICRA), pages 4670–4677, May 2018.&lt;/p&gt;

&lt;p&gt;[9] Ioan Andrei Barsan, Shenlong Wang, Andrei Pokrovsky, Raquel Urtasun. &lt;em&gt;Learning to Localize Using a LiDAR Intensity Map&lt;/em&gt;. Proceedings of The 2nd Conference on Robot Learning, PMLR 87:605-616, 2018.&lt;/p&gt;</content><author><name></name></author><summary type="html">ICP, grid histograms, ...</summary></entry></feed>